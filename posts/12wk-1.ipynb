{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"12wk-1: 선인장 이미지 분류\"\n",
    "author: \"최규빈\"\n",
    "date: \"12/03/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/12wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< video https://youtu.be/playlist?list=PLQqh36zP38-z5Wh8S9Whc_lGehzJvMSit&si=BcmhgMK95Gadjbfl >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import zipfile\n",
    "import os\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "#---#\n",
    "import datasets\n",
    "import transformers\n",
    "import torchvision.transforms\n",
    "import evaluate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: <https://www.kaggle.com/c/aerial-cactus-identification>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. 압축해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('aerial-cactus-identification.zip', 'r') as z:\n",
    "    z.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./data/test.zip', 'r') as z_test:\n",
    "    z_test.extractall('./data')    \n",
    "with zipfile.ZipFile('./data/train.zip', 'r') as z_train:\n",
    "    z_train.extractall('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17495</th>\n",
       "      <td>ffede47a74e47a5930f81c0b6896479e.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>ffef6382a50d23251d4bc05519c91037.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>fff059ecc91b30be5745e8b81111dc7b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>fff43acb3b7a23edcc4ae937be2b7522.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>fffd9e9b990eba07c836745d8aef1a3a.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  has_cactus\n",
       "0      0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1      000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2      000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3      0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4      0014d7a11e90b62848904c1418fc8cf2.jpg           1\n",
       "...                                     ...         ...\n",
       "17495  ffede47a74e47a5930f81c0b6896479e.jpg           0\n",
       "17496  ffef6382a50d23251d4bc05519c91037.jpg           1\n",
       "17497  fff059ecc91b30be5745e8b81111dc7b.jpg           1\n",
       "17498  fff43acb3b7a23edcc4ae937be2b7522.jpg           0\n",
       "17499  fffd9e9b990eba07c836745d8aef1a3a.jpg           1\n",
       "\n",
       "[17500 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"./data/train.csv\")\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train에는 이미지에 해당하는 라벨이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000940378805c44108d287872b2f04ce.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017242f54ececa4512b4d7937d1e21e.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ee6d8564003107853118ab87df407.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002e175c3c1e060769475f52182583d0.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036e44a7e8f7218e9bc7bf8137e4943.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>ffaafd0c9f2f0e73172848463bc2e523.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>ffae37344310a1549162493237d25d3f.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>ffbd469c56873d064326204aac546e0d.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>ffcb76b7d47f29ece11c751e5f763f52.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>fffed17d1a8e0433a934db518d7f532c.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  has_cactus\n",
       "0     000940378805c44108d287872b2f04ce.jpg         0.5\n",
       "1     0017242f54ececa4512b4d7937d1e21e.jpg         0.5\n",
       "2     001ee6d8564003107853118ab87df407.jpg         0.5\n",
       "3     002e175c3c1e060769475f52182583d0.jpg         0.5\n",
       "4     0036e44a7e8f7218e9bc7bf8137e4943.jpg         0.5\n",
       "...                                    ...         ...\n",
       "3995  ffaafd0c9f2f0e73172848463bc2e523.jpg         0.5\n",
       "3996  ffae37344310a1549162493237d25d3f.jpg         0.5\n",
       "3997  ffbd469c56873d064326204aac546e0d.jpg         0.5\n",
       "3998  ffcb76b7d47f29ece11c751e5f763f52.jpg         0.5\n",
       "3999  fffed17d1a8e0433a934db518d7f532c.jpg         0.5\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test에는 이미지에 해당하는 라벨이 존재하지 않음. \n",
    "- 우리의 목표: 확률값을 잘 추정해서 `sample_submission`의 `has_cactus`열에 대입하고 그 결과를 캐글에 제출 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logits의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. 로짓의 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 로짓의 이해: 클래스가 2개인 자료에 대한 분류문제를 푼다고 하자. 8개의 observation/examples 에 대한 로짓값이 아래와 같다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7346244, -3.1177292],\n",
       "       [ 2.7103324, -3.1362345],\n",
       "       [ 2.7464483, -3.0521457],\n",
       "       [ 2.7195318, -3.122628 ],\n",
       "       [ 2.7138977, -3.1041346],\n",
       "       [ 2.7398622, -3.1098123],\n",
       "       [ 0.0657177, -0.0930362],\n",
       "       [-2.7668718,  3.0918367]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = np.array(\n",
    "    [[ 2.7346244, -3.1177292],\n",
    "     [ 2.7103324, -3.1362345],\n",
    "     [ 2.7464483, -3.0521457],\n",
    "     [ 2.7195318, -3.122628 ],\n",
    "     [ 2.7138977, -3.1041346],\n",
    "     [ 2.7398622, -3.1098123],\n",
    "     [ 0.0657177, -0.0930362],\n",
    "     [-2.7668718,  3.0918367]]\n",
    ")\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로짓값은 일반적으로 $(n,k)$의 차원을 가지며 여기에서 $n$은 observation의 숫자, $k$는 클래스의 숫자를 의미한다. 이 예제의 경우는 $n=8$, $k=2$인 경우이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 각 observation에 대한 로짓값이 의미하는 바를 살펴보면 아래와 같다. \n",
    "\n",
    "(1) 첫 번째 관측값 (`[2.7346244, -3.1177292]`):\n",
    "\n",
    "- 첫 번째 클래스에 대한 확신 정도: `2.7346244`\n",
    "- 두 번째 클래스에 대한 확신 정도: `-3.1177292`\n",
    "\n",
    "(2) 두 번째 관측값 (`[2.7103324,  -3.1362345]`):\n",
    "\n",
    "- 첫 번째 클래스에 대한 확신 정도: `2.7103324`\n",
    "- 두 번째 클래스에 대한 확신 정도: `-3.1362345`\n",
    "\n",
    "...\n",
    "\n",
    "(7) 마지막에서 두번째 관측값 ([`0.0657177`, `-0.0930362`]):\n",
    "\n",
    "- 첫 번째 클래스에 대한 확신 정도: `0.0657177`\n",
    "- 두 번째 클래스에 대한 확신 정도: `-0.0930362`\n",
    "\n",
    "\n",
    "(8) 마지막 관측값 ([`-2.7668718`, `3.0918367`]):\n",
    "\n",
    "- 첫 번째 클래스에 대한 확신 정도: `-2.7668718`\n",
    "- 두 번째 클래스에 대한 확신 정도: `3.0918367`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. 로짓 $\\to$ 예측클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 로짓 $\\to$ 예측클래스의 과정을 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 첫 번째 관측값: $2.7346244 > -3.1177292$ $\\Rightarrow$ 첫 번째 클래스로 예측\n",
    "\n",
    "(2) 두 번째 관측값: $2.7103324 > -3.1362345$ $\\Rightarrow$ 첫 번째 클래스로 예측\n",
    "\n",
    "...\n",
    "\n",
    "(7) 마지막에서 두번째 관측값: $0.0657177 > -0.0930362$ $\\Rightarrow$ 첫 번째 클래스로 예측 \n",
    "\n",
    "(8) 마지막 관측값: $-2.7668718 < 3.0918367$ $\\Rightarrow$ 두 번째 클래스로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7346244, -3.1177292],\n",
       "       [ 2.7103324, -3.1362345],\n",
       "       [ 2.7464483, -3.0521457],\n",
       "       [ 2.7195318, -3.122628 ],\n",
       "       [ 2.7138977, -3.1041346],\n",
       "       [ 2.7398622, -3.1098123],\n",
       "       [ 0.0657177, -0.0930362],\n",
       "       [-2.7668718,  3.0918367]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for u in logits:\n",
    "    u1, u2 = u \n",
    "    if u1 > u2: \n",
    "        prediction = 0 \n",
    "    else: \n",
    "        prediction = 1 \n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이것은 아래를 이용하여 구할수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. 로짓 $\\to$ 예측확률 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 로짓 $\\to$ 예측확률의 과정을 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\boldsymbol u}=\\begin{bmatrix} u_1 & \\dots & u_k\\end{bmatrix}$를 고정된 observation에 대한 logits값 이라고 하자. 이때 각 클래스에 속할 확률값은 아래와 같이 구한다. \n",
    "\n",
    "$$\\text{prob} =\\left[\\frac{\\exp(u_1)}{\\exp(u_1)+\\dots+\\exp(u_k)}, \\cdots,  \\frac{\\exp(u_k)}{\\exp(u_1)+\\dots+\\exp(u_k)}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7346244, -3.1177292],\n",
       "       [ 2.7103324, -3.1362345],\n",
       "       [ 2.7464483, -3.0521457],\n",
       "       [ 2.7195318, -3.122628 ],\n",
       "       [ 2.7138977, -3.1041346],\n",
       "       [ 2.7398622, -3.1098123],\n",
       "       [ 0.0657177, -0.0930362],\n",
       "       [-2.7668718,  3.0918367]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9971351022231982, 0.0028648977768018545]\n",
      "[0.9971185237682113, 0.0028814762317887605]\n",
      "[0.9969773496339113, 0.0030226503660887583]\n",
      "[0.9971058336243687, 0.0028941663756314024]\n",
      "[0.997035364944602, 0.0029646350553980375]\n",
      "[0.9971274386623321, 0.002872561337667959]\n",
      "[0.5396053294830294, 0.4603946705169706]\n",
      "[0.0028468010295870897, 0.997153198970413]\n"
     ]
    }
   ],
   "source": [
    "for u in logits:\n",
    "    u1,u2 = u\n",
    "    p1 = np.exp(u1) / (np.exp(u1)+np.exp(u2))\n",
    "    p2 = np.exp(u2) / (np.exp(u1)+np.exp(u2))\n",
    "    prediction_scores = [p1,p2]\n",
    "    print(prediction_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이 확률은 아래를 통하여 구할수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9971, 0.0029],\n",
       "        [0.9971, 0.0029],\n",
       "        [0.9970, 0.0030],\n",
       "        [0.9971, 0.0029],\n",
       "        [0.9970, 0.0030],\n",
       "        [0.9971, 0.0029],\n",
       "        [0.5396, 0.4604],\n",
       "        [0.0028, 0.9972]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(logits).softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. accuracy 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` accuracy의 계산: `logits`와 `labels`가 아래와 같이 주어졌다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.array(\n",
    "    [[ 2.7346244, -3.1177292],\n",
    "     [ 2.7103324, -3.1362345],\n",
    "     [ 2.7464483, -3.0521457],\n",
    "     [ 2.7195318, -3.122628 ],\n",
    "     [ 2.7138977, -3.1041346],\n",
    "     [ 2.7398622, -3.1098123],\n",
    "     [ 0.0657177, -0.0930362],\n",
    "     [-2.7668718,  3.0918367]]\n",
    ")\n",
    "references = labels = np.array([0,0,0,0,0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = logits.argmax(axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy는 아래와 같이 계산할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == references).sum() / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == references).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이걸 아래와 같이 계산할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.875}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = evaluate.load(\"accuracy\")\n",
    "acc.compute(predictions = predictions, references= references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. recall 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 경우에 따라서 1을 얼마나 더 잘맞추는지 알고 싶은 경우도 있다.\n",
    "\n",
    "$$\\text{recall}= \\frac{\\text{실제 라벨이 1인 관측치 중 올바르게 예측된 관측치수}}{\\text{실제 라벨이 1인 관측치 수}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.array(\n",
    "    [[ 2.7346244, -3.1177292],\n",
    "     [ 2.7103324, -3.1362345],\n",
    "     [ 2.7464483, -3.0521457],\n",
    "     [ 2.7195318, -3.122628 ],\n",
    "     [ 2.7138977, -3.1041346],\n",
    "     [ 2.7398622, -3.1098123],\n",
    "     [ 0.0657177, -0.0930362],\n",
    "     [-2.7668718,  3.0918367]]\n",
    ")\n",
    "references = labels = np.array([0,0,0,0,0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = logits.argmax(axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions[references == 1]==1).mean() # recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것을 아래와 같이 구할수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = evaluate.load(\"recall\")\n",
    "rec.compute(predictions = predictions, references = references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. auc 계산"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` accuracy 이외의 평가지표들\n",
    "\n",
    "- <https://guebin.github.io/MP2023/posts/12wk-46.html> // 시험에는 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` AUC: 클래스간의 불균형이 있을때 유의미한 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.array(\n",
    "    [[ 2.7346244, -3.1177292],\n",
    "     [ 2.7103324, -3.1362345],\n",
    "     [ 2.7464483, -3.0521457],\n",
    "     [ 2.7195318, -3.122628 ],\n",
    "     [ 2.7138977, -3.1041346],\n",
    "     [ 2.7398622, -3.1098123],\n",
    "     [ 0.0657177, -0.0930362],\n",
    "     [-2.7668718,  3.0918367]]\n",
    ")\n",
    "references = labels = np.array([0,0,0,0,0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0028649 , 0.00288148, 0.00302265, 0.00289417, 0.00296464,\n",
       "       0.00287256, 0.46039467, 0.9971532 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = torch.tensor(logits).softmax(dim=1).numpy()\n",
    "prediction_scores = probabilities[:,1]\n",
    "prediction_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 확률 0.4 이상부터는 1로 판단한다면? $\\to$ 다 맞춘거아니야?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "roc_auc.compute(prediction_scores=prediction_scores, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예제1` -- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.875}\n",
      "{'recall': 0.5}\n",
      "{'roc_auc': 1.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = np.array(\n",
    "    [[ 2.7346244, -3.1177292],\n",
    "     [ 2.7103324, -3.1362345],\n",
    "     [ 2.7464483, -3.0521457],\n",
    "     [ 2.7195318, -3.122628 ],\n",
    "     [ 2.7138977, -3.1041346],\n",
    "     [ 2.7398622, -3.1098123],\n",
    "     [ 0.0657177, -0.0930362],\n",
    "     [-2.7668718,  3.0918367]]\n",
    ")\n",
    "references = labels = np.array([0,0,0,0,0,0,1,1])\n",
    "probabilities = torch.tensor(logits).softmax(dim=1).numpy()\n",
    "prediction_scores = probabilities[:,1]\n",
    "plt.plot(prediction_scores,'--o')\n",
    "plt.plot(labels,'x')\n",
    "plt.axhline(y=0.5,color='red',linestyle='--')\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "rec = evaluate.load(\"recall\")\n",
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "print(acc.compute(predictions=predictions,references=references))\n",
    "print(rec.compute(predictions=predictions,references=references))\n",
    "print(roc_auc.compute(prediction_scores=prediction_scores,references=references))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예제2` -- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.875}\n",
      "{'recall': 0.5}\n",
      "{'roc_auc': 0.5833333333333333}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABG70lEQVR4nO3deXiTVd4+8DtJm4RuKd33UhahpSzSshRkENQqOIg7/lTABd9hXLHqKDLvMPo6dgaXYUYGHBRxEEQU0dEZBKpC2UUKCG3ZKbS0KaUFki40bZLn90ealNKFpjQ5We7PdfXSPj1pvgkhuTnPeb5HJkmSBCIiIiJB5KILICIiIu/GMEJERERCMYwQERGRUAwjREREJBTDCBEREQnFMEJERERCMYwQERGRUAwjREREJJSP6AI6w2w2o6ysDIGBgZDJZKLLISIiok6QJAnV1dWIiYmBXN7+/IdbhJGysjLEx8eLLoOIiIi6oKSkBHFxce3+3C3CSGBgIADLgwkKChJcDREREXWGXq9HfHy87XO8PW4RRqynZoKCghhGiIiI3MzVllhwASsREREJxTBCREREQjGMEBERkVAMI0RERCQUwwgREREJxTBCREREQjGMEBERkVAMI0RERCQUwwgREREJZXcY2bJlCyZPnoyYmBjIZDJ8/fXXV71Nbm4u0tLSoFar0bt3b7z//vtdqZWIiKh7bMoGcue3/bPc+Zafe7Kmx28yS9h5ogr/3l+KnSeqYDJLQh6/3e3ga2trMWTIEDz66KO45557rjq+qKgIkyZNwhNPPIEVK1Zg+/btePLJJxEeHt6p2xMREXU7uQLY9CfL/4/7XfPx3PmW4+PniqnLWZoe/9ItJ/Bm7R22w6/6f4P/MX3m9MdvdxiZOHEiJk6c2Onx77//PhISErBgwQIAQHJyMvbs2YO3336bYYSIiMSwBpDLA8nlQeTygOKB1odOQ2HjEWThM1QrjHjPdDeeUazF/5jW4N3Ge5ESOg23ObEeh2+Ut3PnTmRmZrY4duutt2Lp0qVobGyEr69vq9sYDAYYDAbb93q93tFlEhGRt7k8kGx5CzA1eEUQMZklvPZtIbSmuyEBeMF3DZ72+RoqmRHvNN6Lhaa7EfVtIW5JiYJC3vEGd93F4QtYy8vLERkZ2eJYZGQkjEYjKisr27xNdnY2NBqN7Ss+Pt7RZRIRkTca9ztAobQEEYXS44MIAOwuOg+trh4A8J7pbhgkH6hkRhgkH7zXFFC0unrsLjrvtJqccjXNlVsHS5LU5nGrOXPmQKfT2b5KSkocXiMREXmh3PnNQcTU0P6iVg9SUV1v+/9nFGttQUQlM+IZxdo2xzmaw0/TREVFoby8vMWxiooK+Pj4IDQ0tM3bqFQqqFQqR5dGRETe7Mo1ItbvAY+eIYkIVAOwBJEXfNfgncZ7bWtGXvBdA8AyY2Id5wwODyMZGRn49ttvWxzbuHEj0tPT21wvQkRE5HBtLVZta1GrBxqRFNJ01UxzEAFg++8LvmsQqPbBiKRJTqvJ7jBSU1OD48eP274vKirC/v37ERISgoSEBMyZMwelpaVYvnw5AGDWrFlYuHAhsrKy8MQTT2Dnzp1YunQpVq1a1X2PgoiIyB5mU9uLVa3fm03Or8lJFHIZJlwXincPNAcRq4WmuyEDcEdyqNMWrwKATLIu4OikzZs3Y/z48a2Oz5gxAx9//DEeeeQRnDp1Cps3b7b9LDc3F88//zwKCgoQExODl19+GbNmzer0fer1emg0Guh0OgQFBdlTLhEREbVhfb7WclWNrnltSLRGjXmTU3BbanS33EdnP7/tDiMiMIwQERF1P5NZwu6i86iorkdEoBojkkK6dUaks5/fDl8zQkRERK5JIZcho0/bF5M4EzfKIyIi8kJnLtTh4Q9/wtsbjoguhWGEiIjIG+WX6rDteCU2HakQXQrDCBERkTcqKLNstTIwRvxaTIYRIiIiL9QcRjSCK2EYISIi8kr5pToAnBkhIiIiAc5VG1BRbYBMBiRHM4wQERGRkxWUWWZFksL84a8S3+WDYYSIiMjLXKxrhKaHr0usFwHY9IyIiMjr3Hl9LKYMjcGlRtfYg4czI0RERF5IJpPBT+kacxIMI0RERCQUwwgREZEX+elkFW74y4/436/zRZdiwzBCRETkRfLL9Dhz4RLK9fWiS7FhGCEiIvIiBU3NzlJd5EoagGGEiIjIq7jSnjRWDCNEREReor7RhOPnagAAqbGcGSEiIiInO1xeDZNZQqi/EpFBKtHl2DCMEBEReQlrG/iBsRrIZDLB1TRjGCEiIvISASofDIkPxrCEYNGltOAardeIiIjI4aYMjcWUobGiy2iFMyNEREQkFMMIERGRF6hvNKHeRTbGuxLDCBERkRf47wEtBs7bgBe/+EV0Ka0wjBAREXmBgjI9TGYJASrXWy7KMEJEROQF8psu63WlZmdWDCNEREQezmyWcMgF28BbMYwQERF5uJILdag2GKH0kaNvRIDoclphGCEiIvJw1s3xBkQFwlfheh/9rlcRERERdav80qY28C54igZgGCEiIvJ4g2I1uGNIDMb0DRNdSptc7/oeIiIi6lYTB0Vj4qBo0WW0izMjREREJBTDCBERkQc7q6/HiXM1MJsl0aW0i2GEiIjIg63+uQQ3vZOL3315QHQp7WIYISIi8mAFTZ1XB0QFCq6kfQwjREREHiy/1Np51fXawFsxjBAREXmoi3UNKL14CQCQ4qI9RgCGESIiIo9V2NR5NT6kBzQ9fAVX0z6GESIiIg9l26nXhU/RAAwjREREHqvAhXfqvRw7sBIREXmoqenxSAz1x6+uCxddSocYRoiIiDzU6L5hGO2i+9FcjqdpiIiISCiGESIiIg904MxF/Hj4LCprDKJLuSqGESIiIg+0clcxHvt4Dz7efkp0KVfFMEJEROSBCrRNl/XGuvaVNADDCBERkcdpMJpxtLwGgGu3gbdiGCEiIvIwxyqq0WAyI0jtg7iePUSXc1UMI0RERB6mudmZBjKZTHA1V8cwQkRE5GEKSi3rRVy986oVwwgREZGHsc2MuMHiVYAdWImIiDxO9t2DcOCMDhm9Xb/7KsAwQkRE5HH6RQaiX2Sg6DI6jadpiIiISCjOjBAREXmQ/x7Q4qy+Hjf2D0fv8ADR5XQKwwgREZEH+eznYmw9VokeykFuE0a6dJpm0aJFSEpKglqtRlpaGrZu3drh+JUrV2LIkCHw8/NDdHQ0Hn30UVRVVXWpYCIiImqbJEnId7PLeoEuhJHVq1dj9uzZmDt3Lvbt24exY8di4sSJKC4ubnP8tm3bMH36dDz++OMoKCjAF198gZ9//hkzZ8685uKJiIiomVZXjwt1jfCRy3CdJy9gfffdd/H4449j5syZSE5OxoIFCxAfH4/Fixe3OX7Xrl3o1asXnn32WSQlJeGGG27Ab37zG+zZs+eaiyciIqJm1lmRvhEBUPsqBFfTeXaFkYaGBuTl5SEzM7PF8czMTOzYsaPN24wePRpnzpzBunXrIEkSzp49izVr1uD2229v934MBgP0en2LLyIiIurY5W3g3YldYaSyshImkwmRkZEtjkdGRqK8vLzN24wePRorV67E1KlToVQqERUVheDgYLz33nvt3k92djY0Go3tKz4+3p4yiYiIvFJBmWVmJNVNOq9adWkB65Wb7kiS1O5GPIWFhXj22Wfxhz/8AXl5eVi/fj2Kioowa9asdn//nDlzoNPpbF8lJSVdKZOIiMirHNJWA3C/mRG7Lu0NCwuDQqFoNQtSUVHRarbEKjs7G2PGjMFLL70EABg8eDD8/f0xduxYvPHGG4iOjm51G5VKBZVKZU9pREREXi8n61c4pK1GSrQHz4wolUqkpaUhJyenxfGcnByMHj26zdvU1dVBLm95NwqFZVGNJEn23D0RERF1wE/pg7TEnuihdJ/Fq0AXTtNkZWXhww8/xEcffYRDhw7h+eefR3Fxse20y5w5czB9+nTb+MmTJ2Pt2rVYvHgxTp48ie3bt+PZZ5/FiBEjEBMT032PhIiIiNyS3R1Yp06diqqqKrz++uvQarVITU3FunXrkJiYCADQarUteo488sgjqK6uxsKFC/HCCy8gODgYEyZMwF/+8pfuexRERERe7q85R3GxrgEPjEhAspudppFJbnCuRK/XQ6PRQKfTISjIvZ5gIiIiZxj/9mYUVdZi+WMj8KvrwkWXA6Dzn9/ctZeIiMjNVdc3oqiyFoB7tYG3YhghIiJyc9ZLeqM1aoQGuN/VqAwjREREbs7a7MwdZ0UAhhEiIiK3Z20Dn+Jmzc6sGEaIiIjcnHWDPM6MEBERkdOZzBJqDEYAQGqse86M2N1nhIiIiFyHQi7DtpcnoLLGgFB/pehyuoRhhIiIyAOEueFVNFY8TUNERERCcWaEiIjIjc381x40msx4ZeIAt2sDb8WZESIiIjdlMkvYdvwcco+eg9LHfT/S3bdyIiIiL3fyXA3qG83wUyqQFOovupwuYxghIiJyU/lNnVdTooMgl8sEV9N1DCNERERuqqDU0nnVXZudWTGMEBERuSlrG/iBbtrszIphhIiIyA1JkuT2G+RZMYwQERG5oWqDEcnRQQgLUKJfRKDocq4J+4wQERG5oSC1L1b/JgOSJEEmc9/FqwBnRoiIiNyauwcRgGGEiIjILdU3mkSX0G0YRoiIiNzQuLc2Ydxbm3DyXI3oUq4Z14wQERG5mYrqepzVGyCTAVEatehyrhlnRoiIiNyMtb9I7zB/+Cndf16BYYSIiMjNFDaFkVQ3b3ZmxTBCRETkZvJLPaPZmRXDCBERkZuxtYGP4cwIEREROZm+vhHF5+sAeM7MiPuveiEiIvIi9Q0mTE2Px7kaA4L9lKLL6RYMI0RERG4kIkiNv9w7WHQZ3YqnaYiIiEgohhEiIiI3cryiGg1Gs+gyuhXDCBERkZu41GBC5l+3YOC89aisMYgup9swjBAREbmJw+V6mCVA08MXof6esXgVYBghIiJyG9b+IikxGshkMsHVdB+GESIiIjfR3OzMM/qLWDGMEBERuYmCMksb+FQP6bxqxTBCRETkBhpNZhwurwbAmREiIiIS4HhFDRqMZgSqfJAQ4ie6nG7FDqxERERuoKefEi/d2h8GoxlyuecsXgUYRoiIiNxClEaNp8b3FV2GQ/A0DREREQnFMEJEROTizGYJ6w5qcaqyFpIkiS6n2zGMEBERubji83V4cuVe3LpgC0xmhhEiIiJysvym/iIDogLho/C8j27Pe0REREQe5vI28J6IYYSIiMjFWcNIaqxnNTuzYhghIiJyYZIkoaDUcppmIGdGiIiIyNnO6g2oqm2AQi7DgKhA0eU4BMMIERGRC8tvmhXpGx4Ata9CcDWOwQ6sRERELuz6hGAsemgYPLC9iA3DCBERkQsLDVBh0qBo0WU4FE/TEBERkVAMI0RERC5Kd6kR/9h0HFuOnhNdikMxjBAREbmo/FId3tpwBP/773zRpTgUwwgREZGLKiiz9hfxzGZnVgwjRERELiq/1NJ51VObnVl1KYwsWrQISUlJUKvVSEtLw9atWzscbzAYMHfuXCQmJkKlUqFPnz746KOPulQwERGRt7DOjKR4+MyI3Zf2rl69GrNnz8aiRYswZswY/POf/8TEiRNRWFiIhISENm9z//334+zZs1i6dCn69u2LiooKGI3Gay6eiIjIU9U1GHGyshYAkOrhMyMySbKvjcrIkSMxbNgwLF682HYsOTkZd955J7Kzs1uNX79+PR544AGcPHkSISEhXSpSr9dDo9FAp9MhKMiz0yEREREA5J0+j3sW70REoAq7594supwu6eznt12naRoaGpCXl4fMzMwWxzMzM7Fjx442b/PNN98gPT0d8+fPR2xsLK677jq8+OKLuHTpUrv3YzAYoNfrW3wRERF5E+tOvZ6+eBWw8zRNZWUlTCYTIiMjWxyPjIxEeXl5m7c5efIktm3bBrVaja+++gqVlZV48skncf78+XbXjWRnZ+O1116zpzQiIiKP8sDwBAxL6OnRbeCturSAVSaTtfhekqRWx6zMZjNkMhlWrlyJESNGYNKkSXj33Xfx8ccftzs7MmfOHOh0OttXSUlJV8okIiJyW0ofOVJjNRgU59nrRQA7Z0bCwsKgUChazYJUVFS0mi2xio6ORmxsLDSa5iczOTkZkiThzJkz6NevX6vbqFQqqFQqe0ojIiIiN2XXzIhSqURaWhpycnJaHM/JycHo0aPbvM2YMWNQVlaGmpoa27GjR49CLpcjLi6uCyUTERF5tuMV1Xh5zQF8scc7zgzYfZomKysLH374IT766CMcOnQIzz//PIqLizFr1iwAllMs06dPt41/8MEHERoaikcffRSFhYXYsmULXnrpJTz22GPo0aNH9z0SIiIiD5F3+gJW7ynBV/tKRZfiFHb3GZk6dSqqqqrw+uuvQ6vVIjU1FevWrUNiYiIAQKvVori42DY+ICAAOTk5eOaZZ5Ceno7Q0FDcf//9eOONN7rvURAREXkQb7qSBuhCnxER2GeEiIi8yT2LdyDv9AUsmDoUd14fK7qcLnNInxEiIiJyLJNZwiGtd82MMIwQERG5kKLKWtQ1mKD2laN3eIDocpyCYYSIiMiFWDfHS44OgkLedg8vT8MwQkRE5ELOXLA0BPWWUzRAF66mISIiIsd5anxfTM9IRH2jWXQpTsMwQkRE5GIC1b4IVIuuwnl4moaIiIiEYhghIiJyEZuPVOD+f+7Eh1tPii7FqXiahoiIyEXsLb6I3UXnkRDiJ7oUp+LMCBERkYsoKLVc1pvqRVfSAAwjRERELsO2J02sRnAlzsUwQkRE5AKqagwo19dDJrM0PPMmDCNEREQuwDorkhTqjwCVdy3pZBghIiJyAflNbeBTvGy9CMAwQkRE5BIkCQgLUCLVy9aLAIBMkiRJdBFXo9frodFooNPpEBTkfYmRiIi8gyRJMJkl+Cg8Y66gs5/f3nVSioiIyIXJZDL4KLxjp97LeUb0IiIicmNms8ufpHAohhEiIiLBPt5xCqPe/AELfzwmuhQhGEaIiIgEKyjTo1xfj0aTd86QMIwQEREJVtB0Wa83XkkDMIwQEREJVd9owrGKGgDAQC/sMQIwjBAREQl19Gw1TGYJPf18Ea1Riy5HCIYRIiIigaxt4FNjNZDJvO+yXsDd+ozU1gIKRevjCgWgVrcc1x65HOjRo2tj6+osLfLaIpMBfn5dG3vpEmA2t1+Hv3/XxtbXAyZT94z187PUDQAGA2A0ds/YHj0szzMANDQAjY3dM1atbn6t2DO2sdEyvj0qFeDjY/9Yo9HyXLRHqQR8fe0fazJZ/uza4+trGW/vWLPZ8lrrjrE+PpbnArD8nair656x9vy953tE22P5HmH/WAe8R+SX6qAwmzAkxKf915s7v0d0huQGdDqdBEDSWf7qtv6aNKnlDfz82h4HSNK4cS3HhoW1PzY9veXYxMT2x6aktBybktL+2MTElmPT09sfGxbWcuy4ce2P9fNrOXbSpPbHXvlHf++9HY+tqWkeO2NGx2MrKprHPvlkx2OLiprHvvhix2Pz85vHzpvX8djdu5vHzp/f8dhNm5rHLlzY8dj//Kd57LJlHY/9/PPmsZ9/3vHYZcuax/7nPx2PXbiweeymTR2PnT+/eezu3R2PnTeveWx+fsdjX3yxeWxRUcdjn3yyeWxFRcdjZ8xoHltT0/HYe++VWuhoLN8jLF98j2j+cqH3iA+2nJDenvl/HY910/cI2+e3Tid1xL1mRoiIiDzMzLG9gfL+wIeiKxHHvfamKStru7c9p2DbHsspWPvH8jSN5f95mqZrY/keYfl/vkfYP9ZD3yM6uzeNe4URbpRHREQe5EJtA1S+cvgpPfNERWc/v3k1DRERkSALNx3HwHkb8LfvvbMNvBXDCBERkSAFZTpIEhAd7J39RawYRoiIiASQJMnWY8RbO69aMYwQEREJUHL+EqrrjVAq5OgXESi6HKEYRoiIiASwbo53XVQAlD7e/XHs3Y+eiIhIkHzrTr0xGsGViOeZ1xIREdFVmcwSdhedR0V1PSIC1RiRFAKF3Dv3RhGB60WaMYwQEXmh9flavPZtIbS65iZX0Ro15k1OwW2p0QIr8x6TUqMR4q9EWmKI6FKEY9MzIiIvsz5fi9+u2Isr3/ytcyKLHx7GQELdgk3PiIioFZNZwmvfFrYKIgBsx177thAms8v/O5U8CMMIEZEX2V10vsWpmStJALS6euwuOu+8orzQ4XI9jpRXw2jqYB8hL8IwQkTkRSqqO9gIrQvjqGv+9v0x3LpgC5ZtPyW6FJfAMEJE5EUiAjvXdryz46hrrJf1DozlOkiAYYSIyKuMSApBtEaN9i7glcFyVc2IJF7h4Si6ukaUnL8EABgYzR4jAMMIEZFXUchlmDc5pc0FrNaAMm9yCvuNOFCB1jIrEtezBzR+voKrcQ0MI0REXua21Gi8//AwRASqWhyP0qh5Wa8TFLLZWStsekZE5IVuS43GLSlRl3VgVUEhl+OLPSW4oV84AlT8eHCU/FK2gb8SX21ERF6mxmBEgMoHCrkMGX1CAVi2s7/p3VycPFeLwXEaTMvoJbZID2ZrA8/FqzY8TUNE5EWMJjNu/esWTFv6E8ouXrIdl8lkmDYqEQCwfOdpuEFzbrc19/ZkvHDLdRgcFyy6FJfBMEJE5EW+P1SB0ouXUFCmR4i/ssXP7kmLg59SgWMVNdh1kk3PHOXG/hF45qZ+CAtQXX2wl2AYISLyIp/sOgUAmDo8HmpfRYufBal9cdf1sQCA5TtPObky8mYMI0REXuJ4RQ22H6+CXAY8NDKhzTHTm9aKbCw8C63uUptjqOtyCs9ifX45ztc2iC7FpTCMEBF5iRW7TgMAJgyIRFxPvzbH9I8KxIikEJjMElb9VOzM8rzCez8ew6wVedh1skp0KS6FYYSIyAvUGIxYk3cGADBjdGKHY2dk9EJscA9EatgSvjs1msw4rK0GwB4jV+KlvUREXuDf+0tRYzCid5g/xvQJ63DsbalRuC01il1Yu9nxiho0mMwIVPsgIaTtmSlvxTBCROQF7hkWB1+FHH5KBeRXCRkMIY5hbXaWEh0EmYzP8eUYRoiIvIDaV4H70+Ptuk2D0Yz1BeVIiQ5E34hAB1XmPWzNzth5tZUurRlZtGgRkpKSoFarkZaWhq1bt3bqdtu3b4ePjw+GDh3albslIiInmvdNPp5dtQ9LtxWJLsUjcE+a9tkdRlavXo3Zs2dj7ty52LdvH8aOHYuJEyeiuLjjVdc6nQ7Tp0/HTTfd1OViiYjIPuW6etz61y1Ytr3I7q6qd10fBwD4el8ZdHWNjijPa5jNEgrKmvakieXMyJXsDiPvvvsuHn/8ccycORPJyclYsGAB4uPjsXjx4g5v95vf/AYPPvggMjIyulwsERHZ59OfTuPI2Wp8l19u9zqF4b16YkBUIC41mvBFXomDKvQOMhnwzTM34G8PDEWfcH/R5bgcu8JIQ0MD8vLykJmZ2eJ4ZmYmduzY0e7tli1bhhMnTmDevHmduh+DwQC9Xt/ii4iI7NNgNOPT3ZYQMT2j48t52yKTyTCt6XYrdp2G2cz9arpKJpOhT3gApgyNhY+CXTWuZNczUllZCZPJhMjIyBbHIyMjUV5e3uZtjh07hldeeQUrV66Ej0/n1stmZ2dDo9HYvuLj7Vt0RUREwPqCclTWGBARqMKtA6O69DvuHBqLQJUPTlXVYevxym6ukMiiS/Hsyqk+SZLanP4zmUx48MEH8dprr+G6667r9O+fM2cOdDqd7aukhNODRET2Wr7jFADgwZEJ8O3iv8b9VT64Nz2uxe8j+y3afBxLtpxgi/122HVpb1hYGBQKRatZkIqKilazJQBQXV2NPXv2YN++fXj66acBAGazGZIkwcfHBxs3bsSECRNa3U6lUkGl4m6GRERdVVimx57TF+Ajl+HBEW3vQ9NZ00YlYtn2U6htMKLRZO5ysPFWkiThw61FOF/bgJFJoYjW9BBdksuxK4wolUqkpaUhJycHd911l+14Tk4OpkyZ0mp8UFAQDh482OLYokWL8OOPP2LNmjVISkrqYtlERNQR6+68t6ZGISLo2tq69w4PwJaXxiMhlF1Du6JcX4/ztQ1QyGXoH8V+LW2xu+lZVlYWpk2bhvT0dGRkZGDJkiUoLi7GrFmzAFhOsZSWlmL58uWQy+VITU1tcfuIiAio1epWx4mIqPtMGRqLC7WNmNG0C++1YhDpuvxSy0UYfcMDoPZVCK7GNdkdRqZOnYqqqiq8/vrr0Gq1SE1Nxbp165CYaFlxrdVqr9pzhIiIHGtU71CM6h3a7b+3qsaAimoDkqPZuKuzrP1FBsbyOWuPTLK3C44Aer0eGo0GOp0OQUH8wyQiEuGHQ2fx2xV7MSA6EN88fYPoctzGE8v3IKfwLP731yl4/AbvWp7Q2c9vrkIiIvIgO05U4o3/FOJ0VW23/+6h8cEAgANndNhfcrHbf7+nYhv4q2MYISLyIB9tK8KH24rwsQMuww0NUOHXQ6IB8DLfztLXN+Ksvh4AkMIw0i6GESIiD1Fyvg4/HK4AYLkc1xGmNy2I/c8BLapqDA65D08SpPZF/mu3Yt2zYxGk9hVdjstiGCEi8hArfjoNSQLG9gtD7/AAh9zH0PhgDI7ToMFkxuo9bEjZGWpfBWdFroJhhIjIA9Q3mvD5z5Zw4KhZESvr7MjKXcUwcb8a6gYMI0REHuA/B7S4UNeI2OAeuCm5dUfs7vTrwdHo6eeLc9UGHNJyI9OOPLVyL+asPcg28Fdhd58RIiJyPct3ngIAPDQqAQp5673CupPaV4F/PDQM/SMDERrArTvaU2swYl2+FpIEZN3S+f3ZvBHDCBGRm2swmjGiVwi0unpMTXfOLuej+4Q55X7c2SGtHpIERAapEB7I0NYRnqYhInJzSh85fv/rFOx8ZYKQmYpKXlXTpoKm/iKpMRrBlbg+hhEiIg/h4+TddCtrDLj/nzsx/u3NqDUYnXrf7iC/tKkNPK+kuSqGESIiN7axoBw7TlRCxM4eIX5KVOjrUV1vxNf7S51+/67OOjMyMJYzI1fDMEJE5KZMZgmvfVuIBz/4Cf89qHX6/cvlMjzcdBnxJztPCwlErspgNOFYRTUAzox0BsMIEZGb+uHQWZRevISefr642cGX87bnvrR4qH3lOFxejZ9PXRBSgyuq0BsQGaRGsJ8vYoN7iC7H5TGMEBG5qU92nQYA3D88HmpfhZAaNH6+uOv6WADAv5ouLyYgPsQP216egB2vTIBM5thLrT0BwwgRkRs6ca4GW49VQiYDHh7p2I6rVzNtVC8AwIb8clQ0bQpHFn5KdtDoDIYRIiI39MlOy6zITQMiEB/iJ7SWlJggpCf2hNEs4Yu8M0JrIffEyEZE5GZqDUZ82fShP61pnxjRnr/lOlTWGDAxNVp0KcKZzBLG/uVHJIX7473/Nwwh/krRJbk8hhEiIjdz5sIlhAeqEBqgxNi+rtEJdYyL1OEKiiprUKarx4W6Rmh6+Iouxy0wjBARuZn+UYH4PmsczlbXQ+7gfWi6wmyWXLIuZ7H2F0mODnT4PkGegmtGiIjckFwuQ7TG9S4Z/XDrSYx7exMOl3vvbr62NvBsdtZpDCNERG5kx4lK1DeaRJfRrr3FF1By/hKWNy2w9UYFZWwDby+GESIiN3FWX4/pS3cjI/sHVLno5nTWy3y/3lcKfX2j2GIEkCQJ+aVNbeC5QV6nMYwQEbmJT38qhtEsoW9EgJDdeTtjVO8QXBcZgLoGk+2KH29SevESdJca4auQoV9kgOhy3AbDCBGRG2g0mbFqdzEA17mcty0ymQzTLtuvxmz2rv1q6hpMuKFvGEYkhUDlI6YrrjtiGCEicgMbCspRUW1AWIAKtw2MEl1Oh+4aFocAlQ9OVtZi+4lK0eU41XWRgVgxcyRWzhwluhS3wjBCROQGrAtCHxwRD6WPa791B6h8cM8wy3413ryQlTqPfUaIiFzc4XI9dhedh0Iuw4OC96HprGkZibh4qRHTXfiUkiPo6hqh8WOjM3sxjBARubgdx6sAALcOjESURi24ms7pGxGIvz1wvegynOpctQHD//Q94nr2wI8v3OjyM1iuhGGEiMjFPXZDEsb1D4fkXWtB3Y61v4jSR84gYieGESIiN9An3D0vEz1eUY1/7TiNUb1Dcftgz95Ez9p5lf1F7MfoRkTkosxmCRX6etFlXJP1+eX4ZNdpfLD1pOhSHK7QFkbYedVeDCNERC5q+4lKjP7zj3jlywOiS+myB0YkQKmQY3/JRRw4c1F0OQ6V33SaJpUzI3ZjGCEiclHLd56G0SxB5cbrD8ICVJg0yNIXxZMv89XXN+J0VR0Azox0hfu+womIPNiZC3X44dBZAK7dcbUzrPV/80sZLtQ2iC3GQaynaGKDe6Cnv1JwNe6HYYSIyAWt/KkYZgkY0zcUfSPcc/Gq1bCEYKTGBqHBaMbqPSWiy3GIYD9fPDQyAZOHxIguxS0xjBARuZj6RhNW/2z50LbuguvOZDIZpjc9jhW7TsPkgfvVDIgKwp/uGoRXJg4QXYpbYhghInIx/z2gxfnaBsRo1Lg5OUJ0Od1i8pAY9A73xx1DYmAwmkSXQy6GfUaIiFzM502nMh4alQgfhWf8m7GHUoEfssZBJpOJLqXbGYwmHNJWY0BUINS+3Km3KxhGiIhczJJp6fgirwR3Xh8rupRu5YlBBAAOa6tx5z+2IyJQhd1zbxZdjltiGCEicjEaP1/MHNtbdBkOYTZLyD12Duf0Btw/PF50Od3C2nm1f1Sg4ErcF8MIEZGLMJklKOSeOXtgteNEFR5d9jMC1T749ZBo+Cnd/2PI2uyMbeC7zjNORhIReYAPtp7ElH9sx6YjFaJLcZjRfUKRGOqH6noj/r2/THQ53cI6M5Iay2ZnXcUwQkTkAkxmCZ/sPI1fSi7iXLVBdDkOI5fL8PDIRACWjqySm29FbDSZcVjLDfKuFcMIEZEL2HS4AqUXLyHYzxd3eHjjrPvS46DykeOQVo+80xdEl3NNTpyrhcFoRoDKB4khfqLLcVsMI0RELmD5Lsu+Lfenx3v85aHBfkpMGWoJXO6+X01B03qR5OhAyD18vY8jMYwQEQl28lwNthw9B5kMtlMYnm5603413+VrUVFdL7aYazAkPhivThqAB4YniC7Frbn/MmYiIje3YlcxAGB8/wgkhHrHVH9qrAbDEoJR12BChd6AiEC16JK6pE94APqEu/feQa6AYYSISKC6BiO+yGvahybDO2ZFrD56ZDg0PXw9thkadR5P0xARCaRUyPHWvUNw9/WxGNcvXHQ5ThXsp3TrIFJZY8C/95fixLka0aW4PYYRIiKBfBRy3JYahXenDvXaBZA1BiPW55eLLsNuu4vO47nP9uP51ftFl+L2GEaIiEiYWoMRY/78I2atyMPRs9Wiy7FLga3zKpudXSuGESIiQf7vP4X4+w/HUFXjuU3OrsZf5YNRvUMAAJ+42WW++aWWZmcpbHZ2zRhGiIgEqKiux/Kdp/BuzlGU69330tbuMKPpMt+1e8+gur5RbDF2sLaB58zItWMYISIS4LPdJWg0SUhL7On1bcQz+oSib0QAahtMWLu3VHQ5nVKhr0dljQFyGZAcxTByrRhGiIicrNFkxsqfLKckpnvZ5bxtkclkmDbKul/NKbfYr8a6U2+f8AD0UHp2x1xnYBghInKynMKzOKs3ICxAidtSo0SX4xLuHhYLf6UCJ87VYseJKtHlXFVBKU/RdKcuhZFFixYhKSkJarUaaWlp2Lp1a7tj165di1tuuQXh4eEICgpCRkYGNmzY0OWCiYjc3fKdpwAADwxPgMqH/6oGgEC1L+4eFgeZDPjlzEXR5VzV1BHxWDItzesa1TmK3WFk9erVmD17NubOnYt9+/Zh7NixmDhxIoqLi9scv2XLFtxyyy1Yt24d8vLyMH78eEyePBn79u275uKJiNzNkfJq7Dp5Hgq5DA+O5H4ml3tyfB9seWk8nryxr+hSrioiUI3MgVFISwwRXYpHkEl2npwbOXIkhg0bhsWLF9uOJScn484770R2dnanfsfAgQMxdepU/OEPf+jUeL1eD41GA51Oh6AgTokRkfsqrqrDwk3H0GiS8NepQ0WXQ+RQnf38tmtvmoaGBuTl5eGVV15pcTwzMxM7duzo1O8wm82orq5GSEj7adJgMMBgaL7uXq/X21MmEZHLSgj1w/x7h7jFIk2RSs7XISJI5ZKnsQ5p9dhYcBbDk3pidJ8w0eV4BLtO01RWVsJkMiEyMrLF8cjISJSXd66V7zvvvIPa2lrcf//97Y7Jzs6GRqOxfcXHx9tTJhGRy3PnPVkcbc7ag/jVW5tctkX8tmOV+Ov3R7F8h3s1aXNlXVrAeuVfIkmSOvUXa9WqVfjjH/+I1atXIyIiot1xc+bMgU6ns32VlJR0pUwiIpchSRLmrz+M/FKd6FJcXrRGDUkC/rXjlOhS2mS9rDc1lssGuotdYSQsLAwKhaLVLEhFRUWr2ZIrrV69Go8//jg+//xz3HzzzR2OValUCAoKavFFROTOdpyowqLNJzD1nztR12AUXY5Le2BEPHwVMuwtvuiS4a2586p3N6vrTnaFEaVSibS0NOTk5LQ4npOTg9GjR7d7u1WrVuGRRx7Bp59+ittvv71rlRIRuTHrv/LvSYuDn9Ku5XpeJyJQjdtSowG43n41dQ1GnDxXA4A9RrqT3adpsrKy8OGHH+Kjjz7CoUOH8Pzzz6O4uBizZs0CYDnFMn36dNv4VatWYfr06XjnnXcwatQolJeXo7y8HDqd66VdIiJHKL14Cd8fOgsAtk6j1LEZTf07vt5fiot1DYKraXZIWw2zBIQFqBARpBZdjsewO4xMnToVCxYswOuvv46hQ4diy5YtWLduHRITLS8crVbboufIP//5TxiNRjz11FOIjo62fT333HPd9yiIiFzYpz+dhlkCMnqHol9koOhy3EJaYk8kRwfBYDTjiz1nRJdjU8j1Ig7RpbnCJ598Ek8++WSbP/v4449bfL958+au3AURkUcwGE34bLdlET73oek8mUyG6RmJmLP2IL7eX4onftVbdEkAgEJtNQCeouluPHFJRORA6w5qUVXbgGiNGrekdLzQn1qaMjQGZknCnUNjRZdi839TBuKR0b3gr3K9/ifujGGEiMiBzGYgMkiFB0ckwEfBvUnt4af0wUMjXWs2yUchR/8onmrrbgwjREQOdE9aHO4YGgOjiR1Xr4UkSTAYzVD7ckbCEzGmExE5mK9Cjh5Kfoh21eYjFZj4t614Z+MRoXXkFJ5F1uf7sT5fK7QOT8QwQkTkABfrGrA+vxxGk1l0KW7PZJZwuLwan+85g0sNJmF1bD9eibV7S/HzqQvCavBUDCNERA7w+Z4SzFqRh//5JE90KW7vxv4RiOvZA7pLjfj2lzJhdVi7wfKy3u7HMEJE1M1MZgmf7LJ0Dr11IK+guVYKuczWLG75rlNCdjw2myUc0rINvKMwjBARdbPcoxUoOX8Jmh6+uGOI61yW6s7uT4+HykeO/FI99pVcdPr9n6qqRW2DCWpfOXqH+Tv9/j0dwwgRUTdb3rSfyn1pcVy42k16+isxeUgMADH71Vg3xxsQFcRLtB2AzygRUTc6XVWL3KPnAAAPcx+abmXtYPvfA1pU1hicet/5TW3g2XnVMdhnhIioG63YdRqSBIy7Lhy9OJ3frQbHBWPmDUm4oV8YQvyUTr3vi7WNkMuA1FiuF3EEhhEiom505Kxle3nuQ+MYv/91ipD7/cu9gzHvDjH37Q0YRoiIutHyx0bg4BkdUjid73H8lPzIdBSuGSEi6maD4jRQyGWiy/BYlTUGzF9/GM+s2ie6FOomDCNERN1Aq7sEXV2j6DK8Qn2jCe/nnsC3v5TheEW1w+/v/dwTuHvRdqzde8bh9+WtGEaIiLrBn787jJHZ32NNHj+wHC2upx8mDLA0k3PGZb57Tl3A3uKLuMiw6TAMI0RE1+hctQHrDmpR32hG/0huL+8MM0ZbFgh/ubcUNQajQ++roMzaBp5X0jgKwwgR0TVa/XMxGk0ShsYHY1AcP7CcYUyfMPQO80eNwYiv9pU67H7O1zZAq6sHACRHM2g6CsMIEdE1MJrMWPlTMYDmf62T48nlMltTueU7HLdfjXVWpFeoHwLVvg65D2IYISK6Jt8fOgutrh6h/kpMGhQtuhyvck9aHPyUChyrqMGuk+cdch/5pU2b4/EUjUPxomkiomtg3Ydm6vB4qHy4D40zaXr44uFRibjUYEJscA+H3EcB28A7BcMIEVEXndXXY3fRechlwEPch0aIVyclO/T39/RTIlqjRmoMZ0YcSSY56kRbN9Lr9dBoNNDpdAgKYjolItdxVl+PXSerMGVorOhSyIEkSYJMxkZ29urs5zfXjBARXYPIIDWDiGCSJCHv9Hm8+tVBNBjNDrkPBhHHYhghIuqCSw0m0SVQE6NZwm9X7MWnPxVjfUF5t/3e+kaTw67SoZYYRoiI7CRJEqb8YxumLf0Jp6tqRZfj9XwVcjw4MgGA5TLf7vL7r/Mx/E/f40t21XU4hhEiIjvtPFmFo2drkHf6Anr6K0WXQwAeHJEAH7kMe05fQGGZvlt+Z0GZHpU1DQhQ81oPR2MYISKy0/Idlst57x4WiyA2wnIJEUFq3JoaBQD4ZNepa/59BqMJx85aNuHjZb2OxzBCRGQHre4Scg6dBQBMz+glthhqYXrT5dVf7yuD7tK1bWp3tLwGRrOEYD9fh/UwoWYMI0REdvj0p2KYzBJGJoXgOm6K51JGJIWgf2QgLjWarnn35MubnfFKGsdjGCEi6iSD0YRVu6370PQSWwy1IpPJMC0jEfEhPaDpcW2nz/KtO/Wy2ZlTcFUOEVEnrc8vR2VNAyKDVLglJVJ0OdSGqcPj8f9GJEAhv7bZjIKmRbApXC/iFAwjRESddOvAKMy/dzAAy+Wk5Hq6689lTJ8wqHzkGBwX3C2/jzrGdvBERORxGoxmfJevRVpiT8T19BNdjtdiO3giIvJaz3++H899th+f7DotuhTqBIYRIqKr0NU14va/b8Wy7UUwmhyz9wl1rylDYgAAn/9cgvpG+1r3l5yvg77+2i4NJvswjBARXcUXeSUoKNPj8z1nrnlhJDnHTcmRiA3ugQt1jfjPAa1dt335ywMY/MeN+OaXMgdVR1diGCEi6oDZLNmm+qdnJLLnhJtQyGV4aFTTfjU7T3X6dpIkIb/Ucllv7zB/R5RGbWAYISLqwJZj53C6qg6Bah9MGRojuhyyw9T0eCgVchw4o8P+koudus2ZC5egrzfCVyFjUzsnYhghIurA8p2WWZH70uLhp2Q3BHcSGqDCrwdHA+j87Ii18+p1kYFQ+vAj0ln4TBMRtaPkfB02HakAAEzLSBRcDXXF9KZOueeqDTCbr97JwtrsjJvjORdjPhFRO1bsOg1JAsb2C0MS1w+4paHxwfjxhXHoHR7QqfHWMJIayzbwzsQwQkTUjptTIlF8vg73pceJLoWuQWeDCADb4lXOjDgXwwgRUTuG9wrB8F4hosugblJZY4DuUiP6tBNOzGYJz0zoi/xSPQZEMYw4E8MIERF5vG9/KcMLn/+Ckb1D8MnjI9scI5fLMC2jl3MLIwBcwEpE1MovJRfxf/8pxKnKWtGlUDcZGh+MRrMZW49V4uS5GtHl0BUYRoiIrvDxjlNYuq0I7/14XHQp1E3iQ/wwoX8EALS7X82O45XIL9WhwciW/87GMEJEdJnKGgP+29Q+fDov5/Uo1st81+SdQV2DsdXP53x1EL9+bxt+PnXeyZURwwgR0WVW/1yCBpMZQ+KDMSQ+WHQ51I3G9g1Dr1A/VNcb8fW+lvvO6OsbcbqqDgCvpBGBYYSIqInRZMZK6z40ozgr4mnkchkebvpzXb7zFCSpuQlaYVN/kdjgHgj2Uwqpz5sxjBARNfnhcAXKdPUI8Vfi9qY24uRZ7kuLh9pXjpOVtSi6bIEyO6+KxUt7iYiaWPcvmTo8HmpfhdhiyCE0fr5Y/HAahsQFI8S/eQakwNbsjJ1XReDMCBERLA2vUqKD0NPPFw+NTBBdDjnQ+P4RLYIIwJkR0TgzQkQEy3qCuben4He3DYCvgv9O8xYX6xqg9lXgeFPvEe5JIwbDCHktk1nC7qLzqKiuR0SgGiOSQqCQy0SXRU7U1muAQcQ7lF68hNmf7UPx+TpsfnE8Pn50OI6UVyMySCW6NK/ktWGEH0Te/Rysz9fitW8LodXV245Fa9SYNzkFt6V6z8JFvgZavgaiNGr80cteA94qPECFoso6VNYYsDj3OPqEB2BgjAZmCVB4x18Bl9KlMLJo0SK89dZb0Gq1GDhwIBYsWICxY8e2Oz43NxdZWVkoKChATEwMfve732HWrFldLvqabMrGsXN1mH7ixlYfRMv7bEa/cD9g/BwxtTmLlz8Hx1e/isIDZ6E13d3ieLmuHoWrfo++gyPRd+qbgqpzEr4GvPs1sCkbkCuAcb9r/bPc+YDZ5NF//gCg9JFjRK+eWJdfjr//0Nxp1xv/UeIK7J6PXL16NWbPno25c+di3759GDt2LCZOnIji4uI2xxcVFWHSpEkYO3Ys9u3bh1dffRXPPvssvvzyy2suviuOnatDv8K/496aT1scv6/mU/Qr/DuOnasTUpczefNzYDJL+PFoFbJ81+AZxdoWP3tasRZZvmvw49EqmMxSO7/BM/A10PZr4BlveQ3IFcCmP1mCx+Vy51uOyz3/SqL1+Vqsyy9vdbxcV4/frtiL9flaAVV5L7tnRt599108/vjjmDlzJgBgwYIF2LBhAxYvXozs7OxW499//30kJCRgwYIFAIDk5GTs2bMHb7/9Nu65555rq95OJrOE6SduxL2NZXjBdw0A4D3T3bY3oHca78WygjF46LtDkMss83RP3tgHgWpfAMD3hWeRV3yh3d//xNjethXauUfPYdfJqnbHPjq6FyKC1AAs+yFsOVbZ7tiHRyUgrqcfAGB30Xn8eLii3bFTh8cjKcwfALCv+AI2FJxt8XOzJGFl/hg8Zmr/OfioYAwe/G+h7TkAgMlDYmwLuw6X6/Fl3pl2a5g0KBrXJ/QEAJw4V4NPf2o7qAJAZkokRvYOBQAUV9Vh2Y6idsdOGBCBsf3CAQBa3SX8M/dku2PH9gvDTcmRACztvf/+wzEAljeajbV3oFphbPX4X2h6/O/V34E9K/IQpbH8+Vw+YzsssSemDI0FAFxqMOEv6w+3W8OgWA3uSYsDYGmm9ad1h9odOyAqEFOHN1/B8af/FqK9z8Le4f54aGRzQ663NxyBwWhqc2xcTz/MaGqBDQDv/XAM+vpGfNrBa+DdxnvxxYkb8dCmY9Bfat0yGwB6+inx2xv72L7/cOtJnNXXtzk2UO2LZ2/qZ/v+4+1FOHPhUptj1b4KvHhrf9v3K3adbtEL4nIKuQyvTkq2fb/652IcKW9/A7S5tydDIZdhd9F5vNmJ18CgovPI6BPa7u9za9YZkU1/av7eGkTGz217xsSDmMwSXvu2sM2fSbD8nX/t20LckhLlNactRbMrjDQ0NCAvLw+vvPJKi+OZmZnYsWNHm7fZuXMnMjMzWxy79dZbsXTpUjQ2NsLX17fVbQwGAwwGg+17vV5vT5nt2l10HlpdPd6DZWr2Bd81eNrna6hkRssbkOluwGRq8SH3yOhetjCy7XglPt5xqt3ff396vC2M/HSyCos3n2h37OTBMbYwsrf4At7PbX/sLSkRtjBy4MzFDseO6RtqCyOHtNXtjr3ac/DB1pahICUmyBZGTlXWtfr55fqEB9jCSOmFS1i6rf2xscE9bGHkbHU9lm0/1e7YsACVLYxU1TR0+GcRoPKxhRH9pUYs39lyY6z3TB08fgAbC1uGOKsGk9kWRhqM5g5ruHNojC2MmCV0+NgyUyJbhJGPtp9q91/mY/uFtQgj/9pxCtWGtkNDemLPFmHkk12nUVFt+bvV4WtAV49Pdp7GWb2hrV+LpDD/FmFkTd4ZHC6vbnNsVJC6RRj55pcy7C2+2ObYILVPizDyXb4W24+3Hep9FS3DSE5hBb4/1PafGwC8OmkAABkqqi2h6WqvAes4j3V5INnyFmBq8IogAjR/FrRHAqDV1WO3JwdSF2NXGKmsrITJZEJkZGSL45GRkSgvbz3dBQDl5eVtjjcajaisrER0dOvzctnZ2XjttdfsKa1TLn9zec90t+0NyCD52N6AAODG/uHoEx4AAOihbJ6uHNU7tMOUHKRufjrTe/XE4zcktTv28mvch8QHdzg2IlBt+//UWA1mdjA2JriH7f/7RwW2GnviXA02HTkHoOPnYHz/cPSLDLR9b30+AMsH0W9+1bvlHV/2tAyIbr5OP65nD8wa16fl0MvGDo5rvowuKkiNJ29sf+ywpoADAOGBKjwzoS/aMzKp+Q0k2E9p+zA8c6EOa/eWAuj48d99fYwtAF7u8sv+VL5yPD2+/RqSL3se5DLgqfHNj026Imf0iwxo8f2scb1tMyNXju0V2rKuR29Iap4ZuWJsbM8eLb5/eFQi9pdctM2udfQcDO8V0uL1dLmeV7TLvjctDueq2w4uAaqWbzN3XR+L4UkhbY5V+7Q8PTB5cAwGxQa3OfbKi14mpka1eh4vJ2t6MV3+96mjx3/5OI817nfNQUSh9IogAnQ+aHp8IHUhXVrAKpO1/ECWJKnVsauNb+u41Zw5c5CVlWX7Xq/XIz4+viultnD5m8szirW2NyCVzIhnFGttb0S/+VWfNtPwbalRuC01qlP3NWFAJCYMiLz6QABj+4Xb/sV/NaN6h2JU784l9bTEnkhL7Nni2M4TVbYw0tFz8D/tPAeAJeTMuexfpB3pHR6AVyYO6NTY+BA//O62zo2NDFLjhcz+Vx8IS/DLuuU6AJbp2Z0nqlCuq8fTbTz+haa7EaVR4637hl51evbKUwod8VHI8dKtnXtsAOwaa31snfHsTf2w80SVLYx09Bp4aGRip/9VOHNs76sPajIto1enxz4wovPNx6yzUFczIikE0Rr1VV8DI9oJTB4ld35zEDE1WL73gkDS2aDpFYHURdgVRsLCwqBQKFrNglRUVLSa/bCKiopqc7yPjw9CQ9t+o1OpVFCpuv9ab+ub0H01n9rWR1x+rlgG4IuABz36TcjbnwOFXIZ5k1NQuOr37T7+lMlvePR5Yr4G+BoA0HqNiPV7wOMDyeWBtK2ToTLAewKpi7ArjCiVSqSlpSEnJwd33XWX7XhOTg6mTJnS5m0yMjLw7bfftji2ceNGpKent7lexJEUcpnlssVCyyI9678A3zPdDRmALN81mNwnBgr5TU6ty5n4HAC3VX2C23zXYIniAbxXfwcAy+MPVPsgC58BVf0BeO6bMV8DfA20uVi1rUWtHsoaSH+7Yi9kaHl20xpB501O8fxA6kLsPk2TlZWFadOmIT09HRkZGViyZAmKi4ttfUPmzJmD0tJSLF++HAAwa9YsLFy4EFlZWXjiiSewc+dOLF26FKtWrereR9JJ/cL9cCzlWXxx4kbgsgVMXwQ8iMl9Yiz9FTyc1z8HZhMwfi4eH/sSBrVo+DUJ2NrH8nMPx9eAl78Gmh5/q8Bh/d7THz+A21KjsfjhYW02vmOfEeeTSdKVy+OubtGiRZg/fz60Wi1SU1Px17/+Fb/61a8AAI888ghOnTqFzZs328bn5ubi+eeftzU9e/nll+1qeqbX66HRaKDT6RAU1D2bGHlz50krPgfE1wB5O/4dcKzOfn53KYw4myPCCBERETlWZz+/uSMUERERCcUwQkREREIxjBAREZFQDCNEREQkFMMIERERCcUwQkREREIxjBAREZFQDCNEREQkFMMIERERCWX33jQiWJvE6vV6wZUQERFRZ1k/t6/W7N0twkh1dTUAID4+XnAlREREZK/q6mpoNJp2f+4We9OYzWaUlZUhMDAQMln3bWCk1+sRHx+PkpISr93zxtufA29//ACfAz5+7378AJ8DRz5+SZJQXV2NmJgYyOXtrwxxi5kRuVyOuLg4h/3+oKAgr3wBXs7bnwNvf/wAnwM+fu9+/ACfA0c9/o5mRKy4gJWIiIiEYhghIiIiobw6jKhUKsybNw8qlUp0KcJ4+3Pg7Y8f4HPAx+/djx/gc+AKj98tFrASERGR5/LqmREiIiISj2GEiIiIhGIYISIiIqEYRoiIiEgorw4jixYtQlJSEtRqNdLS0rB161bRJTnNli1bMHnyZMTExEAmk+Hrr78WXZJTZWdnY/jw4QgMDERERATuvPNOHDlyRHRZTrN48WIMHjzY1uQoIyMD3333neiyhMnOzoZMJsPs2bNFl+I0f/zjHyGTyVp8RUVFiS7LqUpLS/Hwww8jNDQUfn5+GDp0KPLy8kSX5TS9evVq9RqQyWR46qmnnF6L14aR1atXY/bs2Zg7dy727duHsWPHYuLEiSguLhZdmlPU1tZiyJAhWLhwoehShMjNzcVTTz2FXbt2IScnB0ajEZmZmaitrRVdmlPExcXhz3/+M/bs2YM9e/ZgwoQJmDJlCgoKCkSX5nQ///wzlixZgsGDB4suxekGDhwIrVZr+zp48KDokpzmwoULGDNmDHx9ffHdd9+hsLAQ77zzDoKDg0WX5jQ///xziz//nJwcAMB9993n/GIkLzVixAhp1qxZLY4NGDBAeuWVVwRVJA4A6auvvhJdhlAVFRUSACk3N1d0KcL07NlT+vDDD0WX4VTV1dVSv379pJycHGncuHHSc889J7okp5k3b540ZMgQ0WUI8/LLL0s33HCD6DJcynPPPSf16dNHMpvNTr9vr5wZaWhoQF5eHjIzM1scz8zMxI4dOwRVRSLpdDoAQEhIiOBKnM9kMuGzzz5DbW0tMjIyRJfjVE899RRuv/123HzzzaJLEeLYsWOIiYlBUlISHnjgAZw8eVJ0SU7zzTffID09Hffddx8iIiJw/fXX44MPPhBdljANDQ1YsWIFHnvssW7dkLazvDKMVFZWwmQyITIyssXxyMhIlJeXC6qKRJEkCVlZWbjhhhuQmpoquhynOXjwIAICAqBSqTBr1ix89dVXSElJEV2W03z22WfYu3cvsrOzRZcixMiRI7F8+XJs2LABH3zwAcrLyzF69GhUVVWJLs0pTp48icWLF6Nfv37YsGEDZs2ahWeffRbLly8XXZoQX3/9NS5evIhHHnlEyP27xa69jnJl+pMkSUgiJLGefvppHDhwANu2bRNdilP1798f+/fvx8WLF/Hll19ixowZyM3N9YpAUlJSgueeew4bN26EWq0WXY4QEydOtP3/oEGDkJGRgT59+uBf//oXsrKyBFbmHGazGenp6XjzzTcBANdffz0KCgqwePFiTJ8+XXB1zrd06VJMnDgRMTExQu7fK2dGwsLCoFAoWs2CVFRUtJotIc/2zDPP4JtvvsGmTZsQFxcnuhynUiqV6Nu3L9LT05GdnY0hQ4bgb3/7m+iynCIvLw8VFRVIS0uDj48PfHx8kJubi7///e/w8fGByWQSXaLT+fv7Y9CgQTh27JjoUpwiOjq6VfBOTk72mosYLnf69Gl8//33mDlzprAavDKMKJVKpKWl2VYOW+Xk5GD06NGCqiJnkiQJTz/9NNauXYsff/wRSUlJoksSTpIkGAwG0WU4xU033YSDBw9i//79tq/09HQ89NBD2L9/PxQKhegSnc5gMODQoUOIjo4WXYpTjBkzptXl/EePHkViYqKgisRZtmwZIiIicPvttwurwWtP02RlZWHatGlIT09HRkYGlixZguLiYsyaNUt0aU5RU1OD48eP274vKirC/v37ERISgoSEBIGVOcdTTz2FTz/9FP/+978RGBhomyXTaDTo0aOH4Ooc79VXX8XEiRMRHx+P6upqfPbZZ9i8eTPWr18vujSnCAwMbLU+yN/fH6GhoV6zbujFF1/E5MmTkZCQgIqKCrzxxhvQ6/WYMWOG6NKc4vnnn8fo0aPx5ptv4v7778fu3buxZMkSLFmyRHRpTmU2m7Fs2TLMmDEDPj4CI4HTr99xIf/4xz+kxMRESalUSsOGDfOqyzo3bdokAWj1NWPGDNGlOUVbjx2AtGzZMtGlOcVjjz1me+2Hh4dLN910k7Rx40bRZQnlbZf2Tp06VYqOjpZ8fX2lmJgY6e6775YKCgpEl+VU3377rZSamiqpVCppwIAB0pIlS0SX5HQbNmyQAEhHjhwRWodMkiRJTAwiIiIi8tI1I0REROQ6GEaIiIhIKIYRIiIiEophhIiIiIRiGCEiIiKhGEaIiIhIKIYRIiIiEophhIiIiIRiGCEiIiKhGEaIiIhIKIYRIiIiEophhIiIiIT6/5vqlcEA1UPIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = np.array(\n",
    "    [[ 2.7346244, -3.1177292],\n",
    "     [ 2.7103324, -3.1362345],\n",
    "     [ 2.7464483, -3.0521457],\n",
    "     [ 2.7195318, -3.122628 ],\n",
    "     [ 2.7138977, -3.1041346],\n",
    "     [ 0.0657177, -0.0930362],\n",
    "     [ 2.7398622, -3.1098123],\n",
    "     [-2.7668718,  3.0918367]]\n",
    ")\n",
    "references = labels = np.array([0,0,0,0,0,0,1,1])\n",
    "probabilities = torch.tensor(logits).softmax(dim=1).numpy()\n",
    "prediction_scores = probabilities[:,1]\n",
    "plt.plot(prediction_scores,'--o')\n",
    "plt.plot(labels,'x')\n",
    "plt.axhline(y=0.5,color='red',linestyle='--')\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "rec = evaluate.load(\"recall\")\n",
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "print(acc.compute(predictions=predictions,references=references))\n",
    "print(rec.compute(predictions=predictions,references=references))\n",
    "print(roc_auc.compute(prediction_scores=prediction_scores,references=references))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `train.csv`를 pandas로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17495</th>\n",
       "      <td>ffede47a74e47a5930f81c0b6896479e.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>ffef6382a50d23251d4bc05519c91037.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>fff059ecc91b30be5745e8b81111dc7b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>fff43acb3b7a23edcc4ae937be2b7522.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>fffd9e9b990eba07c836745d8aef1a3a.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  has_cactus\n",
       "0      0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1      000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2      000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3      0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4      0014d7a11e90b62848904c1418fc8cf2.jpg           1\n",
       "...                                     ...         ...\n",
       "17495  ffede47a74e47a5930f81c0b6896479e.jpg           0\n",
       "17496  ffef6382a50d23251d4bc05519c91037.jpg           1\n",
       "17497  fff059ecc91b30be5745e8b81111dc7b.jpg           1\n",
       "17498  fff43acb3b7a23edcc4ae937be2b7522.jpg           0\n",
       "17499  fffd9e9b990eba07c836745d8aef1a3a.jpg           1\n",
       "\n",
       "[17500 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"./data/train.csv\")\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000940378805c44108d287872b2f04ce.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017242f54ececa4512b4d7937d1e21e.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ee6d8564003107853118ab87df407.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002e175c3c1e060769475f52182583d0.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036e44a7e8f7218e9bc7bf8137e4943.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>ffaafd0c9f2f0e73172848463bc2e523.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>ffae37344310a1549162493237d25d3f.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>ffbd469c56873d064326204aac546e0d.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>ffcb76b7d47f29ece11c751e5f763f52.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>fffed17d1a8e0433a934db518d7f532c.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  has_cactus\n",
       "0     000940378805c44108d287872b2f04ce.jpg         0.5\n",
       "1     0017242f54ececa4512b4d7937d1e21e.jpg         0.5\n",
       "2     001ee6d8564003107853118ab87df407.jpg         0.5\n",
       "3     002e175c3c1e060769475f52182583d0.jpg         0.5\n",
       "4     0036e44a7e8f7218e9bc7bf8137e4943.jpg         0.5\n",
       "...                                    ...         ...\n",
       "3995  ffaafd0c9f2f0e73172848463bc2e523.jpg         0.5\n",
       "3996  ffae37344310a1549162493237d25d3f.jpg         0.5\n",
       "3997  ffbd469c56873d064326204aac546e0d.jpg         0.5\n",
       "3998  ffcb76b7d47f29ece11c751e5f763f52.jpg         0.5\n",
       "3999  fffed17d1a8e0433a934db518d7f532c.jpg         0.5\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. 예쁜(?) 정석 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step1: Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_train = datasets.Dataset.from_pandas(train_csv)\n",
    "ctx_test = datasets.Dataset.from_pandas(test_csv).remove_columns(['has_cactus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 17500/17500 [00:00<00:00, 59071.71 examples/s]\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 86647.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ctx_train = ctx_train.map(lambda example: {'path': \"./data/train/\" + example['id']})\n",
    "ctx_test = ctx_test.map(lambda example: {'path': \"./data/test/\" + example['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'has_cactus', 'path'],\n",
       "        num_rows: 17500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'path'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = datasets.DatasetDict({\n",
    "    'train':ctx_train,\n",
    "    'test':ctx_test\n",
    "})\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = torchvision.transforms.Compose([\n",
    "    lambda path: PIL.Image.open(path),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224,224))\n",
    "])\n",
    "def w_trans(examples):\n",
    "    # train: examples = {'id':[xx,xxx,....], 'has_cactus':[yy,yyy,...], 'path':[zz,zzz,...]}\n",
    "    # train: examples = {'id':[xx,xxx,....], 'path':[zz,zzz,...]}\n",
    "    dct = dict()\n",
    "    dct['pixel_values'] = torch.stack(list(map(compose, examples['path'])))\n",
    "    try: \n",
    "        dct['labels']= torch.tensor(examples['has_cactus'])\n",
    "    except:\n",
    "        pass\n",
    "    return dct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'has_cactus', 'path'],\n",
       "        num_rows: 17500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'path'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = ctx.with_transform(w_trans)\n",
    "ctx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n",
       "           [0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n",
       "           [0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n",
       "           ...,\n",
       "           [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451],\n",
       "           [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451],\n",
       "           [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451]],\n",
       " \n",
       "          [[0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n",
       "           [0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n",
       "           [0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n",
       "           ...,\n",
       "           [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314],\n",
       "           [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314],\n",
       "           [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314]],\n",
       " \n",
       "          [[0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n",
       "           [0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n",
       "           [0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n",
       "           ...,\n",
       "           [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098],\n",
       "           [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098],\n",
       "           [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098]]],\n",
       " \n",
       " \n",
       "         [[[0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4824],\n",
       "           [0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4824],\n",
       "           [0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4824],\n",
       "           ...,\n",
       "           [0.3647, 0.3647, 0.3647,  ..., 0.4941, 0.4941, 0.4941],\n",
       "           [0.3647, 0.3647, 0.3647,  ..., 0.4941, 0.4941, 0.4941],\n",
       "           [0.3647, 0.3647, 0.3647,  ..., 0.4941, 0.4941, 0.4941]],\n",
       " \n",
       "          [[0.4275, 0.4275, 0.4275,  ..., 0.3804, 0.3804, 0.3804],\n",
       "           [0.4275, 0.4275, 0.4275,  ..., 0.3804, 0.3804, 0.3804],\n",
       "           [0.4275, 0.4275, 0.4275,  ..., 0.3804, 0.3804, 0.3804],\n",
       "           ...,\n",
       "           [0.3059, 0.3059, 0.3059,  ..., 0.4314, 0.4314, 0.4314],\n",
       "           [0.3059, 0.3059, 0.3059,  ..., 0.4314, 0.4314, 0.4314],\n",
       "           [0.3059, 0.3059, 0.3059,  ..., 0.4314, 0.4314, 0.4314]],\n",
       " \n",
       "          [[0.4471, 0.4471, 0.4471,  ..., 0.4235, 0.4235, 0.4235],\n",
       "           [0.4471, 0.4471, 0.4471,  ..., 0.4235, 0.4235, 0.4235],\n",
       "           [0.4471, 0.4471, 0.4471,  ..., 0.4235, 0.4235, 0.4235],\n",
       "           ...,\n",
       "           [0.3255, 0.3255, 0.3255,  ..., 0.4745, 0.4745, 0.4745],\n",
       "           [0.3255, 0.3255, 0.3255,  ..., 0.4745, 0.4745, 0.4745],\n",
       "           [0.3255, 0.3255, 0.3255,  ..., 0.4745, 0.4745, 0.4745]]]]),\n",
       " 'labels': tensor([1, 1])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx['train'][:2]\n",
    "#ctx['test'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step2: Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    \"microsoft/resnet-50\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step3: Train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutputWithNoAttention(loss=tensor(0.6874, grad_fn=<NllLossBackward0>), logits=tensor([[0.0648, 0.0802],\n",
       "        [0.0668, 0.0745]], grad_fn=<AddmmBackward0>), hidden_states=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single_batch = [ctx['train'][0],ctx['train'][1]]\n",
    "# single_batch # [{'pixel_values':xx, 'labels':yy},{'pixel_values':xxx, 'labels':yyy}]\n",
    "# data_collator = transformers.DefaultDataCollator()\n",
    "# data_collator(single_batch) # [{'pixel_values':xx, 'labels':yy},{'pixel_values':xxx, 'labels':yyy}] --> {'pixel_values':[xx,xxx], 'labels':[yy,yyy]}\n",
    "# model.to(\"cpu\")\n",
    "# model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultDataCollator(return_tensors='pt')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = transformers.DefaultDataCollator()\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits,axis=1)\n",
    "    predictions_scores = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n",
    "    acc = evaluate.load(\"accuracy\")\n",
    "    rec = evaluate.load(\"recall\")\n",
    "    roc_auc = evaluate.load(\"roc_auc\")\n",
    "    dct1 = acc.compute(predictions = predictions, references = labels) # {'accuracy':???}\n",
    "    dct2 = rec.compute(predictions = predictions, references = labels) # {'recall':???}\n",
    "    dct3 = roc_auc.compute(prediction_scores = predictions_scores, references = labels) # {'roc_auc':???}\n",
    "    return dct1|dct2|dct3# {'accuracy':???, 'recall':???, 'roc_auc':???}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:28, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671200</td>\n",
       "      <td>0.669483</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.346690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>0.612094</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.634871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.583503</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.572888</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.6141141653060913, metrics={'train_runtime': 29.0371, 'train_samples_per_second': 137.755, 'train_steps_per_second': 2.066, 'total_flos': 8.103429948063744e+16, 'train_loss': 0.6141141653060913, 'epoch': 3.8095238095238093})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"asdf\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ctx[\"train\"].select(range(1000)),\n",
    "    eval_dataset=ctx[\"train\"].select(range(1000,1500)),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step4: Prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/250 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.14711462,  0.28146246],\n",
       "       [-0.0999002 ,  0.31734663],\n",
       "       [-0.13772886,  0.21717918],\n",
       "       ...,\n",
       "       [-0.10952485,  0.2599906 ],\n",
       "       [-0.08912332,  0.41566697],\n",
       "       [-0.13212559,  0.30518785]], dtype=float32), label_ids=None, metrics={'test_runtime': 4.4363, 'test_samples_per_second': 901.655, 'test_steps_per_second': 56.353})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = trainer.predict(ctx['test'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60553384, 0.6028243 , 0.58780724, ..., 0.59134185, 0.6235844 ,\n",
       "       0.6076187 ], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out.predictions\n",
    "has_cactus = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n",
    "has_cactus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000940378805c44108d287872b2f04ce.jpg</td>\n",
       "      <td>0.605534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017242f54ececa4512b4d7937d1e21e.jpg</td>\n",
       "      <td>0.602824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ee6d8564003107853118ab87df407.jpg</td>\n",
       "      <td>0.587807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002e175c3c1e060769475f52182583d0.jpg</td>\n",
       "      <td>0.561108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036e44a7e8f7218e9bc7bf8137e4943.jpg</td>\n",
       "      <td>0.578930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>ffaafd0c9f2f0e73172848463bc2e523.jpg</td>\n",
       "      <td>0.612775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>ffae37344310a1549162493237d25d3f.jpg</td>\n",
       "      <td>0.650841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>ffbd469c56873d064326204aac546e0d.jpg</td>\n",
       "      <td>0.591342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>ffcb76b7d47f29ece11c751e5f763f52.jpg</td>\n",
       "      <td>0.623584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>fffed17d1a8e0433a934db518d7f532c.jpg</td>\n",
       "      <td>0.607619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  has_cactus\n",
       "0     000940378805c44108d287872b2f04ce.jpg    0.605534\n",
       "1     0017242f54ececa4512b4d7937d1e21e.jpg    0.602824\n",
       "2     001ee6d8564003107853118ab87df407.jpg    0.587807\n",
       "3     002e175c3c1e060769475f52182583d0.jpg    0.561108\n",
       "4     0036e44a7e8f7218e9bc7bf8137e4943.jpg    0.578930\n",
       "...                                    ...         ...\n",
       "3995  ffaafd0c9f2f0e73172848463bc2e523.jpg    0.612775\n",
       "3996  ffae37344310a1549162493237d25d3f.jpg    0.650841\n",
       "3997  ffbd469c56873d064326204aac546e0d.jpg    0.591342\n",
       "3998  ffcb76b7d47f29ece11c751e5f763f52.jpg    0.623584\n",
       "3999  fffed17d1a8e0433a934db518d7f532c.jpg    0.607619\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv['has_cactus']= has_cactus\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step1 ~ Step4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/17500 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 17500/17500 [00:00<00:00, 63327.18 examples/s]\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 87028.23 examples/s]\n",
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:27, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.662976</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.753990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>0.621370</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.997312</td>\n",
       "      <td>0.866389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.615200</td>\n",
       "      <td>0.598107</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>0.589067</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"./data/train.csv\")\n",
    "test_csv = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "#---#\n",
    "# Step1: Data\n",
    "ctx_train = datasets.Dataset.from_pandas(train_csv)\n",
    "ctx_test = datasets.Dataset.from_pandas(test_csv).remove_columns(['has_cactus'])\n",
    "ctx_train = ctx_train.map(lambda example: {'path': \"./data/train/\" + example['id']})\n",
    "ctx_test = ctx_test.map(lambda example: {'path': \"./data/test/\" + example['id']})\n",
    "ctx = datasets.DatasetDict({\n",
    "    'train':ctx_train,\n",
    "    'test':ctx_test\n",
    "})\n",
    "compose = torchvision.transforms.Compose([\n",
    "    lambda path: PIL.Image.open(path),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224,224))\n",
    "])\n",
    "def w_trans(examples):\n",
    "    # train: examples = {'id':[xx,xxx,....], 'has_cactus':[yy,yyy,...], 'path':[zz,zzz,...]}\n",
    "    # train: examples = {'id':[xx,xxx,....], 'path':[zz,zzz,...]}\n",
    "    dct = dict()\n",
    "    dct['pixel_values'] = torch.stack(list(map(compose, examples['path'])))\n",
    "    try: \n",
    "        dct['labels']= torch.tensor(examples['has_cactus'])\n",
    "    except:\n",
    "        pass\n",
    "    return dct \n",
    "ctx = ctx.with_transform(w_trans)\n",
    "# Step2: Model\n",
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    \"microsoft/resnet-50\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "# Step3: Train\n",
    "data_collator = transformers.DefaultDataCollator()\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits,axis=1)\n",
    "    predictions_scores = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n",
    "    acc = evaluate.load(\"accuracy\")\n",
    "    rec = evaluate.load(\"recall\")\n",
    "    roc_auc = evaluate.load(\"roc_auc\")\n",
    "    dct1 = acc.compute(predictions = predictions, references = labels) # {'accuracy':???}\n",
    "    dct2 = rec.compute(predictions = predictions, references = labels) # {'recall':???}\n",
    "    dct3 = roc_auc.compute(prediction_scores = predictions_scores, references = labels) # {'roc_auc':???}\n",
    "    return dct1|dct2|dct3# {'accuracy':???, 'recall':???, 'roc_auc':???}\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"asdf\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"roc_auc\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ctx[\"train\"].select(range(1000)),\n",
    "    eval_dataset=ctx[\"train\"].select(range(1000,1500)),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "# Step4: Prediction\n",
    "out = trainer.predict(ctx['test'])\n",
    "logits = out.predictions\n",
    "has_cactus = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n",
    "test_csv['has_cactus']= has_cactus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. \b자유로운 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step1: Datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"./data/train.csv\")\n",
    "test_csv = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "train_csv2 = pd.read_csv(\"./data/train.csv\")\n",
    "test_csv2 = pd.read_csv(\"./data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv2['path'] = ['./data/train/'+l for l in train_csv.id]\n",
    "test_csv2['path'] = ['./data/test/'+l for l in test_csv.id]\n",
    "train_csv2 = train_csv2.loc[:,['has_cactus','path']]\n",
    "test_csv2 = test_csv2.loc[:,['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['has_cactus', 'path'],\n",
       "        num_rows: 17500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['path'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = datasets.DatasetDict(\n",
    "    {\n",
    "        'train': datasets.Dataset.from_pandas(train_csv2),\n",
    "        'test':datasets.Dataset.from_pandas(test_csv2)\n",
    "    }\n",
    ")\n",
    "ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step2~3 과정의 간보기*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    \"microsoft/resnet-50\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'has_cactus': 1,\n",
       "  'path': './data/train/0004be2cfeaba1c0361d39e2b000257b.jpg'},\n",
       " {'has_cactus': 1,\n",
       "  'path': './data/train/000c8a36845c0208e833c79c1bffedd1.jpg'}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch =  [ctx['train'][0], ctx['train'][1]]\n",
    "single_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = torchvision.transforms.Compose([\n",
    "    lambda path: PIL.Image.open(path),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224,224))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(single_batch):\n",
    "    dct = dict()\n",
    "    dct['pixel_values'] = torch.stack([compose(o['path']) for o in single_batch])\n",
    "    try: \n",
    "        dct['labels'] = torch.tensor([o['has_cactus'] for o in single_batch])\n",
    "    except:\n",
    "        pass\n",
    "    return dct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutputWithNoAttention(loss=tensor(0.6771, grad_fn=<NllLossBackward0>), logits=tensor([[-0.0403,  0.0007],\n",
       "        [-0.0529, -0.0292]], grad_fn=<AddmmBackward0>), hidden_states=None)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**collate_fn(single_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step1~4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:27, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.698900</td>\n",
       "      <td>0.686095</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.873656</td>\n",
       "      <td>0.345493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.609499</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.598909</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"./data/train.csv\")\n",
    "test_csv = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "train_csv2 = pd.read_csv(\"./data/train.csv\")\n",
    "test_csv2 = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "#---#\n",
    "# Step1: Data\n",
    "train_csv2['path'] = ['./data/train/'+l for l in train_csv.id]\n",
    "test_csv2['path'] = ['./data/test/'+l for l in test_csv.id]\n",
    "train_csv2 = train_csv2.loc[:,['has_cactus','path']]\n",
    "test_csv2 = test_csv2.loc[:,['path']]\n",
    "ctx = datasets.DatasetDict(\n",
    "    {\n",
    "        'train': datasets.Dataset.from_pandas(train_csv2),\n",
    "        'test':datasets.Dataset.from_pandas(test_csv2)\n",
    "    }\n",
    ")\n",
    "# Step2: Model\n",
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    \"microsoft/resnet-50\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "# Step3: Train\n",
    "def collate_fn(single_batch):\n",
    "    dct = dict()\n",
    "    dct['pixel_values'] = torch.stack([compose(o['path']) for o in single_batch])\n",
    "    try: \n",
    "        dct['labels'] = torch.tensor([o['has_cactus'] for o in single_batch])\n",
    "    except:\n",
    "        pass\n",
    "    return dct \n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits,axis=1)\n",
    "    predictions_scores = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n",
    "    acc = evaluate.load(\"accuracy\")\n",
    "    rec = evaluate.load(\"recall\")\n",
    "    roc_auc = evaluate.load(\"roc_auc\")\n",
    "    dct1 = acc.compute(predictions = predictions, references = labels) # {'accuracy':???}\n",
    "    dct2 = rec.compute(predictions = predictions, references = labels) # {'recall':???}\n",
    "    dct3 = roc_auc.compute(prediction_scores = predictions_scores, references = labels) # {'roc_auc':???}\n",
    "    return dct1|dct2|dct3# {'accuracy':???, 'recall':???, 'roc_auc':???}\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"asdf\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"roc_auc\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=ctx[\"train\"].select(range(1000)),\n",
    "    eval_dataset=ctx[\"train\"].select(range(1000,1500)),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "# Step4: Prediction\n",
    "out = trainer.predict(ctx['test'])\n",
    "logits = out.predictions\n",
    "has_cactus = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n",
    "test_csv['has_cactus']= has_cactus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1. 작년강의노트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<https://guebin.github.io/MP2023/> -- tabular data 분석 위주의 수업"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
