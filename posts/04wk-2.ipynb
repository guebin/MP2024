{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"04wk-2: 감성분석 파고들기 (2)\"\n",
    "author: \"최규빈\"\n",
    "date: \"09/27/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/02wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-xZ2p62reZCCgZsyMQLsOqY&si=bHkFTktvJIGoD0ni >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch # 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 이전시간 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이전시간의 내용중 이번시간에 기억할것들을 요약 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `DatasetDict`: 임의의 자료에 대한 `DatasetDict` 오브젝트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'text': [\n",
    "        \"I prefer making decisions based on logic and objective facts.\",\n",
    "        \"I always consider how others might feel when making a decision.\",\n",
    "        \"Data and analysis drive most of my decisions.\",\n",
    "        \"I rely on my empathy and personal values to guide my choices.\"\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    'text': [\n",
    "        \"I find it important to weigh all the pros and cons logically.\",\n",
    "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
    "    ],\n",
    "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "train_data = datasets.Dataset.from_dict(train_dict)\n",
    "test_data = datasets.Dataset.from_dict(test_dict)\n",
    "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `DatasetDict`: 아래의 코드도 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I prefer making decisions based on logic and objective facts.',\n",
       " 'I always consider how others might feel when making a decision.',\n",
       " 'Data and analysis drive most of my decisions.',\n",
       " 'I rely on my empathy and personal values to guide my choices.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "나의데이터['train']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `토크나이저`: 토크나이저는 \"`Str` $\\to$ `Dict`\" 인 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `토크나이저`: 토크나이저의 \"Str $\\to$ Dict\" 인 함수는 배치처리가 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], [101, 1045, 2467, 5136, 2129, 2500, 2453, 2514, 2043, 2437, 1037, 3247, 1012, 102], [101, 2951, 1998, 4106, 3298, 2087, 1997, 2026, 6567, 1012, 102], [101, 1045, 11160, 2006, 2026, 26452, 1998, 3167, 5300, 2000, 5009, 2026, 9804, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능은 많은 파라메터를 포함하고 있는 어떠한 물체이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능의 파라메터는 변화할 수 있으며, loss가 더 작은쪽으로 파라메터를 변화시키는 과정을 \"학습\"이라고 부른다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능은 \"`**Dict` $\\to$ `transformers.modeling_outputs.SequenceClassifierOutput`\"인 함수이다. 그런데 쓰기 까다롭다.\n",
    "\n",
    "- `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`, `attention_mask`) \n",
    "- `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`. 따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n",
    "- `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "인공지능 = model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#` 입력예시1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1083,  0.0203]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(\n",
    "    **{\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]) # 생략가능\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#` 입력예시2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6309, grad_fn=<NllLossBackward0>), logits=tensor([[-0.1083,  0.0203]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(\n",
    "    **{\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), # 생략가능\n",
    "        'labels': torch.tensor([1]) # 생략가능\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능의 출력결과 \"`transformers.modeling_outputs.SequenceClassifierOutput`\" 에서 유의미한 정보를 추출하는 방법\n",
    "\n",
    "- `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`, `attention_mask`) \n",
    "- `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`. 따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n",
    "- `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 데이터전처리하기2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 아래코드를 파고들어보자. \n",
    "\n",
    "```Python\n",
    "def 데이터전처리하기2(examples):\n",
    "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `examples['text']`의 쓰임으로 유추해본결과 examples에 가정된 입력의 형태?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I prefer making decisions based on logic and objective facts.',\n",
       " 'I always consider how others might feel when making a decision.',\n",
       " 'Data and analysis drive most of my decisions.',\n",
       " 'I rely on my empathy and personal values to guide my choices.']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I prefer making decisions based on logic and objective facts.'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 개념1: Hugging Face의 `datasets` 라이브러리에서 제공하는 `datasets.dataset_dict.DatasetDict`은, 요소들의 변환에 특화된 `map`이라는 메소드가(=함수가) 내장되어있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'text': [\n",
    "        \"I prefer making decisions based on logic and objective facts.\",\n",
    "        \"I always consider how others might feel when making a decision.\",\n",
    "        \"Data and analysis drive most of my decisions.\",\n",
    "        \"I rely on my empathy and personal values to guide my choices.\"\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    'text': [\n",
    "        \"I find it important to weigh all the pros and cons logically.\",\n",
    "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
    "    ],\n",
    "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "train_data = datasets.Dataset.from_dict(train_dict)\n",
    "test_data = datasets.Dataset.from_dict(test_dict)\n",
    "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.dataset_dict.DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.dataset_dict.DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0m나의데이터\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwith_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatched\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_from_cache_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_file_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_nullable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_proc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdesc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DatasetDict'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Apply a function to all the elements in the table (individually or in batches)\n",
       "and update the table (if function does updated examples).\n",
       "The transformation is applied to all the datasets of the dataset dictionary.\n",
       "\n",
       "Args:\n",
       "    function (`callable`): with one of the following signature:\n",
       "        - `function(example: Dict[str, Any]) -> Dict[str, Any]` if `batched=False` and `with_indices=False`\n",
       "        - `function(example: Dict[str, Any], indices: int) -> Dict[str, Any]` if `batched=False` and `with_indices=True`\n",
       "        - `function(batch: Dict[str, List]) -> Dict[str, List]` if `batched=True` and `with_indices=False`\n",
       "        - `function(batch: Dict[str, List], indices: List[int]) -> Dict[str, List]` if `batched=True` and `with_indices=True`\n",
       "\n",
       "        For advanced usage, the function can also return a `pyarrow.Table`.\n",
       "        Moreover if your function returns nothing (`None`), then `map` will run your function and return the dataset unchanged.\n",
       "\n",
       "    with_indices (`bool`, defaults to `False`):\n",
       "        Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.\n",
       "    with_rank (`bool`, defaults to `False`):\n",
       "        Provide process rank to `function`. Note that in this case the\n",
       "        signature of `function` should be `def function(example[, idx], rank): ...`.\n",
       "    input_columns (`[Union[str, List[str]]]`, *optional*, defaults to `None`):\n",
       "        The columns to be passed into `function` as\n",
       "        positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.\n",
       "    batched (`bool`, defaults to `False`):\n",
       "        Provide batch of examples to `function`.\n",
       "    batch_size (`int`, *optional*, defaults to `1000`):\n",
       "        Number of examples per batch provided to `function` if `batched=True`,\n",
       "        `batch_size <= 0` or `batch_size == None` then provide the full dataset as a single batch to `function`.\n",
       "    drop_last_batch (`bool`, defaults to `False`):\n",
       "        Whether a last batch smaller than the batch_size should be\n",
       "        dropped instead of being processed by the function.\n",
       "    remove_columns (`[Union[str, List[str]]]`, *optional*, defaults to `None`):\n",
       "        Remove a selection of columns while doing the mapping.\n",
       "        Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding\n",
       "        columns with names in `remove_columns`, these columns will be kept.\n",
       "    keep_in_memory (`bool`, defaults to `False`):\n",
       "        Keep the dataset in memory instead of writing it to a cache file.\n",
       "    load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):\n",
       "        If a cache file storing the current computation from `function`\n",
       "        can be identified, use it instead of recomputing.\n",
       "    cache_file_names (`[Dict[str, str]]`, *optional*, defaults to `None`):\n",
       "        Provide the name of a path for the cache file. It is used to store the\n",
       "        results of the computation instead of the automatically generated cache file name.\n",
       "        You have to provide one `cache_file_name` per dataset in the dataset dictionary.\n",
       "    writer_batch_size (`int`, default `1000`):\n",
       "        Number of rows per write operation for the cache file writer.\n",
       "        This value is a good trade-off between memory usage during the processing, and processing speed.\n",
       "        Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.\n",
       "    features (`[datasets.Features]`, *optional*, defaults to `None`):\n",
       "        Use a specific [`Features`] to store the cache file\n",
       "        instead of the automatically generated one.\n",
       "    disable_nullable (`bool`, defaults to `False`):\n",
       "        Disallow null values in the table.\n",
       "    fn_kwargs (`Dict`, *optional*, defaults to `None`):\n",
       "        Keyword arguments to be passed to `function`\n",
       "    num_proc (`int`, *optional*, defaults to `None`):\n",
       "        Number of processes for multiprocessing. By default it doesn't\n",
       "        use multiprocessing.\n",
       "    desc (`str`, *optional*, defaults to `None`):\n",
       "        Meaningful description to be displayed alongside with the progress bar while mapping examples.\n",
       "\n",
       "Example:\n",
       "\n",
       "```py\n",
       ">>> from datasets import load_dataset\n",
       ">>> ds = load_dataset(\"rotten_tomatoes\")\n",
       ">>> def add_prefix(example):\n",
       "...     example[\"text\"] = \"Review: \" + example[\"text\"]\n",
       "...     return example\n",
       ">>> ds = ds.map(add_prefix)\n",
       ">>> ds[\"train\"][0:3][\"text\"]\n",
       "['Review: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       " 'Review: the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .',\n",
       " 'Review: effective but too-tepid biopic']\n",
       "\n",
       "# process a batch of examples\n",
       ">>> ds = ds.map(lambda example: tokenizer(example[\"text\"]), batched=True)\n",
       "# set number of processors\n",
       ">>> ds = ds.map(add_prefix, num_proc=4)\n",
       "```\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/dataset_dict.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "나의데이터.map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당장필요한내용: `datasets.dataset_dict.DatasetDict.map()`은 (1) `function`을 입력으로 받는데, (2) `function`은 Dict를 입력으로 받고 Dict를 출력하는 함수이어야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1730.14 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1012.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'I prefer making decisions based on logic and objective facts.',\n",
       "  'label': 0},\n",
       " {'text': 'I prefer making decisions based on logic and objective facts.',\n",
       "  'label': 0,\n",
       "  'dummy': '메롱'})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "나의데이터['train'][0], 전처리된나의데이터['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I prefer making decisions based on logic and objective facts.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': 'I always consider how others might feel when making a decision.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n",
      "{'text': 'Data and analysis drive most of my decisions.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': 'I rely on my empathy and personal values to guide my choices.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['train']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I find it important to weigh all the pros and cons logically.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': \"When making decisions, I prioritize harmony and people's emotions.\", 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['test']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1071.82 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 665.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy':'메롱', 'label2': '사고형(T)'} if x['label'] == 0 else {'dummy':'메롱','label2': '감정형(F)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I prefer making decisions based on logic and objective facts.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': 'I always consider how others might feel when making a decision.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n",
      "{'text': 'Data and analysis drive most of my decisions.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': 'I rely on my empathy and personal values to guide my choices.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['train']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I find it important to weigh all the pros and cons logically.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': \"When making decisions, I prioritize harmony and people's emotions.\", 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['test']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 데이터전처리하기2(examples):\n",
    "    return 데이터전처리하기1(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 893.02 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 569.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(데이터전처리하기2,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I prefer making decisions based on logic and objective facts.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  1045,\n",
       "  9544,\n",
       "  2437,\n",
       "  6567,\n",
       "  2241,\n",
       "  2006,\n",
       "  7961,\n",
       "  1998,\n",
       "  7863,\n",
       "  8866,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리된나의데이터['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 데이터콜렉터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||주어진자료| $\\overset{tokenizer,map}{\\Longrightarrow}$ 전처리된자료|$\\overset{datacollector}{\\Longrightarrow}$더전처리된자료|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Dict의 Keys |`text`,`label`| `input_ids`, `attention_mask`, `label`| `input_ids`, `attention_mask`, `labels`| \n",
    "|자료의형태|텍스트,라벨|숫자화 O, 행렬화 X  | 숫자화 O, 행렬화 O\n",
    "|`torch.tensor`|- | X | O | \n",
    "|미니배치| - | X| O| \n",
    "|패딩/동적패딩| - | X | O| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터콜렉터 사용방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m   \u001b[0m데이터콜렉터\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m        DataCollatorWithPadding\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert/distilbert-bas <...> e, special=True),\n",
       "           }, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/data/data_collator.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Data collator that will dynamically pad the inputs received.\n",
       "\n",
       "Args:\n",
       "    tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
       "        The tokenizer used for encoding the data.\n",
       "    padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
       "        Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
       "        among:\n",
       "\n",
       "        - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
       "          sequence is provided).\n",
       "        - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
       "          acceptable input length for the model if that argument is not provided.\n",
       "        - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
       "    max_length (`int`, *optional*):\n",
       "        Maximum length of the returned list and optionally padding length (see above).\n",
       "    pad_to_multiple_of (`int`, *optional*):\n",
       "        If set will pad the sequence to a multiple of the provided value.\n",
       "\n",
       "        This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
       "        7.5 (Volta).\n",
       "    return_tensors (`str`, *optional*, defaults to `\"pt\"`):\n",
       "        The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\"."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저,return_tensors='pt')\n",
    "데이터콜렉터?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당장필요한것: 입력은 `[딕셔너리, 딕셔너리, 딕셔너리, ...]` 의 형태 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045,  102,    0],\n",
       "        [ 101, 1045, 9544,  102]]), 'attention_mask': tensor([[1, 1, 1, 0],\n",
       "        [1, 1, 1, 1]]), 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "데이터콜렉터(\n",
    "    [\n",
    "        dict(label=0,input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
    "        dict(label=0,input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7409, grad_fn=<NllLossBackward0>), logits=tensor([[-0.1381, -0.0306],\n",
       "        [-0.1232, -0.0442]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**데이터콜렉터(\n",
    "    [\n",
    "        dict(label=0,input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
    "        dict(label=0,input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `accuracy.compute`의 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3333333333333333}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.compute(references=[0, 0, 0], predictions=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 함수내용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def 평가하기(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     accuracy = evaluate.load(\"accuracy\")\n",
    "#     return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 평가하기(eval_pred):\n",
    "    계산된숫자들_로짓, 실제정답 = eval_pred\n",
    "    인공지능의예측 = np.argmax(계산된숫자들_로짓, axis=1)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    return accuracy.compute(predictions=인공지능의예측, references=실제정답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `평가하기` 함수는 `eval_dataset`에 적용됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 트레이너 세부지침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "트레이너세부지침 = transformers.TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2, # 전체문제세트를 2번 공부하라..\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\", \n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note} \n",
    "\n",
    "### 옵션 설명:\n",
    "\n",
    "1. **`output_dir=\"my_awesome_model\"`**:\n",
    "   - 학습된 모델과 관련 파일(예: 체크포인트, 로그 등)이 저장될 디렉토리 경로를 지정합니다.\n",
    "\n",
    "2. **`learning_rate=2e-5`**:\n",
    "   - 학습률(learning rate)을 설정합니다. 모델이 가중치를 업데이트할 때 사용하는 스텝 크기로, 작은 값일수록 학습 속도가 느려지지만 안정성이 높습니다.\n",
    "\n",
    "3. **`per_device_train_batch_size=16`**:\n",
    "   - **훈련** 시, 각 GPU 또는 CPU 디바이스에서 사용할 배치 크기를 설정합니다. 이 경우 각 디바이스에서 16개의 샘플을 한 번에 처리합니다.\n",
    "\n",
    "4. **`per_device_eval_batch_size=16`**:\n",
    "   - **평가** 시, 각 GPU 또는 CPU 디바이스에서 사용할 배치 크기를 설정합니다. 평가 시에는 훈련과 같은 배치 크기를 사용하는 것이 일반적입니다.\n",
    "\n",
    "5. **`num_train_epochs=2`**:\n",
    "   - 전체 훈련 데이터셋을 몇 번 반복(에포크)할지 설정합니다. 여기서는 데이터셋 전체를 2번 학습하게 됩니다.\n",
    "\n",
    "6. **`weight_decay=0.01`**:\n",
    "   - 가중치 감쇠(weight decay)를 적용하여 모델의 가중치가 지나치게 커지지 않도록 제어합니다. 0.01의 값은 가중치가 조금씩 감소하게 하여 모델의 일반화 성능을 높이는 데 도움을 줄 수 있습니다.\n",
    "\n",
    "7. **`eval_strategy=\"epoch\"`**:\n",
    "   - 평가 전략을 설정합니다. 여기서는 `epoch`으로 설정되어, 매 에포크가 끝날 때마다 평가가 진행됩니다.\n",
    "   - 다른 값으로는 `steps` (일정한 스텝마다 평가) 등이 있습니다.\n",
    "\n",
    "8. **`save_strategy=\"epoch\"`**:\n",
    "   - 모델을 언제 저장할지 설정합니다. `epoch`으로 설정되면, 매 에포크가 끝날 때마다 체크포인트를 저장합니다.\n",
    "   - 다른 값으로는 `steps` (일정한 스텝마다 저장) 등이 있습니다.\n",
    "\n",
    "9. **`load_best_model_at_end=True`**:\n",
    "   - 학습이 끝난 후, 가장 성능이 좋았던 체크포인트를 불러옵니다. 평가 지표에 따라 가장 성능이 좋았던 모델을 자동으로 불러와 최종 모델로 사용하게 됩니다.\n",
    "\n",
    "10. **`push_to_hub=False`**:\n",
    "    - 모델 학습이 끝난 후 Hugging Face Hub에 모델을 업로드할지 여부를 설정합니다. `False`로 설정하면 업로드하지 않습니다.\n",
    "    - `True`로 설정하면 모델과 관련된 파일들이 Hugging Face Hub에 업로드되어 다른 사람들과 공유할 수 있습니다.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` lr = 학습률 = 답이 틀렸을 경우 혼내는 정도\n",
    "\n",
    "- 정확한 느낌은 경사하강법을 이해해야함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 트레이너"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 트레이너를 이용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 13:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.233206</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3126, training_loss=0.20330691871472223, metrics={'train_runtime': 790.8461, 'train_samples_per_second': 63.223, 'train_steps_per_second': 3.953, 'total_flos': 6556904415524352.0, 'train_loss': 0.20330691871472223, 'epoch': 2.0})"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너 = transformers.Trainer(\n",
    "    model=인공지능,\n",
    "    args=트레이너세부지침,\n",
    "    train_dataset=전처리된데이터['train'],\n",
    "    eval_dataset=전처리된데이터['test'],\n",
    "    tokenizer=토크나이저, # 왜 필요하지??\n",
    "    data_collator=데이터콜렉터,\n",
    "    compute_metrics=평가하기,\n",
    ")\n",
    "트레이너.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562.5"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25000 / 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3126"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1563 * 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능이 똑똑해졌을까? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0230,  0.0279,  0.0239,  ...,  0.0085, -0.0062, -0.0143],\n",
       "        [ 0.0084,  0.0007, -0.0097,  ...,  0.0189, -0.0008,  0.0304]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight # 숫자들은 바뀌어 있음.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0133,  0.0017,  0.0303,  ...,  0.0005,  0.0322, -0.0122],\n",
       "        [-0.0038,  0.0010,  0.0165,  ..., -0.0163, -0.0115, -0.0138],\n",
       "        [ 0.0033, -0.0210, -0.0019,  ...,  0.0014,  0.0100, -0.0486],\n",
       "        ...,\n",
       "        [-0.0043, -0.0345,  0.0094,  ...,  0.0350, -0.0182, -0.0110],\n",
       "        [ 0.0078, -0.0360, -0.0012,  ...,  0.0021,  0.0170, -0.0120],\n",
       "        [-0.0162,  0.0133, -0.0184,  ..., -0.0165,  0.0240,  0.0200]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.pre_classifier.weight # 숫자들이 바뀌어 있음.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.to(\"cpu\") # 인공지능이 지금 GPU에서 학습했거든요.. 다시 CPU로 내려주는 작업이 필요합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 입력정보에 영화에 대한 부정적 평가를 넣는다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  3185,  2001,  1037,  4121, 10520,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "입력정보_원시텍스트 = \"This movie was a huge disappointment.\"\n",
    "정리된숫자_토큰화된자료 = 토크나이저(입력정보_원시텍스트,truncation=True,return_tensors='pt')\n",
    "정리된숫자_토큰화된자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 2.2626, -2.1934]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**정리된숫자_토큰화된자료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.262645 , -2.1934297]], dtype=float32)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "계산된숫자_로짓 = 인공지능(**정리된숫자_토큰화된자료).logits.detach().numpy()\n",
    "계산된숫자_로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9885254 , 0.01147464]], dtype=float32)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "출력정보_확률 = np.exp(계산된숫자_로짓) / np.exp(계산된숫자_로짓).sum()\n",
    "출력정보_확률 # 0일확률, 1일확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "출력정보_확률.argmax() # 부정적 영화평가에 대한 인공지능의 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 입력정보에 영화에 대한 긍정적 평가를 넣는다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2001,  1037, 17743,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "입력정보_원시텍스트 = \"This was a masterpiece.\"\n",
    "정리된숫자_토큰화된자료 = 토크나이저(입력정보_원시텍스트,truncation=True,return_tensors='pt')\n",
    "정리된숫자_토큰화된자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.1035,  1.6938]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**정리된숫자_토큰화된자료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.103469 ,  1.6938232]], dtype=float32)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "계산된숫자_로짓 = 인공지능(**정리된숫자_토큰화된자료).logits.detach().numpy()\n",
    "계산된숫자_로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0219393, 0.9780607]], dtype=float32)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "출력정보_확률 = np.exp(계산된숫자_로짓) / np.exp(계산된숫자_로짓).sum()\n",
    "출력정보_확률 # 0일확률, 1일확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "출력정보_확률.argmax()\n",
    "계산된숫자_로짓.argmax() # 부정적 영화평가에 대한 인공지능의 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 강인공지능? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ref: <https://zdnet.co.kr/view/?no=20160622145838>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9885253310203552}]\n",
      "[{'label': 'LABEL_1', 'score': 0.978060781955719}]\n"
     ]
    }
   ],
   "source": [
    "강인공지능 = transformers.pipeline(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n",
    "print(강인공지능(\"This movie was a huge disappointment.\"))\n",
    "print(강인공지능(\"This was a masterpiece.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
