{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"04wk-2: 감성분석 파고들기 (2)\"\n",
    "author: \"최규빈\"\n",
    "date: \"09/27/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/04wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{<video https://youtu.be/playlist?list=PLQqh36zP38-yH7aA3RY7GNf1qNIgU6CDs&si=e4-tQHb8cD0FhrUW >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch # 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 이전시간 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이전시간의 내용중 이번시간에 기억할것들을 요약 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `DatasetDict`: 임의의 자료에 대한 `DatasetDict` 오브젝트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'text': [\n",
    "        \"I prefer making decisions based on logic and objective facts.\",\n",
    "        \"I always consider how others might feel when making a decision.\",\n",
    "        \"Data and analysis drive most of my decisions.\",\n",
    "        \"I rely on my empathy and personal values to guide my choices.\"\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    'text': [\n",
    "        \"I find it important to weigh all the pros and cons logically.\",\n",
    "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
    "    ],\n",
    "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.Dataset.from_dict(train_dict)\n",
    "test_data = datasets.Dataset.from_dict(test_dict)\n",
    "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `토크나이저`: 토크나이저는 \"`Str` $\\to$ `Dict`\" 인 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `토크나이저`: 토크나이저의 \"`Str` $\\to$ `Dict`\" 인 함수는 배치처리가 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], [101, 1045, 2467, 5136, 2129, 2500, 2453, 2514, 2043, 2437, 1037, 3247, 1012, 102], [101, 2951, 1998, 4106, 3298, 2087, 1997, 2026, 6567, 1012, 102], [101, 1045, 11160, 2006, 2026, 26452, 1998, 3167, 5300, 2000, 5009, 2026, 9804, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능은 많은 파라메터를 포함하고 있는 어떠한 물체이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0124, -0.0124, -0.0205,  ...,  0.0244, -0.0019,  0.0045],\n",
       "        [ 0.0073, -0.0218, -0.0173,  ...,  0.0125,  0.0105,  0.0278]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능 = model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "인공지능.classifier.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능의 파라메터는 변화할 수 있으며, loss가 더 작은쪽으로 파라메터를 변화시키는 과정을 \"학습\"이라고 부른다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능은 \"`**Dict` $\\to$ `transformers.modeling_outputs.SequenceClassifierOutput`\"인 함수이다. 그런데 쓰기 까다롭다.\n",
    "\n",
    "- `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`, `attention_mask`) \n",
    "- `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`. 따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n",
    "- `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#` 인공지능의 입력예시1 -- 텐서형으로 정리된 텍스트자료만 있는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "인공지능입력1 = {\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]) # 생략가능\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.0177, 0.0286],\n",
       "        [0.0490, 0.0451]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**인공지능입력1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#` 인공지능의 입력예시2 -- 텐서형으로 정리된 텍스트자료와 `labels`이 같이 있는경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "인공지능입력2 = {\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]), # 생략가능\n",
    "        'labels': torch.tensor([1, 0]) # 생략가능\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6895, grad_fn=<NllLossBackward0>), logits=tensor([[0.0177, 0.0286],\n",
       "        [0.0490, 0.0451]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**인공지능입력2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능의 출력결과^[`transformers.modeling_outputs.SequenceClassifierOutput` 자료형을 가짐] 에서 확률/예측값을 추출하는 방법 \n",
    "\n",
    "- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 확률 $\\to$ 인공지능의예측\n",
    "- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 인공지능의예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제1:** 인공지능의 출력결과에서 인공지능의 예측값을 계산하자. -- 로짓 $\\to$ 인공지능의예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0177, 0.0286],\n",
       "        [0.0490, 0.0451]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능출력 = 인공지능(**인공지능입력2)\n",
    "로짓 = 인공지능출력.logits\n",
    "로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "로짓.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제2:** 인공지능의 출력결과에서 인공지능의 예측확률을 계산하자 -- 로짓 $\\to$ 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0177, 0.0286],\n",
       "        [0.0490, 0.0451]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능출력 = 인공지능(**인공지능입력2)\n",
    "로짓 = 인공지능출력.logits\n",
    "로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4973, 0.4909],\n",
       "        [0.5131, 0.4990]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(로짓) / torch.exp(로짓).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`확률게산하기`라는 함수선언하여 외의 과정을 단순화 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 확률계산하기(인공지능출력):\n",
    "    로짓 = 인공지능출력.logits\n",
    "    return torch.exp(로짓) / torch.exp(로짓).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4973, 0.4909],\n",
       "        [0.5131, 0.4990]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**인공지능입력2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 데이터전처리하기2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 아래코드를 파고들어보자. \n",
    "\n",
    "```Python\n",
    "def 데이터전처리하기2(examples):\n",
    "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 입력으로 가정된 두가지 경우: (1) 토크나이징결과, (2) 토크나이징결과 + label\n",
    "\n",
    "- (2) 와 같은 형태의 입력을 정리하기 위해서는, `{'text':[...], 'label':[...]}` 이러한 형태로 정리된 자료를  `{'text':[...], 'label':[...], 'input_ids':[...], 'attention_mask':[...]}` 이러한 형태로 만들어야 하는데 이를 쉽게처리해주는 함수가 바로 `나의데이터.map()` 임. \n",
    "- `나의데이터.map()`의 도움말을 확인해본 결과 map은 (1) function 자체를 입력으로 받는데 (2) function 은 Dict를 입력으로 받고, Dict를 출력하는 함수이어야 한다는 사실을 확인할 수 있었음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 개념1: Hugging Face의 `datasets` 라이브러리에서 제공하는 `datasets.dataset_dict.DatasetDict`은, 요소들의 변환에 특화된 `map`이라는 메소드가(=함수가) 내장되어있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시1` -- 메롱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1570.02 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 1216.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda dct: {'dummy':'메롱'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I prefer making decisions based on logic and objective facts.',\n",
       " 'label': 0,\n",
       " 'dummy': '메롱'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리된나의데이터['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시2` -- Text의 length 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4/4 [00:00<00:00, 2154.79 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 1365.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda dct: {'dummy':'메롱', 'length':len(dct['text'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시2` -- 토크나이징결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1274.67 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 966.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda dct: 토크나이저(dct[\"text\"], truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I prefer making decisions based on logic and objective facts.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  1045,\n",
       "  9544,\n",
       "  2437,\n",
       "  6567,\n",
       "  2241,\n",
       "  2006,\n",
       "  7961,\n",
       "  1998,\n",
       "  7863,\n",
       "  8866,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리된나의데이터['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 데이터콜렉터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 전터리된 데이터가 인공지능은 마음에 들지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Data and analysis drive most of my decisions.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 2951, 1998, 4106, 3298, 2087, 1997, 2026, 6567, 1012, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리된나의데이터['train'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이유: 인공지능은 `torch.tensor()` 자료형을 가지며 (n,m)의 행렬로 정리된 \"묶음\" 형태의 자료형을 기대함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 자료처리과정요약 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||주어진자료| $\\overset{tokenizer,map}{\\Longrightarrow}$ 전처리된자료|$\\overset{datacollector}{\\Longrightarrow}$더전처리된자료|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Dict의 Keys |`text`,`label`| `input_ids`, `attention_mask`, `label`| `input_ids`, `attention_mask`, `labels`| \n",
    "|자료의형태|텍스트,라벨|숫자화 O, 행렬화 X  | 숫자화 O, 행렬화 O\n",
    "|`torch.tensor`|- | X | O | \n",
    "|미니배치| - | X| O| \n",
    "|패딩/동적패딩| - | X | O|\n",
    "|예측할때|강인공지능의 입력|트레이너의 입력|인공지능의 입력|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터콜렉터에서 우리가 기대하는 것:\n",
    "\n",
    "- 자료의 형태가 [Dict,Dict,Dict,Dict] 로 되어있는 경우^[`전처리된나의데이터['train']`이 이러한 형태로 되어있음] (4,??) shape 텐서의 `input_ids`, (4,??) shape 텐서의 `attention_mask`, 그리고 (4,) shape 텐서의 `labels`로 변환해줌. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터콜렉터 사용방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저, return_tensors='pt')\n",
    "# 데이터콜렉터?\n",
    "# 도움말에서 당장필요한 것: 입력형태가 [Dict, Dict, Dict, ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045,  102,    0,    0],\n",
       "        [ 101, 1045, 9544,  102,    0],\n",
       "        [ 101, 1045, 9544, 9544,  102]]), 'attention_mask': tensor([[1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1]]), 'labels': tensor([0, 1, 0])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "데이터콜렉터(\n",
    "    [\n",
    "        dict(label=0, input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
    "        dict(label=1, input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
    "        dict(label=0, input_ids=[101,1045,9544,9544,102],attention_mask=[1,1,1,1,1])\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6952, grad_fn=<NllLossBackward0>), logits=tensor([[0.0177, 0.0286],\n",
       "        [0.0384, 0.0379],\n",
       "        [0.0415, 0.0425]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**데이터콜렉터(\n",
    "    [\n",
    "        dict(label=0, input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
    "        dict(label=1, input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
    "        dict(label=0, input_ids=[101,1045,9544,9544,102],attention_mask=[1,1,1,1,1])\n",
    "        \n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `accuracy.compute`의 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.compute(predictions=[0,0,0], references=[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.compute(predictions=[1,1,1], references=[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.compute(predictions=[0,1,0], references=[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `평가하기` 함수의 내용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def 평가하기(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     accuracy = evaluate.load(\"accuracy\")\n",
    "#     return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 평가하기(eval_pred):\n",
    "    로짓, 실제정답 = eval_pred\n",
    "    인공지능의예측 = np.argmax(로짓, axis=1)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    return accuracy.compute(predictions=인공지능의예측, references=실제정답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 트레이너"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이전코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Step1 \n",
    "데이터불러오기 = datasets.load_dataset\n",
    "토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \n",
    "## Step2 \n",
    "인공지능생성하기 = transformers.AutoModelForSequenceClassification.from_pretrained\n",
    "## Step3 \n",
    "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저)\n",
    "def 평가하기(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "트레이너세부지침생성기 = transformers.TrainingArguments\n",
    "트레이너생성기 = transformers.Trainer\n",
    "## Step4 \n",
    "강인공지능생성하기 = transformers.pipeline\n",
    "#---#\n",
    "## Step1 \n",
    "데이터 = 데이터불러오기('imdb')\n",
    "전처리된데이터 = 데이터.map(lambda dct: 토크나이저(dct[\"text\"], truncation=True),batched=True)\n",
    "전처리된훈련자료, 전처리된검증자료 = 전처리된데이터['train'], 전처리된데이터['test']\n",
    "## Step2 \n",
    "torch.manual_seed(43052)\n",
    "인공지능 = 인공지능생성하기(\"distilbert/distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. 트레이너의 제1역할 -- CPU에서 GPU로.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `#` 트레이너 생성전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
       "        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요한내용1: 숫자들 = 초기숫자들\n",
    "- 중요한내용2: 숫자들이 CPU에 존재한다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능을 이용한 예측 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4642, 0.5358]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4664, 0.5336]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `#` 트레이너 생성후 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 트레이너생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step3 \n",
    "트레이너세부지침 = 트레이너세부지침생성기(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2, # 전체문제세트를 2번 공부하라..\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "트레이너 = 트레이너생성기(\n",
    "    model=인공지능,\n",
    "    args=트레이너세부지침,\n",
    "    train_dataset=전처리된훈련자료,\n",
    "    eval_dataset=전처리된검증자료,\n",
    "    tokenizer=토크나이저,\n",
    "    data_collator=데이터콜렉터,\n",
    "    compute_metrics=평가하기,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
       "        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요한내용1: 숫자들 = 초기숫자들\n",
    "- 중요한내용2: device=\"cuda:0\" // 숫자들이 GPU에 있다는 의미 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능을 이용한 예측 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4642, 0.5358]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4664, 0.5336]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 트레이너의 제1역할: 트레이너는 생성과 동시에 하는역할이 있는데, 바로 인공지능의 파라메터를 GPU에 올리는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. 트레이너의 제2역할 -- 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 트레이너의 제2역할: `트레이너.predict()` 사용가능. `트레이너.predict()`의 입력형태는 input_ids, attention_mask, label 이 존재하는 `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예제1` 트레이너를 이용한 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dict = {\n",
    "    'text': [\"This movie was a huge disappointment.\"],\n",
    "    'label': [0],\n",
    "    'input_ids': [[101, 2023, 3185, 2001, 1037, 4121, 10520, 1012, 102]],\n",
    "    'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "}\n",
    "sample_dataset = datasets.Dataset.from_dict(sample_dict)\n",
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.11731032,  0.02610314]], dtype=float32), label_ids=array([0]), metrics={'test_loss': 0.7674226760864258, 'test_model_preparation_time': 0.0009, 'test_accuracy': 0.0, 'test_runtime': 1.1868, 'test_samples_per_second': 0.843, 'test_steps_per_second': 0.843})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46420796, 0.53579204]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = np.array([[-0.11731032,  0.02610314]])\n",
    "np.exp(logits)/ np.exp(logits).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예제2` -- 트레이너를 이용하여 `train_data`, `test_data` 의 prediction 값을 구하라. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.08470809,  0.0023939 ],\n",
       "       [-0.08299972,  0.02850237],\n",
       "       [-0.06004279,  0.01801764],\n",
       "       ...,\n",
       "       [-0.02317078, -0.01451463],\n",
       "       [-0.00802051, -0.02698467],\n",
       "       [-0.03900156, -0.02573229]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.6949957609176636, 'test_model_preparation_time': 0.0009, 'test_accuracy': 0.4916, 'test_runtime': 89.9353, 'test_samples_per_second': 277.978, 'test_steps_per_second': 17.379})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(전처리된데이터['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.03815563,  0.00212397],\n",
       "       [-0.08166712, -0.00432102],\n",
       "       [-0.10371644,  0.03148611],\n",
       "       ...,\n",
       "       [-0.08171435, -0.00681646],\n",
       "       [-0.09139054,  0.01050513],\n",
       "       [-0.06704493,  0.0221498 ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.6949934363365173, 'test_model_preparation_time': 0.0009, 'test_accuracy': 0.4912, 'test_runtime': 89.8578, 'test_samples_per_second': 278.217, 'test_steps_per_second': 17.394})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(전처리된데이터['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. 트레이너의 제3역할 -- 학습 및 결과저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `#` 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 11:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.233206</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3126, training_loss=0.20330691871472223, metrics={'train_runtime': 718.1146, 'train_samples_per_second': 69.627, 'train_steps_per_second': 4.353, 'total_flos': 6556904415524352.0, 'train_loss': 0.20330691871472223, 'epoch': 2.0})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562.5"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25000 / 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3126"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1563 * 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `#` 학습후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능이 똑똑해졌을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0230,  0.0279,  0.0239,  ...,  0.0085, -0.0062, -0.0143],\n",
       "        [ 0.0084,  0.0007, -0.0097,  ...,  0.0189, -0.0008,  0.0304]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*인공지능의 파라메터 상태확인 2와 비교삿*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Parameter containing:\n",
    "tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
    "        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
    "       device='cuda:0', requires_grad=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*숫자들이 바뀐걸 확인 $\\to$ 뭔가 다른 계산결과를 준다는 의미겠지? $\\to$ 진짜 그런지 보자..*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능을 이용한 예측 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9885, 0.0115]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0219, 0.9781]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 다시 트레이너를 이용하여 `train_data`, `test_data` 의 prediction 값을 구해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.5927906 , -1.3617778 ],\n",
       "       [ 2.36449   , -2.1244614 ],\n",
       "       [ 2.1150742 , -1.9663404 ],\n",
       "       ...,\n",
       "       [-2.690494  ,  2.2624812 ],\n",
       "       [ 0.32332823, -0.05149931],\n",
       "       [-1.96404   ,  1.7741865 ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.1358911097049713, 'test_model_preparation_time': 0.0008, 'test_accuracy': 0.95244, 'test_runtime': 89.3077, 'test_samples_per_second': 279.931, 'test_steps_per_second': 17.501})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(전처리된데이터['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 2.5778208 , -2.250055  ],\n",
       "       [ 1.396875  , -1.2021751 ],\n",
       "       [ 2.1249173 , -1.9882215 ],\n",
       "       ...,\n",
       "       [-0.3729212 ,  0.34651938],\n",
       "       [ 0.19383232,  0.01419903],\n",
       "       [-1.2160491 ,  1.007748  ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.19937647879123688, 'test_model_preparation_time': 0.0008, 'test_accuracy': 0.923, 'test_runtime': 90.2744, 'test_samples_per_second': 276.933, 'test_steps_per_second': 17.314})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(전처리된데이터['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 강인공지능? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ref: <https://zdnet.co.kr/view/?no=20160622145838>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9885253310203552}]\n",
      "[{'label': 'LABEL_1', 'score': 0.978060781955719}]\n"
     ]
    }
   ],
   "source": [
    "강인공지능 = transformers.pipeline(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n",
    "print(강인공지능(\"This movie was a huge disappointment.\"))\n",
    "print(강인공지능(\"This was a masterpiece.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9885, 0.0115]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0219, 0.9781]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")]).to(\"cuda:0\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
