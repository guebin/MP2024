{
 "cells": [
  {
   "cell_type": "raw",
   "id": "52ecac9c-ae21-4bda-a584-035b13a770b3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"11wk-1: `data_collator`\"\n",
    "author: \"최규빈\"\n",
    "date: \"11/22/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ab2b6-7a21-4b07-9f64-9dd4a44b30aa",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/11wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c042875-a54c-44b0-acbf-fc9d4668237c",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca1605-636e-4f5d-a74f-7066304b501b",
   "metadata": {},
   "source": [
    "{{< video https://youtu.be/playlist?list=PLQqh36zP38-yntkaNrZmlqWVX-ineTf4k&si=xZ1WZainJuXiHheC >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fabb3-8e24-4432-87c3-f9eb1fe13980",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad4c88c-28b7-4606-aede-bec8621faa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31afc0f9-ad5d-4919-847c-9b89fcd87c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets \n",
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5da1f-df2a-45bb-958d-834bc38b9d5c",
   "metadata": {},
   "source": [
    "# 3. `data_collator` 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ce815-c1fa-4fe4-8f26-fe76ce18b199",
   "metadata": {},
   "source": [
    "## A. 외우세요 $(\\star\\star\\star)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fc221-2fac-4cc9-a40f-31fb3b4453bd",
   "metadata": {},
   "source": [
    "`-` `data_collator`를 잘 설계하는 방법: `trainer_input`과 `model`이 주어졌을때 `data_collator`는 아래의 코드가 동작하도록 설계하면 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632a929-dd2b-4db6-b724-8f3776f1a0ee",
   "metadata": {},
   "source": [
    "```Python\n",
    "trainer_input = ~~~\n",
    "model = ~~~~ \n",
    "#---#\n",
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x\n",
    ") # 이 과정에서 model이 cuda로 감 \n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "model.to(\"cpu\") # 경우에 따라 생략해야할수도있음\n",
    "model(**data_collator(single_batch))\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf0e7e-321e-4959-8d4b-79f673ab694d",
   "metadata": {},
   "source": [
    "`-` 위의 코드가 오류없이 실행되었다면 아래의 코드를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832e659-8fbe-4168-983d-54bcbb80a7b5",
   "metadata": {},
   "source": [
    "```Python\n",
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = data_collator\n",
    ")\n",
    "trainer.predict(trainer_input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c41d7d-e007-426b-a881-fc889b7e3487",
   "metadata": {},
   "source": [
    "> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0f275-2877-46b4-8120-f9c1f4020f58",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "코랩사용자의 경우 아래와 같이 wandb(Weights & Biases) 로그인을 요구하는 문제가 있습니다. \n",
    "```bash\n",
    "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
    "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
    "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
    "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
    "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n",
    "```\n",
    "이를 해결하기 위해서는 아래의 코드를 코랩처음에 실행하면 됩니다. \n",
    "\n",
    "```Python\n",
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714705b-dbb6-45a2-af96-413d827a8506",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "주의: `trainer_input`의 type이 꼭 `Dataset` 일 필요는 없다..\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e68160-763e-40b8-a69a-bf7c80fe00f6",
   "metadata": {},
   "source": [
    "## B. IMDB -- 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9d435-91bc-4bc0-8a6d-d64d08b24e01",
   "metadata": {},
   "source": [
    "ref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09eeda6-1ba4-4813-a8fc-e57a93598280",
   "metadata": {},
   "source": [
    "*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cd490d-ae86-4920-b487-79c7c45fec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████| 10/10 [00:00<00:00, 1694.39 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = datasets.load_dataset(\"guebin/imdb-tiny\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "tokenized_imdb = imdb.map(preprocess_function,batched=True)\n",
    "trainer_input = tokenized_imdb['train']\n",
    "trainer_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855c728-6a0b-4122-97a8-9df52b6679e7",
   "metadata": {},
   "source": [
    "*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0610264c-a333-4ea1-9e1d-8108817eea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26202fdf-7aca-4966-bd89-bbbf654ae759",
   "metadata": {},
   "source": [
    "*3. 데이터콜렉터: `DataCollatorWithPadding()` $\\to$ `data_collator`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87136dce-a4be-4a18-9db6-8f346a989d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ec4a1-3b20-49ad-a943-e595550eea14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6e545-d859-4716-8904-65fbdb5e3bfe",
   "metadata": {},
   "source": [
    "데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어 \n",
    "\n",
    "```Python\n",
    "trainer.predict(trainer_input)\n",
    "```\n",
    "\n",
    "이 정상동작하는지 확인하라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeca824-187a-4b0a-8871-290b36579ff2",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "483da651-055e-4807-b126-fd510eb4f931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7085, grad_fn=<NllLossBackward0>), logits=tensor([[-0.0543,  0.0011],\n",
       "        [-0.0405, -0.0351]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x\n",
    ") # 이 과정에서 model이 cuda로 감 \n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "model.to(\"cpu\") # 경우에 따라 생략해야할수도있음\n",
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc8e41-5c3f-41bb-a122-876bcecd15e0",
   "metadata": {},
   "source": [
    "- 잘 돌아갔음. (=여기에서 사용된 데이터콜렉터는 잘 설계된 `data_collator` 라는 의미)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a72b78-ddbb-4945-a1ae-19651f01427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.24347985,  0.03874021],\n",
       "       [-0.26586303,  0.06817057],\n",
       "       [-0.2564777 ,  0.04826375],\n",
       "       [-0.2534306 ,  0.06623521],\n",
       "       [-0.23762025,  0.05738585],\n",
       "       [-0.25557715,  0.07033838],\n",
       "       [-0.19689777,  0.07268588],\n",
       "       [-0.20918864,  0.05981901],\n",
       "       [-0.2526626 ,  0.10021226],\n",
       "       [-0.24273753,  0.05700814]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), metrics={'test_loss': 0.8574765920639038, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.038, 'test_samples_per_second': 263.415, 'test_steps_per_second': 52.683})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = data_collator\n",
    ")\n",
    "out = trainer.predict(trainer_input)\n",
    "out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8661973-ef37-40b4-a3bc-bdc84d794ad7",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ce50d-7fb1-4b88-ae8f-944d9a6373f9",
   "metadata": {},
   "source": [
    "`-`  관찰1: `batched_data[-1]` 는 하나의배치(single_batch)를 의미함. 모델의 입력으로는 부적절한 형식임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c813562-c818-4365-af02-11dcd5c8ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched_data[-1] -- 부적절해보이는 모델입력.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d87a224-68ce-4a3d-9be3-1404224e5e39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n) argument after ** must be a mapping, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatched_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n) argument after ** must be a mapping, not list"
     ]
    }
   ],
   "source": [
    "model(**batched_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862012b-f107-4516-9182-28c9778a0c12",
   "metadata": {},
   "source": [
    "`-` 관찰2: `data_collator(batched_data[-1])` 역시 하나의배치(single_batch)를 의미함. 그런데 이것은 모델의 입력으로도 적절한 형식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d481e53e-4099-4fc0-b3f4-7c400d99fb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2040,  2024,  ..., 22132,  7847,   102],\n",
       "        [  101,  2023,  2003,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator(batched_data[-1]) # 모델의 입력으로 매우 바람직해 보이는 형식임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0fef91b-a769-40f3-9682-69111b7f99f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.8696, grad_fn=<NllLossBackward0>), logits=tensor([[-0.2527,  0.1002],\n",
       "        [-0.2427,  0.0570]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model(**data_collator(batched_data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7e94d-5ec6-4d1b-a943-97c566364750",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "### `data_collator` -- 심화이해\n",
    "\n",
    "아래의 형식으로 정리된 배치화된 자료가 있다고 하자. (주의: `batched_data`는 항상 list비슷한 오브젝트이어야함)\n",
    "\n",
    "```Python\n",
    "batched_data = [batch_1, batch_2, ...,batch_n]\n",
    "```\n",
    "\n",
    "`data_collator` 는 각각의 `single_batch`, 즉 `batch_1`, `batch_2` 등을 `model`이 처리가능한 형태로 \"형식\"을 맞춰주는 역할을 한다. 즉 아래가 실행되도록 만들어주는 역할을 한다. \n",
    "\n",
    "```Python\n",
    "model(**data_collator(batch_1))\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0eaea-f8dd-4911-9f1f-8c37de386219",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "### `trainer`와 `model`의 자료처리과정 비교\n",
    "\n",
    "***#. `model`의 자료처리과정*** \n",
    "\n",
    "-코드: `model.forward(model_input)`\n",
    "\n",
    "-처리과정: `model_input`에 정리된 입력을 단순히 `model.forward()` 함수가 처리. \n",
    "\n",
    "***#. `trainer`의 자료처리과정***\n",
    "\n",
    "-코드: `trainer.predict(trainer_input)`\n",
    "\n",
    "-처리과정: 배치화 $\\to$ 데이터콜렉팅 $\\to$ 추론의 3단계를 거친다. \n",
    "\n",
    "1. `trainer_input`을 배치(batch)로 나눈다.\n",
    "2.\t각 배치(=`single_batch`)를 `data_collator`를 통해 형식을 맞춘다. \n",
    "3.\t형식이 조정된 데이터를 `model.forward`의 입력으로 전달한다. \n",
    "\n",
    "-슈도코드:\n",
    "```Python\n",
    "## 이 코드는.. \n",
    "trainer.predict(trainer_input)\n",
    "\n",
    "## 대략 아래의 느낌으로 해석하면 된다.. (동일X. 결과정리, GPU처리 등 세부로직이 더 있음)\n",
    "batched_data = some_function(trainer_input)\n",
    "for single_batch in batched_data:\n",
    "    collated_data = data_collator(single_batch)\n",
    "    model(**collated_data)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635a728-22e9-4619-a2c5-7161e61677f3",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "### `trainer.predict()` 의 분해\n",
    "\n",
    "`trainer.predict()`의 동작은 개념적으로 (1) 배치화 (2) 데이터콜렝팅 (3) 추론의 과정으로 분해할 수 있지만, 실제이러한 과정으로 코드를 정확하게 분리하는건 어렵다. (그리고 저 사이사이에는 다른 자잘한 과정들이 많다..) 하지만 이해를 위해서 코드조각을 억지로 분리해본다면 아래 3개의 코드조각으로 분리할 수 있을것이다. \n",
    "\n",
    "`1`. 배치화: `trainer_input` $\\to$ `batched_data`\n",
    "\n",
    "```Python\n",
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x\n",
    ")\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "```\n",
    "\n",
    "`2`. 데이터콜렉팅: `single_batch` $\\to$ `collated_data`\n",
    "\n",
    "```Python\n",
    "#for single_batch in batched_data:\n",
    "    collated_data = data_collator(single_batch)\n",
    "```\n",
    "\n",
    "`3`. 추론: `collated_data` $\\to$ `model_out`\n",
    "\n",
    "```Python\n",
    "#for single_batch in batched_data:\n",
    "    #collated_data = data_collator(single_batch)\n",
    "    model_out = model(**collated_data)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1475c7f-c8ec-4874-837e-0f70f6c3a6c4",
   "metadata": {},
   "source": [
    "## C. FOOD101 -- 복습 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e001f0b-f281-449e-9a54-e1d89eaf2296",
   "metadata": {},
   "source": [
    "ref: <https://huggingface.co/docs/transformers/tasks/image_classification>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9edac-4a04-43ca-9ed9-8a7bd04a18a7",
   "metadata": {},
   "source": [
    "*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c095a8f-c132-4ed2-8413-1d7e2d08198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food = datasets.load_dataset(\"guebin/food101-tiny\")\n",
    "image_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "normalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size), \n",
    "    torchvision.transforms.ToTensor(), \n",
    "    normalize\n",
    "])\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "trainer_input = food['train'].with_transform(transforms)\n",
    "trainer_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb611fd-8479-4a20-b7ab-37305ee9e6ac",
   "metadata": {},
   "source": [
    "*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de8bcc77-0431-4a6f-80d1-27b838cc947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "labels = food[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856eafde-13e2-47fc-9662-e1ca61a3624d",
   "metadata": {},
   "source": [
    "*3. 데이터콜렉터: `DefaultDataCollator()` $\\to$ `data_collator`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9cbb38e-0504-4cd9-a28d-1f85eb100d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultDataCollator(return_tensors='pt')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = transformers.DefaultDataCollator()\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12d9a5-e18a-4325-8c67-8cd75bcca9b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f01c1-b868-41dc-b69f-a862fcd469c2",
   "metadata": {},
   "source": [
    "데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어 \n",
    "\n",
    "```Python\n",
    "trainer.predict(trainer_input)\n",
    "```\n",
    "\n",
    "이 정상동작하는지 확인하라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2482ce-aba8-4806-997c-237872f56b4d",
   "metadata": {},
   "source": [
    "`(풀이1)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71c727a7-7799-4c1d-a1cb-e385e32ca26d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_maker \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m      3\u001b[0m     data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x \n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m _batched_data \u001b[38;5;241m=\u001b[39m batch_maker\u001b[38;5;241m.\u001b[39mget_test_dataloader(trainer_input)\n\u001b[0;32m----> 6\u001b[0m batched_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_batched_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m single_batch \u001b[38;5;241m=\u001b[39m batched_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_collator(single_batch))\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2865\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2865\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2866\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:516\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    515\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mtransforms\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransforms\u001b[39m(examples):\n\u001b[0;32m---> 15\u001b[0m     examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [_transforms(img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m examples\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x \n",
    ")\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332fc9a-6951-4cfc-955b-837be5a1eebe",
   "metadata": {},
   "source": [
    "`-` 왜 실패했지?? (예전에는 분명히 되었던 것 같은뎅..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce28f48-e54f-40cc-a43d-87775d57db33",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "**<에러메시지의 해석>**\n",
    "\n",
    "`-` 아래가 동작하지 않음. \n",
    "\n",
    "```Python\n",
    "batched_data = list(_batched_data)\n",
    "```\n",
    "\n",
    "`-` 그 이유는 아래가 동작하지 않기 때문임. \n",
    "\n",
    "```Python \n",
    "next(dataloader_iter)\n",
    "```\n",
    "\n",
    "`-` ...(생략)...\n",
    "\n",
    "`-` 최종적으로는 아래가 동작하지 않기 때문에 생긴 문제였음. (그런데 이건 `.with_transform()`에 있는 코드인데?)\n",
    "\n",
    "```Python\n",
    "examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "```\n",
    "\n",
    "`-` 결국 \n",
    "\n",
    "```Python\n",
    "[_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "```\n",
    "\n",
    "를 실행하는 시점에서 `examples[\"image\"]`가 없었다는 의미.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b659b8-0974-4740-9f99-7a78e3b2eb36",
   "metadata": {},
   "source": [
    "> 눈치: `with_transform`이 지금 실행되는거였어?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a5c42-2ac1-4281-9067-bd1923bf3dec",
   "metadata": {},
   "source": [
    "`-` 왜 이런일이 생기지? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510ec51-c163-4a7d-8e54-718adfa9713f",
   "metadata": {},
   "source": [
    "`-` 배치화를 하는 코드 \n",
    "\n",
    "```Python\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
    "```\n",
    "\n",
    "에서 아래의 column_names: \n",
    "\n",
    "- `pixel_values`\n",
    "- `head_mask`\n",
    "- `labels`\n",
    "- `output_attentions`\n",
    "- `output_hidden_states`\n",
    "- `interpolate_pos_encoding`\n",
    "- `return_dict`\n",
    "\n",
    "를 제외하고는 모두 트레이너(`batch_maker = trainer`)가 강제로 제거하는 로직이 있음.^[왜 이런 로직이 있을까? 이런 로직이 없다면 model의 args를 강제로 외우고 있어야 하니까..]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53a588-0108-4b66-b746-d164a604f746",
   "metadata": {},
   "source": [
    "`-` `image`라는 column_name은 위에 해당되지 않으므로 제거됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38a0f2-137c-4bf5-8ca3-4ea330e9a0aa",
   "metadata": {},
   "source": [
    "`-` 그리고 `image` 칼럼이 제거된 이후에 `with_transform` 이 나중에 실행되면서 (지연실행) 문제가 발생. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92680013-c7de-49fe-a0ad-639a5fafb037",
   "metadata": {},
   "source": [
    "> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f265b3-2baa-404c-a847-9c39f3e3c8a4",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "### 중간정리\n",
    "\n",
    "`trainer.predict()` 은 (1) 배치화 (2) 데이터콜렉팅 (3) 추론의 과정을 거친다. 그리고 배치화와 데이터콜렉팅 사이에 \"싱글배치\"를 만드는 과정이 있다. \n",
    "\n",
    "- 세부사항1: 그런데 \"**배치화**\"단계에서 `model.forward()`의 입력으로 사용되지 않는 columns는 지워지는 내부로직이 존재한다. \n",
    "- 세부사항2: `trainer_input`에 걸려있는 `.with_transform()`은 \"**배치화**\"이후 싱글배치가 만들어지는 과정에서 실행된다. \n",
    "\n",
    "\n",
    "따라서 `.with_transform()` 에서 특정컬럼의 변화시키는 동작이 약속된 경우, 그 컬럼이 **배치화**의 단계에서 자동제거되어 코드가 돌아가지 않을 수 있는 위험성이 존재한다. \n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc4791-d9dc-4d16-bbfe-ae7868c4a005",
   "metadata": {},
   "source": [
    "`(풀이2)` -- `image`를 `return_dict` 로 위장.. // 완전 테크니컬한 풀이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792778cd-ec1d-4738-9bd9-c17e663b1411",
   "metadata": {},
   "source": [
    "`-` 현재상황: `food['train']`에 `.with_transform(transforms)`을 걸어두고(?) `trainer_input`을 만든상황 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e97df-417b-460a-ad50-27636bec4417",
   "metadata": {},
   "source": [
    "`-` 문제: `trainer.predict()` 내부동작에서 `.with_transform(transform)` 이 실현될때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9208c47c-a073-4bbc-97f5-e77c440693c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pixel_values\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdel\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_706133/1515420127.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "transforms??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80223898-0adf-4331-b48a-9aeb29e811a1",
   "metadata": {},
   "source": [
    "이 내용이 실행되어야하는데, `image`는 model의 입력으로 유하하지 않은 키라서 트레이너가 이미 제거한 상태임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a0db01-e8ff-4d34-b68b-1e51768429b4",
   "metadata": {},
   "source": [
    "`-` 전략: 제거가 안되게 막아보자.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "557b831d-a9c0-4403-ba4e-12dba33f7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "690817e9-aa83-45dd-b673-29a17c38f6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['return_dict', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainer_input = food['train'].with_transform(transforms)\n",
    "trainer_input2 = trainer_input.rename_columns({'image':'return_dict'})\n",
    "trainer_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aea39a00-b799-4f67-bdee-812febf8f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms2(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"return_dict\"]]\n",
    "    del examples[\"return_dict\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe3a7a79-f6ef-44d2-be7f-7e105bf8357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['return_dict', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input3 = trainer_input2.with_transform(transforms2)\n",
    "trainer_input3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e39e170-787a-404c-b81c-9538e42ccdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=tensor(4.5805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0258,  0.0340,  0.0493,  0.0371,  0.0371,  0.0636, -0.0353, -0.0416,\n",
       "          0.0061, -0.0304,  0.0127, -0.0633,  0.0532, -0.1117, -0.1657, -0.0810,\n",
       "          0.0022,  0.0071, -0.0947, -0.0831, -0.1189,  0.0783, -0.2383, -0.0486,\n",
       "          0.1039,  0.0115,  0.0054, -0.0113,  0.0740,  0.0783,  0.0188,  0.0618,\n",
       "          0.2759,  0.1308, -0.1028,  0.0198,  0.0032,  0.2006, -0.1247, -0.0512,\n",
       "         -0.0331, -0.0608, -0.1030,  0.0307,  0.2115,  0.1275, -0.1836, -0.2429,\n",
       "         -0.1090, -0.0293,  0.1010,  0.0847, -0.0655,  0.0416, -0.1167, -0.0598,\n",
       "          0.1333,  0.1627, -0.1722,  0.0046, -0.0842,  0.0161,  0.1583, -0.0403,\n",
       "         -0.0190, -0.1496,  0.0723, -0.0647, -0.1083, -0.1299,  0.0851, -0.1810,\n",
       "          0.0214,  0.2340, -0.0186, -0.1256,  0.0582,  0.1798,  0.1589, -0.0982,\n",
       "          0.0066,  0.0177,  0.0315,  0.0404,  0.1300, -0.0198,  0.0468, -0.0595,\n",
       "          0.2014,  0.0155, -0.0009,  0.1910, -0.0110,  0.1809,  0.0187,  0.0010,\n",
       "          0.0691,  0.2024,  0.1041, -0.1182,  0.0577],\n",
       "        [-0.0791,  0.0483, -0.0684,  0.0205,  0.0634,  0.0355,  0.1256,  0.0242,\n",
       "          0.0795, -0.1158,  0.1004, -0.0554,  0.1398,  0.0703, -0.0372, -0.0903,\n",
       "          0.0322, -0.1763, -0.0331,  0.0778,  0.0345,  0.0899,  0.0006, -0.1170,\n",
       "         -0.0303,  0.0620, -0.1490, -0.0589, -0.0060,  0.0266, -0.0812, -0.0497,\n",
       "         -0.0114,  0.0981, -0.0686,  0.0337,  0.0196,  0.0132, -0.1738, -0.0574,\n",
       "         -0.0434,  0.0773,  0.0020,  0.1212,  0.1227, -0.0150, -0.0698, -0.1568,\n",
       "          0.0644, -0.1053,  0.0420, -0.1292, -0.1032, -0.1744, -0.1242, -0.0229,\n",
       "          0.1295,  0.0844, -0.1660, -0.0132, -0.0407,  0.1438, -0.0115, -0.0879,\n",
       "         -0.1188, -0.1644, -0.0454, -0.0449, -0.0555, -0.2129, -0.0220, -0.1480,\n",
       "         -0.0191,  0.2003,  0.0107,  0.1169,  0.0108,  0.0526,  0.1320, -0.2591,\n",
       "          0.0240, -0.0215,  0.2772,  0.0699,  0.0940,  0.0377,  0.0715,  0.1504,\n",
       "          0.0094, -0.0027,  0.1345,  0.2739,  0.0965,  0.1069, -0.0843,  0.0841,\n",
       "          0.0078,  0.1318,  0.1355,  0.0620, -0.0478]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x \n",
    ")\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input3)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "055cd7ea-3f07-46d9-a44d-4ce6b531360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.05419738, -0.05692905,  0.02577981, ...,  0.06238552,\n",
       "        -0.08741985,  0.00835681],\n",
       "       [ 0.06003767,  0.03531971, -0.01702251, ...,  0.10187533,\n",
       "        -0.04111148, -0.11816782],\n",
       "       [-0.06362653, -0.06895374,  0.04998193, ...,  0.04436018,\n",
       "         0.09370279, -0.10635335],\n",
       "       ...,\n",
       "       [ 0.01029072,  0.00109556, -0.0853666 , ...,  0.117467  ,\n",
       "        -0.07630866,  0.04534987],\n",
       "       [-0.02582262,  0.03399263,  0.04932407, ...,  0.10409873,\n",
       "        -0.11815406,  0.05774596],\n",
       "       [-0.07906114,  0.04832995, -0.06836515, ...,  0.1355295 ,\n",
       "         0.06195256, -0.04780686]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.615988254547119, 'test_model_preparation_time': 0.0021, 'test_runtime': 0.122, 'test_samples_per_second': 81.994, 'test_steps_per_second': 16.399})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator= data_collator\n",
    ")\n",
    "trainer.predict(trainer_input3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b615852-5107-42ee-9b64-301c287c7982",
   "metadata": {},
   "source": [
    "`(풀이3)` -- trainer_input 에 예약된 `with_transform`을 지연실행하지 않고 즉시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eee109ec-36f1-4d2c-9433-2c27d5a007a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7bce360-8f9c-4152-bd24-62d3dad7419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_input2 = [l for l in trainer_input]\n",
    "#trainer_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d96fe9a-4ec3-44b0-b6da-d5037d5493c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=tensor(4.5605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0081,  0.0617,  0.0638,  0.0713,  0.0144,  0.0612, -0.0130,  0.0154,\n",
       "         -0.0081, -0.0375,  0.0250, -0.0233,  0.0434, -0.1051, -0.1325, -0.0450,\n",
       "         -0.0049, -0.0313, -0.0842, -0.0833, -0.0892,  0.0594, -0.2713, -0.0347,\n",
       "          0.1534,  0.0343,  0.0183,  0.0157,  0.0553,  0.1003,  0.0007,  0.0441,\n",
       "          0.2778,  0.1277, -0.1301,  0.0467, -0.0503,  0.2478, -0.1140, -0.1092,\n",
       "         -0.0189, -0.0305, -0.1160,  0.0112,  0.2403,  0.1366, -0.1775, -0.2425,\n",
       "         -0.1163, -0.0243,  0.0992,  0.0648, -0.0584,  0.0718, -0.1058, -0.0473,\n",
       "          0.1545,  0.1715, -0.2551,  0.0352, -0.0359,  0.0221,  0.1607, -0.0603,\n",
       "         -0.0414, -0.1300,  0.1734, -0.0703, -0.1057, -0.1081,  0.0777, -0.1908,\n",
       "          0.0017,  0.3012, -0.0455, -0.1913,  0.0702,  0.1233,  0.1578, -0.0738,\n",
       "         -0.0173,  0.0552,  0.0420,  0.0655,  0.1074, -0.0273,  0.0485, -0.0461,\n",
       "          0.1798,  0.0381,  0.0032,  0.1604, -0.0975,  0.1537,  0.0042, -0.0461,\n",
       "          0.0601,  0.2107,  0.1335, -0.1295,  0.0352],\n",
       "        [-0.1044,  0.0104, -0.0422, -0.1469, -0.0117,  0.0846,  0.1661, -0.0103,\n",
       "          0.0525, -0.0917,  0.1212, -0.0444,  0.1618,  0.1138, -0.0373,  0.0542,\n",
       "          0.0429, -0.2012, -0.0207,  0.0457,  0.0667,  0.0972, -0.0717, -0.0703,\n",
       "          0.0701,  0.0540, -0.0171, -0.0794,  0.0547,  0.2083, -0.0065,  0.0393,\n",
       "          0.0592,  0.2466,  0.0027,  0.0328, -0.0566,  0.0978, -0.1787,  0.0818,\n",
       "         -0.0550,  0.0916,  0.0148,  0.1101,  0.1682,  0.0056, -0.0835, -0.2765,\n",
       "         -0.0238, -0.1956,  0.0127, -0.0766, -0.0920, -0.1452, -0.0421, -0.0560,\n",
       "          0.1438,  0.1189, -0.1660,  0.0936, -0.0736,  0.1523,  0.0853, -0.0591,\n",
       "         -0.0346, -0.1171,  0.0096, -0.0056,  0.0095, -0.2420,  0.0185, -0.0991,\n",
       "          0.1547,  0.2323,  0.0378,  0.0578,  0.0714,  0.1055,  0.1090, -0.2153,\n",
       "          0.1281,  0.0639,  0.1533, -0.0397,  0.2495,  0.0217,  0.0576,  0.1019,\n",
       "          0.2074,  0.0387,  0.1036,  0.3094,  0.1219,  0.0817, -0.0584,  0.0388,\n",
       "          0.0619,  0.0701,  0.0913,  0.0300, -0.0823]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x \n",
    ")\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input2)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29fdb21c-bec8-4ee1-bc87-05d4df1562f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.11918398, -0.16509736,  0.0360051 , ..., -0.0015837 ,\n",
       "        -0.1649007 ,  0.06934457],\n",
       "       [ 0.02522344, -0.03897335,  0.14615731, ...,  0.14916745,\n",
       "        -0.08329906,  0.00363915],\n",
       "       [-0.03516109, -0.03787031,  0.06803481, ...,  0.0288963 ,\n",
       "         0.03937618, -0.04595642],\n",
       "       ...,\n",
       "       [ 0.05573866, -0.03177875, -0.12821546, ...,  0.08249602,\n",
       "        -0.12046868,  0.02415534],\n",
       "       [-0.00807494,  0.06173132,  0.06380235, ...,  0.13346131,\n",
       "        -0.1294754 ,  0.03517982],\n",
       "       [-0.10440043,  0.01043405, -0.04224908, ...,  0.09133518,\n",
       "         0.03001446, -0.08225137]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.626803398132324, 'test_model_preparation_time': 0.0022, 'test_runtime': 0.0629, 'test_samples_per_second': 159.085, 'test_steps_per_second': 31.817})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator= data_collator\n",
    ")\n",
    "trainer.predict(trainer_input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299fba55-50e8-4fcb-97b8-ad9eb4ec59fe",
   "metadata": {},
   "source": [
    "`(풀이4)` -- 트레이너가 가진 \"사용하지 않는 column을 제거하는 기능\"을 `False` 시킴.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3793d6db-8d64-4305-b884-440ffffa2ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "199dec4b-139d-4104-b1a5-34f0abcf117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=tensor(4.5805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0258,  0.0340,  0.0493,  0.0371,  0.0371,  0.0636, -0.0353, -0.0416,\n",
       "          0.0061, -0.0304,  0.0127, -0.0633,  0.0532, -0.1117, -0.1657, -0.0810,\n",
       "          0.0022,  0.0071, -0.0947, -0.0831, -0.1189,  0.0783, -0.2383, -0.0486,\n",
       "          0.1039,  0.0115,  0.0054, -0.0113,  0.0740,  0.0783,  0.0188,  0.0618,\n",
       "          0.2759,  0.1308, -0.1028,  0.0198,  0.0032,  0.2006, -0.1247, -0.0512,\n",
       "         -0.0331, -0.0608, -0.1030,  0.0307,  0.2115,  0.1275, -0.1836, -0.2429,\n",
       "         -0.1090, -0.0293,  0.1010,  0.0847, -0.0655,  0.0416, -0.1167, -0.0598,\n",
       "          0.1333,  0.1627, -0.1722,  0.0046, -0.0842,  0.0161,  0.1583, -0.0403,\n",
       "         -0.0190, -0.1496,  0.0723, -0.0647, -0.1083, -0.1299,  0.0851, -0.1810,\n",
       "          0.0214,  0.2340, -0.0186, -0.1256,  0.0582,  0.1798,  0.1589, -0.0982,\n",
       "          0.0066,  0.0177,  0.0315,  0.0404,  0.1300, -0.0198,  0.0468, -0.0595,\n",
       "          0.2014,  0.0155, -0.0009,  0.1910, -0.0110,  0.1809,  0.0187,  0.0010,\n",
       "          0.0691,  0.2024,  0.1041, -0.1182,  0.0577],\n",
       "        [-0.0791,  0.0483, -0.0684,  0.0205,  0.0634,  0.0355,  0.1256,  0.0242,\n",
       "          0.0795, -0.1158,  0.1004, -0.0554,  0.1398,  0.0703, -0.0372, -0.0903,\n",
       "          0.0322, -0.1763, -0.0331,  0.0778,  0.0345,  0.0899,  0.0006, -0.1170,\n",
       "         -0.0303,  0.0620, -0.1490, -0.0589, -0.0060,  0.0266, -0.0812, -0.0497,\n",
       "         -0.0114,  0.0981, -0.0686,  0.0337,  0.0196,  0.0132, -0.1738, -0.0574,\n",
       "         -0.0434,  0.0773,  0.0020,  0.1212,  0.1227, -0.0150, -0.0698, -0.1568,\n",
       "          0.0644, -0.1053,  0.0420, -0.1292, -0.1032, -0.1744, -0.1242, -0.0229,\n",
       "          0.1295,  0.0844, -0.1660, -0.0132, -0.0407,  0.1438, -0.0115, -0.0879,\n",
       "         -0.1188, -0.1644, -0.0454, -0.0449, -0.0555, -0.2129, -0.0220, -0.1480,\n",
       "         -0.0191,  0.2003,  0.0107,  0.1169,  0.0108,  0.0526,  0.1320, -0.2591,\n",
       "          0.0240, -0.0215,  0.2772,  0.0699,  0.0940,  0.0377,  0.0715,  0.1504,\n",
       "          0.0094, -0.0027,  0.1345,  0.2739,  0.0965,  0.1069, -0.0843,  0.0841,\n",
       "          0.0078,  0.1318,  0.1355,  0.0620, -0.0478]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11a793e7-e305-4ad1-a399-14edee7f59ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.05419738, -0.05692905,  0.02577981, ...,  0.06238552,\n",
       "        -0.08741985,  0.00835681],\n",
       "       [ 0.06003767,  0.03531971, -0.01702251, ...,  0.10187533,\n",
       "        -0.04111148, -0.11816782],\n",
       "       [-0.06362653, -0.06895374,  0.04998193, ...,  0.04436018,\n",
       "         0.09370279, -0.10635335],\n",
       "       ...,\n",
       "       [ 0.01029072,  0.00109556, -0.0853666 , ...,  0.117467  ,\n",
       "        -0.07630866,  0.04534987],\n",
       "       [-0.02582262,  0.03399263,  0.04932407, ...,  0.10409873,\n",
       "        -0.11815406,  0.05774596],\n",
       "       [-0.07906114,  0.04832995, -0.06836515, ...,  0.1355295 ,\n",
       "         0.06195256, -0.04780686]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.615988254547119, 'test_model_preparation_time': 0.0021, 'test_runtime': 0.0794, 'test_samples_per_second': 125.968, 'test_steps_per_second': 25.194})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator= data_collator,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )    \n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3980242-7e02-4b9e-be07-20223612bc09",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021cfa0-ab5a-4a06-8562-470240010cea",
   "metadata": {},
   "source": [
    "`(풀이5)` -- 트레이너가 가진 \"사용하지 않는 column을 제거하는 기능\"을 `False` 시킬꺼면, `batch_maker`를 고려할 필요도 없이 아래와 같이 바로 `single_batch`를 얻을 수 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac5c12-e1d8-4be8-94c0-6d738699747f",
   "metadata": {},
   "source": [
    "*풀이4: 실제로 trainer가 싱글배치를 얻는 과정과 유사하게 얻는 방법*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7659eb7c-82f7-4113-87ed-2aaa19d53290",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir= \"asdf\", # 아무거나 써야함. \n",
    "        remove_unused_columns= False # 이 부분이 포인트!!\n",
    "    )        \n",
    ")\n",
    "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[0]\n",
    "# single_batch = [\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "#     {'label':int, 'pixel_values': 3d-tsr},\n",
    "# ]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c30972-dae3-46fe-a2aa-36e381158313",
   "metadata": {},
   "source": [
    "> 형식관찰: `single_batch`는 `[Dict, Dict, Dict, .... Dict]` 꼴임을 주목하라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c48f5f-8229-46a7-a52b-6300b395f52e",
   "metadata": {},
   "source": [
    "*풀이5: 형식관찰에 힌트를 얻어 무식하게 얻은 싱글배치*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d43aae24-8606-4256-98d5-bbcdbfc00f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch = [\n",
    "    trainer_input[0],\n",
    "    trainer_input[1],\n",
    "    trainer_input[2],\n",
    "    trainer_input[3],\n",
    "    trainer_input[4],\n",
    "    trainer_input[5],\n",
    "    trainer_input[6],\n",
    "    trainer_input[7],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87de0c-c467-4403-9bad-08962163aae7",
   "metadata": {},
   "source": [
    "*아무튼 풀이5 스타일로 싱글배치를 얻었다면? 이후의 코드는 동일*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "18693c6e-fa15-499d-bb91-b71542ae5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "model(**data_collator(single_batch));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "920e15ac-7809-4abd-b9dc-96b572c0e5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.05419738, -0.05692905,  0.02577981, ...,  0.06238552,\n",
       "        -0.08741985,  0.00835681],\n",
       "       [ 0.06003767,  0.03531971, -0.01702251, ...,  0.10187533,\n",
       "        -0.04111148, -0.11816782],\n",
       "       [-0.06362653, -0.06895374,  0.04998193, ...,  0.04436018,\n",
       "         0.09370279, -0.10635335],\n",
       "       ...,\n",
       "       [ 0.01029072,  0.00109556, -0.0853666 , ...,  0.117467  ,\n",
       "        -0.07630866,  0.04534987],\n",
       "       [-0.02582262,  0.03399263,  0.04932407, ...,  0.10409873,\n",
       "        -0.11815406,  0.05774596],\n",
       "       [-0.07906114,  0.04832995, -0.06836515, ...,  0.1355295 ,\n",
       "         0.06195256, -0.04780686]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.615988254547119, 'test_model_preparation_time': 0.0015, 'test_runtime': 0.0567, 'test_samples_per_second': 176.35, 'test_steps_per_second': 35.27})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator= data_collator,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )    \n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a16d7-4261-4b0e-a044-a5714e1c7f7f",
   "metadata": {},
   "source": [
    "*참고1: 아래의 방식으로 싱글배치를 얻을 수 없음. -- 이유? 지연실행때문에..*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ba8c39e-5b82-462a-86a2-e4917b016ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_batch = trainer_input.to_list()[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1046f-a0fd-4309-a2e3-134c96bb97de",
   "metadata": {},
   "source": [
    "*참고2: 아래의 방식으로도 싱글배치를 얻을 수 없음.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8994af4b-8096-498d-8f19-6cc45554a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_batch = trainer_input[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376b577-2723-4e84-9ec6-67cd0a4fe553",
   "metadata": {},
   "source": [
    "*이유?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f87f2e15-742a-4063-a979-d291334de790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input[:2] == [trainer_input[0],trainer_input[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6b185-4e10-46b4-aed0-ac18bc225836",
   "metadata": {},
   "source": [
    "## D. FOOD101 -- DefaultDataCollator 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89115b6e-d8a1-4305-82a3-ffd3cb6b044c",
   "metadata": {},
   "source": [
    "*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b830cfc2-bb28-41f9-9968-9ef4cd7f9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food = datasets.load_dataset(\"guebin/food101-tiny\")\n",
    "image_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "normalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size), \n",
    "    torchvision.transforms.ToTensor(), \n",
    "    normalize\n",
    "])\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "trainer_input = food['train'].with_transform(transforms)\n",
    "trainer_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87c732-c6ae-4064-966a-f9e1571ed8cf",
   "metadata": {},
   "source": [
    "*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c01621bd-0365-4636-8913-5b04512ad2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "labels = food[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491b81f-84ca-4292-a26e-91807b8b2e8c",
   "metadata": {},
   "source": [
    "*3. 데이터콜렉터: `collate_fn` 직접설계*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ff687af-d42e-4b3e-ac7e-f3db3d181f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = transformers.DefaultDataCollator()\n",
    "# data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ea9b134-9f9a-4597-8038-0389165c9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(single_batch):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f7218-c1a5-422b-955d-09a895c703c4",
   "metadata": {},
   "source": [
    "`DefaultDataCollator()` 와 동일한 역할을 하는 `collate_fn`을 설계하라. 이를 이용하여 적당한 `trainer`를 만들어 \n",
    "\n",
    "```Python\n",
    "trainer.predict(trainer_input)\n",
    "```\n",
    "\n",
    "이 정상동작하는지 확인하라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bea4b1-0348-4051-b8dc-4e6413095e8e",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "293ba961-f650-42b8-8e50-447fecbceead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ea9418a6-b8ab-44a4-866c-39b399a85aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 6,\n",
       "  'pixel_values': tensor([[[ 0.9294,  0.9137,  0.9137,  ..., -0.0902, -0.1373, -0.1451],\n",
       "           [ 0.9216,  0.8902,  0.8824,  ..., -0.1059, -0.1451, -0.1216],\n",
       "           [ 0.9137,  0.8745,  0.8588,  ..., -0.1294, -0.1608, -0.1216],\n",
       "           ...,\n",
       "           [ 0.8902,  0.8824,  0.8588,  ...,  0.6471,  0.6941,  0.7490],\n",
       "           [ 0.8980,  0.9608,  0.9216,  ...,  0.6471,  0.6863,  0.7412],\n",
       "           [ 0.7961,  0.9294,  0.8980,  ...,  0.6863,  0.7569,  0.8275]],\n",
       "  \n",
       "          [[ 0.7882,  0.7725,  0.7725,  ..., -0.7020, -0.7490, -0.7569],\n",
       "           [ 0.7804,  0.7412,  0.7333,  ..., -0.7176, -0.7569, -0.7490],\n",
       "           [ 0.7725,  0.7255,  0.7098,  ..., -0.7412, -0.7725, -0.7490],\n",
       "           ...,\n",
       "           [ 0.6000,  0.6000,  0.5765,  ...,  0.3569,  0.4196,  0.4824],\n",
       "           [ 0.6078,  0.6784,  0.6549,  ...,  0.3647,  0.4275,  0.4824],\n",
       "           [ 0.5059,  0.6471,  0.6314,  ...,  0.4118,  0.5137,  0.5843]],\n",
       "  \n",
       "          [[ 0.3020,  0.2863,  0.2863,  ..., -0.8824, -0.9294, -0.9373],\n",
       "           [ 0.2941,  0.2784,  0.2627,  ..., -0.8980, -0.9373, -0.9294],\n",
       "           [ 0.3020,  0.2627,  0.2471,  ..., -0.9294, -0.9608, -0.9373],\n",
       "           ...,\n",
       "           [-0.0588, -0.0431, -0.0275,  ..., -0.2000, -0.1294, -0.0588],\n",
       "           [-0.0196,  0.0745,  0.0824,  ..., -0.1843, -0.1059, -0.0353],\n",
       "           [-0.1059,  0.0667,  0.0745,  ..., -0.1216, -0.0118,  0.0745]]])},\n",
       " {'label': 6,\n",
       "  'pixel_values': tensor([[[ 0.2471,  0.2392,  0.2235,  ...,  0.5529,  0.5608,  0.5686],\n",
       "           [ 0.2784,  0.2706,  0.2549,  ...,  0.5137,  0.5216,  0.5294],\n",
       "           [ 0.2863,  0.2863,  0.2706,  ...,  0.5373,  0.5373,  0.5373],\n",
       "           ...,\n",
       "           [ 0.1843,  0.1843,  0.1922,  ...,  0.3961,  0.4039,  0.4039],\n",
       "           [ 0.1765,  0.1765,  0.1765,  ...,  0.3725,  0.3804,  0.3804],\n",
       "           [ 0.1843,  0.1843,  0.1843,  ...,  0.3412,  0.3490,  0.3490]],\n",
       "  \n",
       "          [[ 0.0196,  0.0118, -0.0039,  ...,  0.2392,  0.2471,  0.2549],\n",
       "           [ 0.0510,  0.0431,  0.0275,  ...,  0.2000,  0.2078,  0.2157],\n",
       "           [ 0.0431,  0.0353,  0.0275,  ...,  0.2235,  0.2235,  0.2235],\n",
       "           ...,\n",
       "           [ 0.0275,  0.0275,  0.0353,  ...,  0.2314,  0.2392,  0.2392],\n",
       "           [ 0.0196,  0.0196,  0.0275,  ...,  0.2078,  0.2157,  0.2157],\n",
       "           [ 0.0353,  0.0353,  0.0353,  ...,  0.1765,  0.1843,  0.1843]],\n",
       "  \n",
       "          [[-0.0275, -0.0353, -0.0510,  ...,  0.3020,  0.3098,  0.3176],\n",
       "           [ 0.0039, -0.0039, -0.0196,  ...,  0.2627,  0.2706,  0.2784],\n",
       "           [-0.0196, -0.0196, -0.0275,  ...,  0.2784,  0.2784,  0.2784],\n",
       "           ...,\n",
       "           [-0.0275, -0.0275, -0.0196,  ...,  0.2000,  0.2078,  0.2078],\n",
       "           [-0.0353, -0.0353, -0.0275,  ...,  0.1843,  0.1922,  0.1922],\n",
       "           [-0.0118, -0.0118, -0.0118,  ...,  0.1529,  0.1608,  0.1608]]])}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_maker = transformers.Trainer(\n",
    "#     model= model,\n",
    "#     data_collator= lambda x: x,\n",
    "#     args = transformers.TrainingArguments(\n",
    "#         output_dir=\"asdf\",\n",
    "#         remove_unused_columns=False\n",
    "#     )\n",
    "# )\n",
    "# _batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
    "# batched_data = list(_batched_data)\n",
    "# single_batch = batched_data[-1]\n",
    "#---#\n",
    "single_batch = [trainer_input[-2],trainer_input[-1]]\n",
    "single_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9a6f6c3e-0168-4a6b-9fae-e88f368885d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(single_batch):\n",
    "    #single_batch = [Dict,Dict] \n",
    "    #Dict = {'label': 6, 'pixel_values': [3, 224, 224]-tensor\n",
    "    collated_data = dict()\n",
    "    collated_data['labels'] = torch.tensor([dct['label'] for dct in single_batch])    \n",
    "    collated_data['pixel_values'] = torch.stack([dct['pixel_values'] for dct in single_batch])\n",
    "    return collated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a3657c6b-7843-487b-92be-10fd09c4a283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=tensor(4.6879, grad_fn=<NllLossBackward0>), logits=tensor([[-0.0804,  0.0968,  0.0104,  0.0587,  0.0753, -0.1459, -0.0490,  0.0943,\n",
       "         -0.1302,  0.0035,  0.0278,  0.0814, -0.0322, -0.0997,  0.0074,  0.0590,\n",
       "          0.1447, -0.0570,  0.0402, -0.1111,  0.0828, -0.0466, -0.0744, -0.0126,\n",
       "         -0.0425,  0.1688, -0.0974, -0.0623,  0.0361,  0.0408,  0.0729, -0.0884,\n",
       "         -0.1466, -0.0140, -0.0014,  0.0648,  0.1264, -0.0280,  0.1474, -0.0689,\n",
       "         -0.1422,  0.0655,  0.0284, -0.0079, -0.0690, -0.0004,  0.1554,  0.2469,\n",
       "         -0.0823, -0.1235,  0.1127,  0.0328, -0.0263, -0.1717, -0.0735, -0.0631,\n",
       "         -0.0033,  0.0384,  0.0394, -0.0366, -0.0721, -0.1715, -0.1646,  0.1292,\n",
       "         -0.0584,  0.1022,  0.1657, -0.0345, -0.0113,  0.0878,  0.0139,  0.0916,\n",
       "          0.0486,  0.1362, -0.1265, -0.0859,  0.1684,  0.0747, -0.0101,  0.0710,\n",
       "          0.1240,  0.0428,  0.0963, -0.0619,  0.0882, -0.1248, -0.0710, -0.0345,\n",
       "         -0.0587,  0.0099, -0.0551,  0.0146,  0.0188, -0.0608, -0.0025, -0.0860,\n",
       "          0.0773, -0.0181,  0.0626, -0.0063,  0.1354],\n",
       "        [-0.1139,  0.1333,  0.0288,  0.1036,  0.0013, -0.1305, -0.0787, -0.0498,\n",
       "         -0.0068, -0.0083, -0.1182,  0.1121, -0.0138,  0.1194, -0.0208,  0.0663,\n",
       "          0.1040,  0.0072,  0.0234, -0.0689, -0.0308, -0.1163,  0.0537, -0.0286,\n",
       "         -0.0101,  0.0307, -0.0585, -0.0954,  0.0320, -0.0579,  0.0325, -0.0295,\n",
       "         -0.1303, -0.0086,  0.0865, -0.0150,  0.1053, -0.0445,  0.1173,  0.0385,\n",
       "         -0.0747, -0.0407,  0.0267,  0.0213, -0.0670, -0.0072,  0.1436,  0.2285,\n",
       "         -0.0249, -0.0071,  0.2300,  0.0438, -0.0619, -0.1296, -0.0915, -0.1184,\n",
       "         -0.0810, -0.0472,  0.0674, -0.0898, -0.2508,  0.0194, -0.1328,  0.0603,\n",
       "         -0.0573,  0.2025,  0.1324, -0.0234,  0.1049, -0.0662, -0.0686,  0.1090,\n",
       "          0.0918, -0.0061,  0.0338, -0.0134,  0.2654,  0.0237, -0.0282,  0.0598,\n",
       "          0.0974,  0.0358,  0.0761,  0.0540, -0.0830,  0.0899, -0.0992, -0.1714,\n",
       "         -0.1553,  0.0348,  0.0597, -0.0319,  0.0956,  0.0430, -0.0128,  0.0559,\n",
       "          0.1588, -0.0096,  0.0150, -0.0084, -0.0050]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model(**collate_fn(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b8c4ede6-e568-44b5-b1b7-155d90f15143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.11636792, -0.0263294 ,  0.1064104 , ..., -0.04388852,\n",
       "        -0.07757819,  0.01414965],\n",
       "       [-0.07075333,  0.05525547,  0.0611947 , ..., -0.03989508,\n",
       "        -0.0375449 ,  0.12472424],\n",
       "       [-0.07043052,  0.12611614,  0.00971566, ...,  0.00761356,\n",
       "        -0.00533151,  0.02300033],\n",
       "       ...,\n",
       "       [-0.20117757,  0.09828947,  0.00724527, ..., -0.04101294,\n",
       "        -0.02915922,  0.21293962],\n",
       "       [-0.05230844,  0.08269425,  0.02642585, ...,  0.03440103,\n",
       "        -0.00195974,  0.12479743],\n",
       "       [-0.0799979 ,  0.02366202,  0.03927091, ...,  0.05246412,\n",
       "         0.07132983, -0.06526391]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.681787967681885, 'test_model_preparation_time': 0.0015, 'test_runtime': 0.0592, 'test_samples_per_second': 168.828, 'test_steps_per_second': 33.766})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=collate_fn,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73194a16-446f-409c-b99c-3cded0de4aca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48d134-2e24-4efc-8b64-3639e57be53f",
   "metadata": {},
   "source": [
    "## E. IMDB -- DataCollatorWithPadding 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4d6f4-c98e-46c7-b327-bcc6f1f356e3",
   "metadata": {},
   "source": [
    "ref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634ab82-3b78-480d-b53b-e87633bcf6bc",
   "metadata": {},
   "source": [
    "*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222fed30-5759-4bd2-9921-bbd6734ee144",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = datasets.load_dataset(\"guebin/imdb-tiny\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "tokenized_imdb = imdb.map(preprocess_function,batched=True)\n",
    "trainer_input = tokenized_imdb['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700481ef-323b-4801-a4b5-3cec65f71241",
   "metadata": {},
   "source": [
    "*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b403722-789e-453b-87be-9971c838ab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebfaea-b894-44d6-9578-d4cb9f291fe1",
   "metadata": {},
   "source": [
    "*3. 데이터콜렉터: `collate_fn` 직접설계* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d01cdf-2962-43cf-8b65-97817eb2504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a69b5ba3-44fc-45d0-ac0a-06066250100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(single_batch):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452727d9-2646-4bfd-bc41-649b9f63300b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd10a4-ae7d-4ee3-b662-efff511e1729",
   "metadata": {},
   "source": [
    "`DataCollatorWithPadding()` 와 동일한 역할을 하는 `collate_fn`을 설계하라. 이를 이용하여 적당한 `trainer`를 만들어 \n",
    "\n",
    "```Python\n",
    "trainer.predict(trainer_input)\n",
    "```\n",
    "\n",
    "이 정상동작하는지 확인하라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415c914-8d19-43d6-a013-2f798e665113",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ce3b1f-e0d0-4cab-9f3d-42a4d44b7568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a78cb791-bd51-4132-8718-fdf4bf5afe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model= model,\n",
    "    data_collator= lambda x: x,\n",
    ")\n",
    "_batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbb4fcf9-3be1-42e2-a9b3-87559a7bb899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([dct['label'] for dct in single_batch])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17ddcdb8-58be-47cd-9137-936ca2c4a5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2040,  2024,  ..., 22132,  7847,   102],\n",
       "        [  101,  2023,  2003,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['input_ids']) for dct in single_batch]).t()\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce76a9b2-96e0-4e5b-a91d-f463fee7e151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['attention_mask']) for dct in single_batch]).t()\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "403b9ed5-31e0-4c74-985f-3a0baebbf04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_batch = [Dict, Dict]\n",
    "# Dict = {\n",
    "#     'label': int \n",
    "#     'input_ids': 1d-list \n",
    "#     'attention_mask': 1d-list \n",
    "# }\n",
    "def collate_fn(single_batch):\n",
    "    collated_data = dict()\n",
    "    collated_data['input_ids'] = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['input_ids']) for dct in single_batch]).t()    \n",
    "    collated_data['attention_mask'] = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['attention_mask']) for dct in single_batch]).t()\n",
    "    collated_data['labels'] = torch.tensor([dct['label'] for dct in single_batch])\n",
    "    return collated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57f69284-1bdc-421c-a99f-2a46c97e4111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2040,  2024,  ..., 22132,  7847,   102],\n",
       "         [  101,  2023,  2003,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(single_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05281a70-8b3c-4d2a-a3e6-2415b15930ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6132, grad_fn=<NllLossBackward0>), logits=tensor([[0.1724, 0.0153],\n",
       "        [0.1978, 0.0212]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model(**collate_fn(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "858e44c9-63ed-4f54-aeed-68fc254b1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.18233198,  0.0185583 ],\n",
       "       [ 0.19031762,  0.02762305],\n",
       "       [ 0.19021928,  0.03987525],\n",
       "       [ 0.15878916, -0.00159456],\n",
       "       [ 0.18261112,  0.02069864],\n",
       "       [ 0.14113042, -0.00186965],\n",
       "       [ 0.17083615,  0.03911189],\n",
       "       [ 0.16111258,  0.01503472],\n",
       "       [ 0.17235444,  0.0153002 ],\n",
       "       [ 0.19777855,  0.02123523]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), metrics={'test_loss': 0.6185036897659302, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.0378, 'test_samples_per_second': 264.573, 'test_steps_per_second': 52.915})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76056b10-b74a-48d6-8eff-a3b8f4ac474e",
   "metadata": {},
   "source": [
    "# 4. 연습 -- `sms_spam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0395f64b-c3a5-4deb-94c6-3e0730b8fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sms', 'label'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "spam = datasets.load_dataset('guebin/spam-tiny')\n",
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108db8a9-0d44-46d5-8808-6b7395174874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sms', 'label'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a278b-13b9-4096-87bb-77617b347af6",
   "metadata": {},
   "source": [
    "## A. 방법1: 고정패딩, `collate_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "58affb00-6c85-4a18-9329-5aabb2b52b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_trans(example_batch):\n",
    "    # example_batch = {'sms':[xxx,xxxx,...], 'label':[yyy,yyyy] \n",
    "    # example_batch = spam['train'][:8]\n",
    "    out = tokenizer(example_batch['sms'],padding=True,truncation=True)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2be22233-3cee-4f88-8bf8-2d0845df16f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1538.07 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam2 = spam.map(m_trans,batched=True,batch_size=8)\n",
    "spam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f08a00a5-2afd-4bc8-8b37-8a94cd8ae8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam2.set_format(\"pt\")\n",
    "#spam2['train']['input_ids'] -- list of tensor with length 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7786cde4-e7ef-4986-98e2-b6eeaf3704d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n",
       "          2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n",
       "         10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n",
       "         21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n",
       "          9398,  2260,  2847,  2069,  1012,   102],\n",
       "        [  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n",
       "          1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n",
       "          2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n",
       "          2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam2['train'][8:]['input_ids'] # 2d-tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "eb8cb797-2cdc-4dc1-a252-530d4bb6496c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  101,  2004,  2566,  2115,  5227,  1005, 11463,  2571, 11463,  2571,\n",
       "          1006,  2030,  2226,  8117, 28987, 11231,  3070, 18447,  2063, 27617,\n",
       "          5575,  2226, 29525, 15464,  1007,  1005,  2038,  2042,  2275,  2004,\n",
       "          2115, 20587,  8525,  2638,  2005,  2035, 20587,  2015,  1012,  2811,\n",
       "          1008,  1023,  2000,  6100,  2115,  2814, 20587,  8525,  2638,   102,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " tensor([  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n",
       "          2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n",
       "         10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n",
       "         21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n",
       "          9398,  2260,  2847,  2069,  1012,   102]),\n",
       " tensor([  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n",
       "          1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n",
       "          2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n",
       "          2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0])]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam2['train'][7:]['input_ids'] # list of 1d-tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9074786d-b628-4fb6-be8e-73b38451c012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input = spam2['train'].remove_columns(['sms']).rename_columns({'label':'labels'})\n",
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "69a835e7-664f-4f4e-bf9a-c7957dfc097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': tensor(1, device='cuda:0'),\n",
       "  'input_ids': tensor([  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n",
       "           2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n",
       "          10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n",
       "          21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n",
       "           9398,  2260,  2847,  2069,  1012,   102], device='cuda:0'),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         device='cuda:0')},\n",
       " {'labels': tensor(1, device='cuda:0'),\n",
       "  'input_ids': tensor([  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n",
       "           1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n",
       "           2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n",
       "           2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n",
       "              0,     0,     0,     0,     0,     0], device='cuda:0'),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         device='cuda:0')}]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model= model,\n",
    "    data_collator=lambda x:x\n",
    ") \n",
    "_batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "single_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7bafe764-bcca-4897-ad6f-b657c91f86d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([single_batch[0]['labels'],single_batch[1]['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c4d5117d-75b5-4bf7-aa93-e1ac062693ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(single_batch):\n",
    "    out = dict()\n",
    "    out['labels'] = torch.stack([dct['labels'] for dct in single_batch])\n",
    "    out['input_ids'] = torch.stack([dct['input_ids'] for dct in single_batch])\n",
    "    out['attention_mask'] = torch.stack([dct['attention_mask'] for dct in single_batch])\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "046f3ba6-748c-4f9a-bacd-9cf0b44bb392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.2875, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.4793,  0.6985],\n",
       "        [-0.4598,  0.5654]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**collate_fn(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ce2d70cd-b2f9-4523-a8d4-a853aee7b5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.70305747, -0.7353085 ],\n",
       "       [ 0.7872642 , -0.77549946],\n",
       "       [-0.6230489 ,  0.72870666],\n",
       "       [ 0.7890144 , -0.74234533],\n",
       "       [ 0.6112454 , -0.5727863 ],\n",
       "       [-0.56530714,  0.636417  ],\n",
       "       [ 0.39937705, -0.28327113],\n",
       "       [ 0.45833465, -0.43777147],\n",
       "       [-0.6101986 ,  0.7738755 ],\n",
       "       [-0.48634416,  0.7041703 ]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.2599327564239502, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.0119, 'test_samples_per_second': 842.754, 'test_steps_per_second': 168.551})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model= model,\n",
    "    data_collator=collate_fn\n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3bd7329b-008f-458e-a3b9-20053070823e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [56] at entry 0 and [46] at entry 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[213], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mcollate_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[210], line 4\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(single_batch)\u001b[0m\n\u001b[1;32m      2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      3\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([dct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m dct \u001b[38;5;129;01min\u001b[39;00m single_batch])\n\u001b[0;32m----> 4\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdct\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msingle_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([dct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m dct \u001b[38;5;129;01min\u001b[39;00m single_batch])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [56] at entry 0 and [46] at entry 3"
     ]
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=trainer_input,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa37613-5097-46f6-9320-bc90de44f797",
   "metadata": {},
   "source": [
    "## B. 방법2: 고정패딩, DefaultDataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "563dc0cc-c97a-4fd6-8aeb-2fcfc1abcd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1685.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def m_trans(example_batch):\n",
    "    # example_batch = {'sms':[xxx,xxxx,...], 'label':[yyy,yyyy] \n",
    "    # example_batch = spam['train'][:8]\n",
    "    out = tokenizer(example_batch['sms'],padding=True,truncation=True)\n",
    "    return out \n",
    "spam2 = spam.map(m_trans,batched=True,batch_size=8)\n",
    "spam2.set_format(\"pt\")\n",
    "trainer_input = spam2['train'].remove_columns(['sms']).rename_columns({'label':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7991c069-f7dc-4bf4-8f6e-6f8ce6cd32b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': tensor(1, device='cuda:0'),\n",
       "  'input_ids': tensor([  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n",
       "           2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n",
       "          10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n",
       "          21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n",
       "           9398,  2260,  2847,  2069,  1012,   102], device='cuda:0'),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         device='cuda:0')},\n",
       " {'labels': tensor(1, device='cuda:0'),\n",
       "  'input_ids': tensor([  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n",
       "           1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n",
       "           2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n",
       "           2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n",
       "              0,     0,     0,     0,     0,     0], device='cuda:0'),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         device='cuda:0')}]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model= model,\n",
    "    data_collator=lambda x:x\n",
    ") \n",
    "_batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
    "batched_data = list(_batched_data)\n",
    "single_batch = batched_data[-1]\n",
    "single_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0e1c0c20-1ab2-4a6c-a94f-4a8bde92455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(single_batch):\n",
    "#     out = dict()\n",
    "#     out['labels'] = torch.stack([dct['labels'] for dct in single_batch])\n",
    "#     out['input_ids'] = torch.stack([dct['input_ids'] for dct in single_batch])\n",
    "#     out['attention_mask'] = torch.stack([dct['attention_mask'] for dct in single_batch])\n",
    "#     return out \n",
    "data_collator = transformers.DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8037ca7f-7a42-486d-9a8d-fad91ca725b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.2875, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.4793,  0.6985],\n",
       "        [-0.4598,  0.5654]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "97b50ea9-c014-470d-bec0-16b0cf3d2fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.70305747, -0.7353085 ],\n",
       "       [ 0.7872642 , -0.77549946],\n",
       "       [-0.6230489 ,  0.72870666],\n",
       "       [ 0.7890144 , -0.74234533],\n",
       "       [ 0.6112454 , -0.5727863 ],\n",
       "       [-0.56530714,  0.636417  ],\n",
       "       [ 0.39937705, -0.28327113],\n",
       "       [ 0.45833465, -0.43777147],\n",
       "       [-0.6101986 ,  0.7738755 ],\n",
       "       [-0.48634416,  0.7041703 ]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.2599327564239502, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.0118, 'test_samples_per_second': 844.621, 'test_steps_per_second': 168.924})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model= model,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c15fbecc-4534-4688-a826-f5233f1beaef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [56] at entry 0 and [46] at entry 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/data/data_collator.py:124\u001b[0m, in \u001b[0;36mDefaultDataCollator.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_tensors\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_data_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/data/data_collator.py:92\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# have the same attributes.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# on the whole batch.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_default_data_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/data/data_collator.py:154\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 154\u001b[0m         batch[k] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    156\u001b[0m         batch[k] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mstack([f[k] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [56] at entry 0 and [46] at entry 3"
     ]
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=trainer_input,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c89ca-7e7a-42bb-ab06-3af1396ac2e3",
   "metadata": {},
   "source": [
    "## C. 방법3: 동적패딩, `DataCollatorWithPadding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "97a969bd-7dd5-429e-80c4-36a004dffabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sms', 'label'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ae148560-cc29-4e3e-8ff0-42d40d7303a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_trans(examples):\n",
    "    # examples = spam['train'][:8] = {'sms': [xxx,xxxx,...], 'label':[yyy,yyyy,...]\n",
    "    out = tokenizer(examples['sms'],truncation=True)\n",
    "    out['labels'] = torch.tensor(examples['label'])\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5ccad917-bba0-4b84-8e5e-5642b380c7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input = spam.with_transform(w_trans)['train']\n",
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3bc25669-91a4-4239-8ec9-103ce4526691",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_maker = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = lambda x: x,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "single_batch = next(iter(batch_maker.get_eval_dataloader(trainer_input)))\n",
    "#sigle_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fb2db1de-78e6-4d6d-be0b-48b75376494a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.5369, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.2340, -0.2688],\n",
       "        [ 0.2608, -0.2633],\n",
       "        [-0.1423,  0.2838],\n",
       "        [ 0.2734, -0.3063],\n",
       "        [ 0.3347, -0.1394],\n",
       "        [-0.0950,  0.1350],\n",
       "        [ 0.0552,  0.0188],\n",
       "        [ 0.1153,  0.0608]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = transformers.DataCollatorWithPadding(tokenizer)\n",
    "model.to(\"cpu\")\n",
    "model(**data_collator(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a2c83652-2ea6-468d-b68b-7677771465a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.2797705 , -0.19910407],\n",
       "       [ 0.30945048, -0.2513666 ],\n",
       "       [-0.14997171,  0.28633246],\n",
       "       [ 0.30314386, -0.24964799],\n",
       "       [ 0.2884021 , -0.17398489],\n",
       "       [-0.07598098,  0.12895201],\n",
       "       [ 0.11931977, -0.05026204],\n",
       "       [ 0.08751589, -0.07571842],\n",
       "       [-0.13582245,  0.29102388],\n",
       "       [-0.06882622,  0.2479064 ]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.5247495770454407, 'test_model_preparation_time': 0.0007, 'test_runtime': 0.0093, 'test_samples_per_second': 1075.104, 'test_steps_per_second': 215.021})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    data_collator = data_collator,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4b5f31d9-6f9b-4893-9d0b-f5b18d86793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.38783260186513263, metrics={'train_runtime': 1.0559, 'train_samples_per_second': 28.412, 'train_steps_per_second': 5.682, 'total_flos': 421204931664.0, 'train_loss': 0.38783260186513263, 'epoch': 3.0})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=trainer_input,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e631d-fe55-40ce-b331-8c274b9e1cfe",
   "metadata": {},
   "source": [
    "## D. 방법4: 동적패딩, 전처리X $(\\star)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4c7a52d1-83d9-4b5e-97ea-6066a7446490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_input = spam['train']\n",
    "trainer_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66d327a3-32b1-4630-abd9-7f13e4a40a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sms': 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\\n',\n",
       "  'label': 1},\n",
       " {'sms': 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\\n',\n",
       "  'label': 1}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_batch = [trainer_input[-2],trainer_input[-1]]\n",
    "single_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "73dce43d-3b9c-442f-b44e-b3cf807f3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(single_batch):\n",
    "    out = tokenizer(\n",
    "        [dct['sms'] for dct in single_batch],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    out['labels'] = torch.tensor([dct['label'] for dct in single_batch])\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ebf41195-f28c-41ca-969c-1ef5bf37d37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6672, grad_fn=<NllLossBackward0>), logits=tensor([[0.0171, 0.1000],\n",
       "        [0.0605, 0.0832]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model(**collate_fn(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "017fe106-c414-4f91-9f0a-43c974324129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.02218767,  0.10636629],\n",
       "       [-0.01826159,  0.08857261],\n",
       "       [-0.01180449,  0.07579152],\n",
       "       [-0.03820946,  0.06749745],\n",
       "       [ 0.04095571,  0.06443821],\n",
       "       [ 0.0097203 ,  0.05986086],\n",
       "       [-0.01054696,  0.09217122],\n",
       "       [-0.02597055,  0.07729876],\n",
       "       [ 0.01710123,  0.09998252],\n",
       "       [ 0.06050469,  0.08315243]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.7104923725128174, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.0109, 'test_samples_per_second': 919.985, 'test_steps_per_second': 183.997})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=collate_fn,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.predict(trainer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "db46e799-021a-4915-ba06-60fbab9808af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.6373028755187988, metrics={'train_runtime': 1.0552, 'train_samples_per_second': 28.431, 'train_steps_per_second': 5.686, 'total_flos': 421204931664.0, 'train_loss': 0.6373028755187988, 'epoch': 3.0})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=trainer_input,\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=\"asdf\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e42fc9-c39b-48a0-b09b-6044cff19896",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac07322-4bed-4ce7-88a1-4d7919153d6e",
   "metadata": {},
   "source": [
    "# A1. 공지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b441823-6cc3-4901-819b-3300d395a8b5",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "### 강의시간 이슈 \n",
    "\n",
    "안녕하세요, 제가 촬영하고 강의시간을 살펴보니 원래 강의시간보다 약 20분정도 초과되었습니다. (3시간 분량인데 3시간20분 소요됨) \n",
    "죄송합니다. \n",
    "이후의 강의에서 이를 반영하여 조금 강의시간을 줄여서 올리도록하겠습니다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095a8b4-e6b5-4624-98bb-689f037a68c6",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "### 깊은복사 얕은복사 \n",
    "\n",
    "아래의 코드 \n",
    "\n",
    "```Python\n",
    "lst = [1,2,3]\n",
    "lst2 = lst \n",
    "lst2.append(4)\n",
    "```\n",
    "\n",
    "를 실행하였을 경우 `lst`와 `lst2`에 동일한 값이 저장되는 현상에 대한 설명은 \n",
    "\n",
    "> <https://guebin.github.io/PP2023/posts/2023-06-21-13wk-1.html>\n",
    " \n",
    "에 있으니 관심있으신 학생들은 참고하시기 바랍니다. (이 수업에서는 저 내용을 몰라도 학점받는데 영향없습니다)\n",
    "\n",
    "\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
