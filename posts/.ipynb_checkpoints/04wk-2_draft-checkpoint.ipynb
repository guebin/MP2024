{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"04wk-2: 감성분석 파고들기 (2)\"\n",
    "author: \"최규빈\"\n",
    "date: \"09/27/2024\"\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/02wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-xZ2p62reZCCgZsyMQLsOqY&si=bHkFTktvJIGoD0ni >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch # 파이토치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function evaluate.loading.load(path: str, config_name: Optional[str] = None, module_type: Optional[str] = None, process_id: int = 0, num_process: int = 1, cache_dir: Optional[str] = None, experiment_id: Optional[str] = None, keep_in_memory: bool = False, download_config: Optional[datasets.download.download_config.DownloadConfig] = None, download_mode: Optional[datasets.download.download_manager.DownloadMode] = None, revision: Union[str, datasets.utils.version.Version, NoneType] = None, **init_kwargs) -> evaluate.module.EvaluationModule>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_dataset\n",
    "datasets.Dataset.from_dict, \n",
    "datasets.dataset_dict.DatasetDict,\n",
    "transformers.AutoTokenizer.from_pretrained,\n",
    "transformers.AutoModelForSequenceClassification.from_pretrained,\n",
    "transformers.DataCollatorWithPadding,\n",
    "transformers.TrainingArguments,\n",
    "transformers.Trainer,\n",
    "transformers.pipeline,\n",
    "evaluate.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 이전시간 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이전시간의 내용중 이번시간에 기억할것들을 요약 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `DatasetDict`: 임의의 자료에 대한 `DatasetDict` 오브젝트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'text': [\n",
    "        \"I prefer making decisions based on logic and objective facts.\",\n",
    "        \"I always consider how others might feel when making a decision.\",\n",
    "        \"Data and analysis drive most of my decisions.\",\n",
    "        \"I rely on my empathy and personal values to guide my choices.\"\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    'text': [\n",
    "        \"I find it important to weigh all the pros and cons logically.\",\n",
    "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
    "    ],\n",
    "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.Dataset.from_dict(train_dict)\n",
    "test_data = datasets.Dataset.from_dict(test_dict)\n",
    "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `토크나이저`: 토크나이저는 \"`Str` $\\to$ `Dict`\" 인 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `토크나이저`: 토크나이저의 \"`Str` $\\to$ `Dict`\" 인 함수는 배치처리가 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 9544, 2437, 6567, 2241, 2006, 7961, 1998, 7863, 8866, 1012, 102], [101, 1045, 2467, 5136, 2129, 2500, 2453, 2514, 2043, 2437, 1037, 3247, 1012, 102], [101, 2951, 1998, 4106, 3298, 2087, 1997, 2026, 6567, 1012, 102], [101, 1045, 11160, 2006, 2026, 26452, 1998, 3167, 5300, 2000, 5009, 2026, 9804, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토크나이저(나의데이터['train']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능은 많은 파라메터를 포함하고 있는 어떠한 물체이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능의 파라메터는 변화할 수 있으며, loss가 더 작은쪽으로 파라메터를 변화시키는 과정을 \"학습\"이라고 부른다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능은 \"`**Dict` $\\to$ `transformers.modeling_outputs.SequenceClassifierOutput`\"인 함수이다. 그런데 쓰기 까다롭다.\n",
    "\n",
    "- `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`, `attention_mask`) \n",
    "- `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`. 따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n",
    "- `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "인공지능 = model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#` 인공지능의 입력예시1 -- 텐서형으로 정리된 텍스트자료만 있는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0877, -0.0312],\n",
       "        [ 0.0976,  0.0009]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(\n",
    "    **{\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]) # 생략가능\n",
    "    }\n",
    ")\n",
    "# 인공지능이 문제를 푸는 상황으로 비유할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#` 인공지능의 입력예시2 -- 텐서형으로 정리된 텍스트자료와 `labels`이 같이 있는경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7001, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0877, -0.0312],\n",
       "        [ 0.0976,  0.0009]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(\n",
    "    **{\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]), # 생략가능\n",
    "        'labels': torch.tensor([1, 0]) # 생략가능\n",
    "    }\n",
    ")\n",
    "# 인공지능이 문제를 풀고 자기 스스로 채점까지 하는 상황으로 비유할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `인공지능`: 인공지능의 출력결과^[`transformers.modeling_outputs.SequenceClassifierOutput` 자료형을 가짐] 에서 확률/예측값을 추출하는 방법 \n",
    "\n",
    "- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 확률 $\\to$ 인공지능의예측\n",
    "- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 인공지능의예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7001, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0877, -0.0312],\n",
       "        [ 0.0976,  0.0009]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능출력 = 인공지능(\n",
    "    **{\n",
    "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
    "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]), # 생략가능\n",
    "        'labels': torch.tensor([1, 0]) # 생략가능\n",
    "    }\n",
    ")\n",
    "인공지능출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제1:** 인공지능의 출력결과에서 인공지능의 예측값을 계산하자. -- 로짓 $\\to$ 인공지능의예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0877, -0.0312],\n",
       "        [ 0.0976,  0.0009]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "로짓 = 인공지능출력.logits\n",
    "로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "로짓.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제2:** 인공지능의 출력결과에서 인공지능의 예측확률을 계산하자 -- 로짓 $\\to$ 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0877, -0.0312],\n",
       "        [ 0.0976,  0.0009]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "로짓 = 인공지능출력.logits\n",
    "로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5297, 0.4608],\n",
       "        [0.5350, 0.4758]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(로짓) / torch.exp(로짓).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률게산하기라는 함수선언하여 외의 과정을 단순화 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 확률계산하기(인공지능출력):\n",
    "    로짓 = 인공지능출력.logits\n",
    "    return torch.exp(로짓) / torch.exp(로짓).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 데이터전처리하기2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 아래코드를 파고들어보자. \n",
    "\n",
    "```Python\n",
    "def 데이터전처리하기2(examples):\n",
    "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `examples['text']`의 쓰임으로 유추해본결과 examples에 가정된 입력의 형태?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I prefer making decisions based on logic and objective facts.',\n",
       " 'I always consider how others might feel when making a decision.',\n",
       " 'Data and analysis drive most of my decisions.',\n",
       " 'I rely on my empathy and personal values to guide my choices.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I prefer making decisions based on logic and objective facts.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 개념1: Hugging Face의 `datasets` 라이브러리에서 제공하는 `datasets.dataset_dict.DatasetDict`은, 요소들의 변환에 특화된 `map`이라는 메소드가(=함수가) 내장되어있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'text': [\n",
    "        \"I prefer making decisions based on logic and objective facts.\",\n",
    "        \"I always consider how others might feel when making a decision.\",\n",
    "        \"Data and analysis drive most of my decisions.\",\n",
    "        \"I rely on my empathy and personal values to guide my choices.\"\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    'text': [\n",
    "        \"I find it important to weigh all the pros and cons logically.\",\n",
    "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
    "    ],\n",
    "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
    "}\n",
    "train_data = datasets.Dataset.from_dict(train_dict)\n",
    "test_data = datasets.Dataset.from_dict(test_dict)\n",
    "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.dataset_dict.DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.dataset_dict.DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0m나의데이터\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwith_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatched\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_from_cache_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_file_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_nullable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_proc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdesc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DatasetDict'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Apply a function to all the elements in the table (individually or in batches)\n",
       "and update the table (if function does updated examples).\n",
       "The transformation is applied to all the datasets of the dataset dictionary.\n",
       "\n",
       "Args:\n",
       "    function (`callable`): with one of the following signature:\n",
       "        - `function(example: Dict[str, Any]) -> Dict[str, Any]` if `batched=False` and `with_indices=False`\n",
       "        - `function(example: Dict[str, Any], indices: int) -> Dict[str, Any]` if `batched=False` and `with_indices=True`\n",
       "        - `function(batch: Dict[str, List]) -> Dict[str, List]` if `batched=True` and `with_indices=False`\n",
       "        - `function(batch: Dict[str, List], indices: List[int]) -> Dict[str, List]` if `batched=True` and `with_indices=True`\n",
       "\n",
       "        For advanced usage, the function can also return a `pyarrow.Table`.\n",
       "        Moreover if your function returns nothing (`None`), then `map` will run your function and return the dataset unchanged.\n",
       "\n",
       "    with_indices (`bool`, defaults to `False`):\n",
       "        Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.\n",
       "    with_rank (`bool`, defaults to `False`):\n",
       "        Provide process rank to `function`. Note that in this case the\n",
       "        signature of `function` should be `def function(example[, idx], rank): ...`.\n",
       "    input_columns (`[Union[str, List[str]]]`, *optional*, defaults to `None`):\n",
       "        The columns to be passed into `function` as\n",
       "        positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.\n",
       "    batched (`bool`, defaults to `False`):\n",
       "        Provide batch of examples to `function`.\n",
       "    batch_size (`int`, *optional*, defaults to `1000`):\n",
       "        Number of examples per batch provided to `function` if `batched=True`,\n",
       "        `batch_size <= 0` or `batch_size == None` then provide the full dataset as a single batch to `function`.\n",
       "    drop_last_batch (`bool`, defaults to `False`):\n",
       "        Whether a last batch smaller than the batch_size should be\n",
       "        dropped instead of being processed by the function.\n",
       "    remove_columns (`[Union[str, List[str]]]`, *optional*, defaults to `None`):\n",
       "        Remove a selection of columns while doing the mapping.\n",
       "        Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding\n",
       "        columns with names in `remove_columns`, these columns will be kept.\n",
       "    keep_in_memory (`bool`, defaults to `False`):\n",
       "        Keep the dataset in memory instead of writing it to a cache file.\n",
       "    load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):\n",
       "        If a cache file storing the current computation from `function`\n",
       "        can be identified, use it instead of recomputing.\n",
       "    cache_file_names (`[Dict[str, str]]`, *optional*, defaults to `None`):\n",
       "        Provide the name of a path for the cache file. It is used to store the\n",
       "        results of the computation instead of the automatically generated cache file name.\n",
       "        You have to provide one `cache_file_name` per dataset in the dataset dictionary.\n",
       "    writer_batch_size (`int`, default `1000`):\n",
       "        Number of rows per write operation for the cache file writer.\n",
       "        This value is a good trade-off between memory usage during the processing, and processing speed.\n",
       "        Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.\n",
       "    features (`[datasets.Features]`, *optional*, defaults to `None`):\n",
       "        Use a specific [`Features`] to store the cache file\n",
       "        instead of the automatically generated one.\n",
       "    disable_nullable (`bool`, defaults to `False`):\n",
       "        Disallow null values in the table.\n",
       "    fn_kwargs (`Dict`, *optional*, defaults to `None`):\n",
       "        Keyword arguments to be passed to `function`\n",
       "    num_proc (`int`, *optional*, defaults to `None`):\n",
       "        Number of processes for multiprocessing. By default it doesn't\n",
       "        use multiprocessing.\n",
       "    desc (`str`, *optional*, defaults to `None`):\n",
       "        Meaningful description to be displayed alongside with the progress bar while mapping examples.\n",
       "\n",
       "Example:\n",
       "\n",
       "```py\n",
       ">>> from datasets import load_dataset\n",
       ">>> ds = load_dataset(\"rotten_tomatoes\")\n",
       ">>> def add_prefix(example):\n",
       "...     example[\"text\"] = \"Review: \" + example[\"text\"]\n",
       "...     return example\n",
       ">>> ds = ds.map(add_prefix)\n",
       ">>> ds[\"train\"][0:3][\"text\"]\n",
       "['Review: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       " 'Review: the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .',\n",
       " 'Review: effective but too-tepid biopic']\n",
       "\n",
       "# process a batch of examples\n",
       ">>> ds = ds.map(lambda example: tokenizer(example[\"text\"]), batched=True)\n",
       "# set number of processors\n",
       ">>> ds = ds.map(add_prefix, num_proc=4)\n",
       "```\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/dataset_dict.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "나의데이터.map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당장필요한내용: `datasets.dataset_dict.DatasetDict.map()`은 (1) `function`을 입력으로 받는데, (2) `function`은 Dict를 입력으로 받고 Dict를 출력하는 함수이어야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2347.12 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1523.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'I prefer making decisions based on logic and objective facts.',\n",
       "  'label': 0},\n",
       " {'text': 'I prefer making decisions based on logic and objective facts.',\n",
       "  'label': 0,\n",
       "  'dummy': '메롱'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "나의데이터['train'][0], 전처리된나의데이터['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I prefer making decisions based on logic and objective facts.', 'label': 0, 'dummy': '메롱'}\n",
      "{'text': 'I always consider how others might feel when making a decision.', 'label': 1, 'dummy': '메롱'}\n",
      "{'text': 'Data and analysis drive most of my decisions.', 'label': 0, 'dummy': '메롱'}\n",
      "{'text': 'I rely on my empathy and personal values to guide my choices.', 'label': 1, 'dummy': '메롱'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['train']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I find it important to weigh all the pros and cons logically.', 'label': 0, 'dummy': '메롱'}\n",
      "{'text': \"When making decisions, I prioritize harmony and people's emotions.\", 'label': 1, 'dummy': '메롱'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['test']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2474.15 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1539.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy':'메롱', 'label2': '사고형(T)'} if x['label'] == 0 else {'dummy':'메롱','label2': '감정형(F)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I prefer making decisions based on logic and objective facts.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': 'I always consider how others might feel when making a decision.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n",
      "{'text': 'Data and analysis drive most of my decisions.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': 'I rely on my empathy and personal values to guide my choices.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['train']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I find it important to weigh all the pros and cons logically.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
      "{'text': \"When making decisions, I prioritize harmony and people's emotions.\", 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n"
     ]
    }
   ],
   "source": [
    "for d in 전처리된나의데이터['test']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# 예시3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 데이터전처리하기2(examples):\n",
    "    return 데이터전처리하기1(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1189.87 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1161.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "전처리된나의데이터 = 나의데이터.map(데이터전처리하기2,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I prefer making decisions based on logic and objective facts.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  1045,\n",
       "  9544,\n",
       "  2437,\n",
       "  6567,\n",
       "  2241,\n",
       "  2006,\n",
       "  7961,\n",
       "  1998,\n",
       "  7863,\n",
       "  8866,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리된나의데이터['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 데이터콜렉터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 전처리된 데이터가 인공지능은 마음에 들지 않는다.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Data and analysis drive most of my decisions.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 2951, 1998, 4106, 3298, 2087, 1997, 2026, 6567, 1012, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리된나의데이터['train'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이유: `torch.tensor()` 자료형을 가지고 (n,m)의 행렬로 정리된 묶음 형태의 자료가 아니잖아?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||주어진자료| $\\overset{tokenizer,map}{\\Longrightarrow}$ 전처리된자료|$\\overset{datacollector}{\\Longrightarrow}$더전처리된자료|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|Dict의 Keys |`text`,`label`| `input_ids`, `attention_mask`, `label`| `input_ids`, `attention_mask`, `labels`| \n",
    "|자료의형태|텍스트,라벨|숫자화 O, 행렬화 X  | 숫자화 O, 행렬화 O\n",
    "|`torch.tensor`|- | X | O | \n",
    "|미니배치| - | X| O| \n",
    "|패딩/동적패딩| - | X | O|\n",
    "|예측할때|강인공지능의 입력|트레이너의 입력|인공지능의 입력|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터콜렉터에서 우리가 기대하는것: \n",
    "\n",
    "- 자료의 형태가 [Dict,Dict,Dict] 로 되어있는 경우^[`전처리된나의데이터['train']`이 이러한 형태로 되어있죠..] (3,??) 텐서의 `input_ids`, (3,??) 텐서의 `attention_mask`, (3,) 텐서의 labels 로 변환한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터콜렉터 사용방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m   \u001b[0m데이터콜렉터\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m        DataCollatorWithPadding\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert/distilbert-bas <...> e, special=True),\n",
       "           }, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/data/data_collator.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Data collator that will dynamically pad the inputs received.\n",
       "\n",
       "Args:\n",
       "    tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
       "        The tokenizer used for encoding the data.\n",
       "    padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
       "        Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
       "        among:\n",
       "\n",
       "        - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
       "          sequence is provided).\n",
       "        - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
       "          acceptable input length for the model if that argument is not provided.\n",
       "        - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
       "    max_length (`int`, *optional*):\n",
       "        Maximum length of the returned list and optionally padding length (see above).\n",
       "    pad_to_multiple_of (`int`, *optional*):\n",
       "        If set will pad the sequence to a multiple of the provided value.\n",
       "\n",
       "        This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
       "        7.5 (Volta).\n",
       "    return_tensors (`str`, *optional*, defaults to `\"pt\"`):\n",
       "        The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\"."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저,return_tensors='pt')\n",
    "데이터콜렉터?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당장필요한것: 입력은 `[딕셔너리, 딕셔너리, 딕셔너리, ...]` 의 형태 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045,  102,    0,    0],\n",
       "        [ 101, 1045, 9544,  102,    0],\n",
       "        [ 101, 1045, 9544, 9544,  102]]), 'attention_mask': tensor([[1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1]]), 'labels': tensor([0, 0, 1])}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "데이터콜렉터(\n",
    "    [\n",
    "        dict(label=0,input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
    "        dict(label=0,input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
    "        dict(label=1,input_ids=[101,1045,9544,9544,102],attention_mask=[1,1,1,1,1]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6744, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0877, -0.0312],\n",
       "        [ 0.0862, -0.0120],\n",
       "        [ 0.0964,  0.0002]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능(**데이터콜렉터(\n",
    "    [\n",
    "        dict(label=0,input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
    "        dict(label=0,input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
    "        dict(label=1,input_ids=[101,1045,9544,9544,102],attention_mask=[1,1,1,1,1]),\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `accuracy.compute`의 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3333333333333333}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.compute(references=[0, 0, 0], predictions=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 함수내용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def 평가하기(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     accuracy = evaluate.load(\"accuracy\")\n",
    "#     return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 평가하기(eval_pred):\n",
    "    계산된숫자들_로짓, 실제정답 = eval_pred\n",
    "    인공지능의예측 = np.argmax(계산된숫자들_로짓, axis=1)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    return accuracy.compute(predictions=인공지능의예측, references=실제정답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 트레이너"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. 트레이너의 제1역할 -- CPU에서 GPU로.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Step1~4 를 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Step1 \n",
    "데이터불러오기 = datasets.load_dataset\n",
    "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \n",
    "def 데이터전처리하기2(examples):\n",
    "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
    "## Step2 \n",
    "인공지능생성하기 = transformers.AutoModelForSequenceClassification.from_pretrained\n",
    "## Step3 \n",
    "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저)\n",
    "def 평가하기(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "트레이너세부지침생성기 = transformers.TrainingArguments\n",
    "트레이너생성기 = transformers.Trainer\n",
    "## Step4 \n",
    "강인공지능생성하기 = transformers.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Step1~2 까지의 코드 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /home/cgb3/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Thu Sep 26 23:35:50 2024).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "데이터 = 데이터불러오기('imdb')\n",
    "전처리된데이터 = 데이터.map(데이터전처리하기2,batched=True)\n",
    "전처리된훈련자료, 전처리된검증자료 = 전처리된데이터['train'], 전처리된데이터['test']\n",
    "## Step2 \n",
    "torch.manual_seed(43052)\n",
    "인공지능 = 인공지능생성하기(\"distilbert/distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
       "        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요한내용1: 숫자들\n",
    "- 중요한내용2: 나 CPU에 있어요.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능을 이용한 예측 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4642, 0.5358]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 트레이너 생성: 생성되자마자 하는일 = 모델을 CPU에서 GPU로 옮긴다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step3 \n",
    "트레이너세부지침 = 트레이너세부지침생성기(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2, # 전체문제세트를 2번 공부하라..\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "트레이너 = 트레이너생성기(\n",
    "    model=인공지능,\n",
    "    args=트레이너세부지침,\n",
    "    train_dataset=전처리된훈련자료,\n",
    "    eval_dataset=전처리된검증자료,\n",
    "    tokenizer=토크나이저,\n",
    "    data_collator=데이터콜렉터,\n",
    "    compute_metrics=평가하기,\n",
    ")\n",
    "# 트레이너.train()\n",
    "# ## Step4 \n",
    "# 강인공지능 = 강인공지능생성하기(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n",
    "# print(강인공지능(\"This movie was a huge disappointment.\"))\n",
    "# print(강인공지능(\"This was a masterpiece.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
       "        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요한내용1: 숫자들 (똑같나?) \n",
    "- 중요한내용2: `device='cuda:0'`, (나 GPU에 있어요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능을 이용한 예측 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]))) # 에러발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공지능은 GPU에 있는데, 데이터는 CPU에 있음.. $\\to$ 에러발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4642, 0.5358]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 트레이너의 제1역할: 트레이너는 생성과 동시에 하는역할이 있는데, 바로 인공지능을 GPU에 올리는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. 트레이너의 제2역할 -- 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 트레이너의 제2역할: `트레이너.predict()` 사용가능 \n",
    "\n",
    "- `트레이너.predict()`의 입력형태는 input_ids, attention_mask, label 이 존재하는 `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dict = {\n",
    "    'text': [\"This movie was a huge disappointment.\"],\n",
    "    'label': [0],\n",
    "    'input_ids': [[101, 2023, 3185, 2001, 1037, 4121, 10520, 1012, 102]],\n",
    "    'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "}\n",
    "sample_dataset = datasets.Dataset.from_dict(sample_dict)\n",
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.11731032,  0.02610314]], dtype=float32), label_ids=array([0]), metrics={'test_loss': 0.7674226760864258, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.0, 'test_runtime': 1.1668, 'test_samples_per_second': 0.857, 'test_steps_per_second': 0.857})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46420796, 0.53579204]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = np.array([[-0.11731032,  0.02610314]])\n",
    "np.exp(logits)/np.exp(logits).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 결과와 동일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4642, 0.5358]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 이렇게 쓰면 좋음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.08470809,  0.0023939 ],\n",
       "       [-0.08299972,  0.02850237],\n",
       "       [-0.06004279,  0.01801764],\n",
       "       ...,\n",
       "       [-0.02317078, -0.01451463],\n",
       "       [-0.00802051, -0.02698467],\n",
       "       [-0.03900156, -0.02573229]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.6949957609176636, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.4916, 'test_runtime': 94.7244, 'test_samples_per_second': 263.924, 'test_steps_per_second': 16.501})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(전처리된데이터['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train`에서 문제 품 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.03815563,  0.00212397],\n",
       "       [-0.08166712, -0.00432102],\n",
       "       [-0.10371644,  0.03148611],\n",
       "       ...,\n",
       "       [-0.08171435, -0.00681646],\n",
       "       [-0.09139054,  0.01050513],\n",
       "       [-0.06704493,  0.0221498 ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.6949934363365173, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.4912, 'test_runtime': 94.9759, 'test_samples_per_second': 263.225, 'test_steps_per_second': 16.457})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.predict(전처리된데이터['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `test`에서 문제 품 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. 트레이너의 제3역할 -- 학습 및 결과저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 12:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.233206</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3126, training_loss=0.20330691871472223, metrics={'train_runtime': 758.1933, 'train_samples_per_second': 65.946, 'train_steps_per_second': 4.123, 'total_flos': 6556904415524352.0, 'train_loss': 0.20330691871472223, 'epoch': 2.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "트레이너.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562.5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25000 / 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3126"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1563 * 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능이 똑똑해졌을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0230,  0.0279,  0.0239,  ...,  0.0085, -0.0062, -0.0143],\n",
       "        [ 0.0084,  0.0007, -0.0097,  ...,  0.0189, -0.0008,  0.0304]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "인공지능.classifier.weight # 진짜 살짝 바뀐것 같은데?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요한내용1: 숫자들 \n",
    "- 중요한내용2: `device='cuda:0'`, (나 GPU에 있어요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 인공지능의 파라메터 상태확인 2와 비교삿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "인공지능.classifier.weight\n",
    "```\n",
    "```\n",
    "Parameter containing:\n",
    "tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
    "        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
    "       device='cuda:0', requires_grad=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 숫자들이 바뀐걸 확인 $\\to$ 뭔가 다른 계산결과를 준다는 의미겠지? $\\to$ 진짜 그런지 보자.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9885, 0.0115]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0219, 0.9781]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")]).to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 강인공지능? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ref: <https://zdnet.co.kr/view/?no=20160622145838>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9885253310203552}]\n",
      "[{'label': 'LABEL_1', 'score': 0.978060781955719}]\n"
     ]
    }
   ],
   "source": [
    "강인공지능 = transformers.pipeline(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n",
    "print(강인공지능(\"This movie was a huge disappointment.\"))\n",
    "print(강인공지능(\"This was a masterpiece.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
