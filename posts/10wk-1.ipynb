{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cbfd508a-9de1-4f9e-8f36-9cfaf2b0c115",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"10wk-1: `Dataset` 클래스\"\n",
    "author: \"최규빈\"\n",
    "date: \"11/12/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bcf5f-7576-4fa1-a6c3-40a8361ed8b0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/10wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d792b1d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675c089",
   "metadata": {},
   "source": [
    "{{<video https://youtu.be/playlist?list=PLQqh36zP38-ykYDGqzZhVu08gNRipqhaf&si=fb8GRsvDxQY70mGh >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4c720",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d347ad-b4e1-4db2-a109-bcdbed72065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall mp2024pkg -y\n",
    "#!pip install git+https://github.com/guebin/mp2024pkg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ada738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets \n",
    "import transformers\n",
    "import torch\n",
    "from mp2024pkg import signature, show\n",
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ee6eed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = datasets.load_dataset('emotion')\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5af0c",
   "metadata": {},
   "source": [
    "# 3. Dataset 형식이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da4d55",
   "metadata": {},
   "source": [
    "`-` `emotion` 데이터셋 일부를 `d`로 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54703cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6a2f1",
   "metadata": {},
   "source": [
    "`-` `d` 는 아래와 같이 length-$n$ 인 list로 이해하는것이 편리하다. \n",
    "\n",
    "- dataset = [example_1, example_2, example_3 , example_4]\n",
    "- example_i = {'text': xxx, 'label': yyy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed6ab62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600293bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i didnt feel humiliated', 'label': 0},\n",
       " {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'label': 0},\n",
       " {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3},\n",
       " {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'label': 2}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[0],d[1],d[2],d[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccfd6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i didnt feel humiliated', 'label': 0},\n",
       " {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'label': 0},\n",
       " {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3},\n",
       " {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'label': 2}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30713f71",
   "metadata": {},
   "source": [
    "`-` 그런데 `Dataset`은 특이하게도 아래의 문법이 동작했었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "402c49be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89de636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 3, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f8033",
   "metadata": {},
   "source": [
    "`-` 위의 결과를 관찰하면 `Dataset` 는 마치 dictionary 처럼 느껴진다. 실제로 경우에 따라서 `Dataset`을 dictionary 처럼 생각해도 된다. 이때 `Dataset`은 아래와 같은 구조로 이해하는게 편리하다. \n",
    "\n",
    "- d = examples = {'text':[xxx,xxxx,xxxxx,xxxxxx], 'label':[yyy,yyyy,yyyyy,yyyyyy]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a66d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property'],\n",
       " 'label': [0, 0, 3, 2]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dct = {'text': d['text'], 'label':d['label']}\n",
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadcce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property'],\n",
       " 'label': [0, 0, 3, 2]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8902d",
   "metadata": {},
   "source": [
    "`-` 복습: 딕셔너리를 데이터프레임과 비슷하게 생각할 수 있었음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca83e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  2\n",
       "1  2  3\n",
       "2  3  4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'a':[1,2,3], 'b':[2,3,4]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ea6c6",
   "metadata": {},
   "source": [
    "`-` 이 개념을 확장하면 `d`역시 데이터프레임과 비슷하게 이해할 수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9236e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f63ce13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33537ce4",
   "metadata": {},
   "source": [
    "# 4. 쉬운 함수들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09f3ea",
   "metadata": {},
   "source": [
    "## A. `.select()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535e47d",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9c7318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d = datasets.Dataset.from_list([emotion['train'][0],emotion['train'][1],emotion['train'][2],emotion['train'][3]])\n",
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d07e09",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b52d5",
   "metadata": {},
   "source": [
    "## B. `.shuffle()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851d089",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff4c2352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6481cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'label': 2}\n",
      "\n",
      "2. list[1]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n",
      "\n",
      "3. list[2]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i didnt feel humiliated', 'label': 0}\n",
      "\n",
      "4. list[3]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "show(d.shuffle())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61de7a",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa0f1b",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f152a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emotion['train']에서 처음 4개의 observation/example 을 뽑는 코드\n",
    "d = emotion['train'].select(range(4))\n",
    "d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2546c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emotion['train']에서 랜덤으로 4개의 observation/example 을 뽑는 코드\n",
    "d = emotion['train'].shuffle().select(range(4))\n",
    "d "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4244bf",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119aa7d",
   "metadata": {},
   "source": [
    "## C. `.select_columns()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0c1b6",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d5059b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe36b7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.select_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17c0f85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.select_columns(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "04fac007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.select_columns(['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fac8b9",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6d069",
   "metadata": {},
   "source": [
    "## D. `.set_format()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6616e",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56e33c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "163e4de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf9f8c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              i didnt feel humiliated\n",
       "1    i can go from feeling so hopeless to so damned...\n",
       "2     im grabbing a minute to post i feel greedy wrong\n",
       "3    i am ever feeling nostalgic about the fireplac...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "588e713b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    3\n",
       "3    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45f98d",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e234d59",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4abdbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d54adce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type=\"pandas\",columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42e04d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8a447bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    3\n",
       "3    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644955e",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efea065",
   "metadata": {},
   "source": [
    "`# 예시3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ee352db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3a65a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type=\"pt\",columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2688cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ff11514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a519f88",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea3bf1",
   "metadata": {},
   "source": [
    "## E. `.reset_format()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70ed6e",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1318008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8cc229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type=\"pt\",columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2fa9950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d08b94ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 2])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aed2a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8729de49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f0ddd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 3, 2]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6135ad",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b855da",
   "metadata": {},
   "source": [
    "# 5. `.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92a789",
   "metadata": {},
   "source": [
    "## A. `d.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de3815",
   "metadata": {},
   "source": [
    "`# 예제1` -- `.map()`에 대한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ec27b",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32ca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36465c",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf6ff3",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7987f",
   "metadata": {},
   "source": [
    "`(풀이1)` -- `d.map()`을 사용하지 않은 풀이.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4415ad",
   "metadata": {},
   "source": [
    "*`d`는 아래와 같은 구조로 이해할 수 있음*\n",
    "\n",
    "-  d = [example_1, example_2, example_3, example_4]\n",
    "- example_i = {'text': xxx, 'label' = yyy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de4991",
   "metadata": {},
   "source": [
    "*리스트화*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e0b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i didnt feel humiliated', 'label': 0},\n",
       " {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'label': 0},\n",
       " {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3},\n",
       " {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'label': 2}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst = d.to_list()\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a74a9f",
   "metadata": {},
   "source": [
    "*리스트의 첫 요소에 변환적용*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e4df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = lst[0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ec7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = tokenizer(l['text'])\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3a24b",
   "metadata": {},
   "source": [
    "*`l`와 `tokenizer(l['text'])`을 합침*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52adb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc3ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b473825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0, 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l|r "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e4179",
   "metadata": {},
   "source": [
    "*반복*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbe193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i didnt feel humiliated', 'label': 0, 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0, 'input_ids': [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3, 'input_ids': [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'label': 2, 'input_ids': [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst2 = [l | tokenizer(l['text']) for l in lst]\n",
    "lst2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae0c24",
   "metadata": {},
   "source": [
    "*`lst2`를 `d2`로..*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8474e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = datasets.Dataset.from_list(lst2)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508891d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89165027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3c165",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85998db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = l = {'text': 'i didnt feel humiliated', 'label': 0} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcec82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980c600",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db35793d",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.map()`의 특징**\n",
    "\n",
    "- 특징1: `m_transform()`은 입력으로 `example = {'text':xxx, 'label':yyy}` 꼴을 가정한다. \n",
    "- 특징2: `.map()`은 변환전 dict와 변환후 dict를 합친다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1e9d0",
   "metadata": {},
   "source": [
    "## B. `dd.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b467a",
   "metadata": {},
   "source": [
    "`# 예제1` -- `dd`에도 `.map`을 적용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035db0b5",
   "metadata": {},
   "source": [
    "아래와 같은 DatasetDict가 있다고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b02b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = datasets.DatasetDict({\n",
    "    'train':emotion['train'].select(range(4)),\n",
    "    'test':emotion['test'].select(range(4)),\n",
    "})\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a0d23",
   "metadata": {},
   "source": [
    "`dd.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96783401",
   "metadata": {},
   "source": [
    "|tr/test|데이터|변환전|변환후|\n",
    "|:-|:-|:-|:-|\n",
    "|train|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|train|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|\n",
    "|test|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|test|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384478ac",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = l = {'text': 'i didnt feel humiliated', 'label': 0} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df41089",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = dd.map(m_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8aaf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21025349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['train'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb25361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'im feeling rather rotten so im not very ambitious right now',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  10047,\n",
       "  3110,\n",
       "  2738,\n",
       "  11083,\n",
       "  2061,\n",
       "  10047,\n",
       "  2025,\n",
       "  2200,\n",
       "  12479,\n",
       "  2157,\n",
       "  2085,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2179b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['im feeling rather rotten so im not very ambitious right now'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101,\n",
       "   10047,\n",
       "   3110,\n",
       "   2738,\n",
       "   11083,\n",
       "   2061,\n",
       "   10047,\n",
       "   2025,\n",
       "   2200,\n",
       "   12479,\n",
       "   2157,\n",
       "   2085,\n",
       "   102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['test'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0913c9",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8b603",
   "metadata": {},
   "source": [
    "## C. `d.map(batch=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ceb4a",
   "metadata": {},
   "source": [
    "`# 예제1` -- `d.map(batch=True)`의 이해 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208cf6b7",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(8))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37459659",
   "metadata": {},
   "source": [
    "`d.map(batch=True)`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541bc87",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|특이사항|\n",
    "|:-|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|변환시 2개의 example씩 묶어서 패딩|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|변환시 2개의 example씩 묶어서 패딩|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d71f52",
   "metadata": {},
   "source": [
    "`(풀이1)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text':xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'],padding=True)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f79700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d2<span style=\"font-weight: bold\">[</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">][</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d2\u001b[1m[\u001b[0m:\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: list\n",
      "   - Length: 7\n",
      "   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102]\n",
      "\n",
      "2. list[1]\n",
      "   - Type: list\n",
      "   - Length: 23\n",
      "   - Values: [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]\n",
      "\n",
      "3. list[2]\n",
      "   - Type: list\n",
      "   - Length: 12\n",
      "   - Values: [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102]\n",
      "\n",
      "4. list[3]\n",
      "   - Type: list\n",
      "   - Length: 22\n",
      "   - Values: [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102]\n"
     ]
    }
   ],
   "source": [
    "rprint(\"d2[:4]['input_ids']\")\n",
    "show(d2[:4]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5d5de",
   "metadata": {},
   "source": [
    "`(풀이2)` -- 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def m_transform(example):\n",
    "#     # example = {'text':xxx, 'label':yyy}\n",
    "#     result = tokenizer(example['text'], padding=True)\n",
    "#     return result \n",
    "def m_transform_batch(example_batch):\n",
    "    # example_batch = {'text':[xxx,xxxx], 'label':[yyy,yyyy]}\n",
    "    result = tokenizer(example_batch['text'], padding=True)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e504040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform_batch,batched=True,batch_size=2)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e605320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d2<span style=\"font-weight: bold\">[</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">][</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d2\u001b[1m[\u001b[0m:\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: list\n",
      "   - Length: 23\n",
      "   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "2. list[1]\n",
      "   - Type: list\n",
      "   - Length: 23\n",
      "   - Values: [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]\n",
      "\n",
      "3. list[2]\n",
      "   - Type: list\n",
      "   - Length: 22\n",
      "   - Values: [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "4. list[3]\n",
      "   - Type: list\n",
      "   - Length: 22\n",
      "   - Values: [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102]\n"
     ]
    }
   ],
   "source": [
    "rprint(\"d2[:4]['input_ids']\")\n",
    "show(d2[:4]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ca7db",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c4426",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.map(batch=True)`의 특징**\n",
    "\n",
    "- 특징1: `m_transform_batch()`은 입력으로 `example_batch = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}` 꼴을 가정한다. \n",
    "- 특징2: `example_batch`는 `batch_size`만큼 데이터가 있다고 생각한다.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a459c95",
   "metadata": {},
   "source": [
    "## D. `d.map()` + 칼럼선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae66e183",
   "metadata": {},
   "source": [
    "`# 예제1` -- attention_mask 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11f172",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d789c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f3953",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b618d",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec828d",
   "metadata": {},
   "source": [
    "`(풀이1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text':xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd730120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2 = d2.select_columns(['text', 'label', 'input_ids'])\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f07969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a5f38",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text':xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    del result['attention_mask']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62252da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dccd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f1256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28483f",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2172b2",
   "metadata": {},
   "source": [
    "`# 예제2` -- text 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499cba1",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666f161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4b45e",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c8b7e",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf12ca5",
   "metadata": {},
   "source": [
    "`(풀이1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55531b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    del example['text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4004c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ccdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ebd348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f4e7d",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ba1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2 = d2.select_columns(['label', 'input_ids', 'attention_mask'])\n",
    "d2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc2a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4061b",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068aead",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.map()`에서 컬럼을 제외하려면?**\n",
    "\n",
    "- `del`을 이용한 풀이: 제외하고자 하는 column이 `example`에 있을 경우, `result`에 있을 경우 미묘하게 다름. \n",
    "- `select`를 이용한 풀이: 제외하고자 하는 column이 `example`에 있든지 `result`에 있든지 상관없음.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebdcf3",
   "metadata": {},
   "source": [
    "## E. `d.map()` + 타입변환 ($\\star$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1cf45",
   "metadata": {},
   "source": [
    "`# 예제1` -- `.map()`을 이용한 타입변환은 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee0f6b9",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff5fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39849780",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0425a8e",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: int<br/>input_ids: tensor([int,...,int])<br/>attention_mask: tensor([int,...,int])|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label:[int]<br/>input_ids: tensor([[int,...,int]])<br/>attention_mask: tensor([[int,...,int]])|\n",
    "|d[:2]|text: [str,str]<br/>label: [int,int]|label:[int,int]<br/>input_ids: tensor([[int,...,int],[int,...,int]])<br/>attention_mask: tensor([[int,...,int],[int,...,int]])|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bcf5a",
   "metadata": {},
   "source": [
    "`(풀이1)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca58a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    del example['text']\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5342054",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.map(m_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2be005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f8090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa2e03",
   "metadata": {},
   "source": [
    "`(풀이2)` -- 실패 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c25608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'],return_tensors='pt')\n",
    "    del example['text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef90fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a673a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e424a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[[101, 1045, 2134, 2102, 2514, 26608, 102]]],\n",
       " 'attention_mask': [[[1, 1, 1, 1, 1, 1, 1]]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a749f",
   "metadata": {},
   "source": [
    "> 도데체 왜 자료형을 안바꿔주는거야?? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03cafe",
   "metadata": {},
   "source": [
    "`(풀이3)` -- 이것도 실패한다고? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dbac21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i didnt feel humiliated', 'label': 0},\n",
       " {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'label': 0},\n",
       " {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3},\n",
       " {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'label': 2}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst = d.to_list()\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f109b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 0, 'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'label': 0, 'input_ids': tensor([  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "          2003,  8300,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'label': 3, 'input_ids': tensor([  101, 10047,  9775,  1037,  3371,  2000,  2695,  1045,  2514, 20505,\n",
       "          3308,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'label': 2, 'input_ids': tensor([  101,  1045,  2572,  2412,  3110, 16839,  9080, 12863,  2055,  1996,\n",
       "         13788,  1045,  2097,  2113,  2008,  2009,  2003,  2145,  2006,  1996,\n",
       "          3200,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst2 = [] \n",
    "for l in lst:\n",
    "    result = tokenizer(l['text'])\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    del l['text']\n",
    "    lst2.append(l|result)\n",
    "lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55816b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = datasets.Dataset.from_list(lst2)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90086c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706911f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7afb27",
   "metadata": {},
   "source": [
    "`(풀이4)` -- 성공??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b297aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    del example['text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f18d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.set_format(type=\"pt\",columns=['input_ids','attention_mask'],output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c149121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f1ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'label': [0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d237205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " tensor([  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "          2003,  8300,   102])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:2]['input_ids'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603574e",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84f5b3",
   "metadata": {},
   "source": [
    "# 6. `.with_transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf7992",
   "metadata": {},
   "source": [
    "## A. `d.with_transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff9c92",
   "metadata": {},
   "source": [
    "`# 예제1` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a10fc",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e9f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c73a5c3",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5da02",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7783c4d",
   "metadata": {},
   "source": [
    "`(풀이1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded78ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property'],\n",
       " 'label': [0, 0, 3, 2]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dct = d.to_dict()\n",
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e55963",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer(d['text'])\n",
    "dct2 = dct | result\n",
    "d2 = datasets.Dataset.from_dict(dct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3550ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbba728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e39dc4",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01befa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples): \n",
    "    #examples = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = examples | result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b94b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45349311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7791bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618c808",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb4470",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.with_transform()`와 `.map()`의 차이점**\n",
    "\n",
    "1. `.map()`은 입력으로 example꼴을, `.with_transform()`은 입력으로 examples를 기대한다. \n",
    "2. `.map()`은 변환전과 변환후 데이터가 자동으로 합쳐진다. `.with_transform()`은 변환후 데이터만 살아남는다. \n",
    "3. `.map()`은 변환이 실제로 이루어진다. `.with_transform()`은 변환이 실제로 이루어지지 않다가 `d[0]`,`d[:1]` 등이 실행하는 순간 이루어진다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212b226",
   "metadata": {},
   "source": [
    "`# 예제2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a6ed5",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856d34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e7876",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f2cc3",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304d12a",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a960db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,....], 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    del result['attention_mask']\n",
    "    result['text'] = examples['text']\n",
    "    result['label'] = examples['label']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb0f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a8878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'text': 'i didnt feel humiliated',\n",
       " 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7575a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819cc30",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48dc7dc",
   "metadata": {},
   "source": [
    "`# 예제3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5869140",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bac87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f227c",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7fa51",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f933920",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa146e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,....], 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    result['label'] = examples['label']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce4efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad984071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91764c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'label': [0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2e2cb",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4fc97",
   "metadata": {},
   "source": [
    "`# 예제4`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44483e",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a4eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b9cce7",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e790d",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: tensor(int)<br/>input_ids: tensor([int,...,int])<br/>attention_mask: tensor([int,...,int])|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label: tensor([int])<br/>input_ids: tensor([[int,...,int]])<br/>attention_mask: tensor([[int,...,int]])|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85555968",
   "metadata": {},
   "source": [
    "`(풀이)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3490fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...],'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    result['label'] = torch.tensor(examples['label'])\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961255e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc425a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdcbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a8ce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 7 at dim 1 (got 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[43md2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n",
      "\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n",
      "\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n",
      "\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n",
      "\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n",
      "\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n",
      "\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:516\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n",
      "\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n",
      "\u001b[1;32m    515\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n",
      "\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m, in \u001b[0;36mw_transform\u001b[0;34m(examples)\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m tokenizer(examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m      4\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;32m----> 5\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      6\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 23)"
     ]
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976003c",
   "metadata": {},
   "source": [
    "*에러나는 이유*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ded93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake'],\n",
       " 'label': [0, 0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = d[:2]\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeea232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = tokenizer(examples['text'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710582d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.tensor(examples['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24581d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': tensor([0, 0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result['label'] = torch.tensor(examples['label'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01251c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 7 at dim 1 (got 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 23)"
     ]
    }
   ],
   "source": [
    "torch.tensor(result['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd0d6c",
   "metadata": {},
   "source": [
    "- 패딩.... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6a4cc",
   "metadata": {},
   "source": [
    "`(풀이2)` -- 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...],'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'],padding=True)\n",
    "    result['label'] = torch.tensor(examples['label'])\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac6775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fde507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd42bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "          2003,  8300,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d24af",
   "metadata": {},
   "source": [
    "`(풀이3)` -- 이것도 성공.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...],'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'],padding=True,return_tensors=\"pt\")\n",
    "    result['label'] = torch.tensor(examples['label'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5bdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2cebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca876c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "          2003,  8300,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48af02",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c052a",
   "metadata": {},
   "source": [
    "## B. `dd.with_transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad7410",
   "metadata": {},
   "source": [
    "`# 예제1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbf281",
   "metadata": {},
   "source": [
    "아래와 같은 DatasetDict가 있다고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070d0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = datasets.DatasetDict({\n",
    "    'train':emotion['train'].select(range(4)),\n",
    "    'test':emotion['test'].select(range(4)),\n",
    "})\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b1183",
   "metadata": {},
   "source": [
    "`dd.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf94455",
   "metadata": {},
   "source": [
    "|tr/test|데이터|변환전|변환후|\n",
    "|:-|:-|:-|:-|\n",
    "|train|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|train|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|\n",
    "|test|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|test|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229267f",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c990c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,....]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = examples | result \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2 = dd.with_transform(w_transform)\n",
    "dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0ae36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec87a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['train'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f12f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'im feeling rather rotten so im not very ambitious right now',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  10047,\n",
       "  3110,\n",
       "  2738,\n",
       "  11083,\n",
       "  2061,\n",
       "  10047,\n",
       "  2025,\n",
       "  2200,\n",
       "  12479,\n",
       "  2157,\n",
       "  2085,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20e219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['im feeling rather rotten so im not very ambitious right now'], 'label': [0], 'input_ids': [[101, 10047, 3110, 2738, 11083, 2061, 10047, 2025, 2200, 12479, 2157, 2085, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd2['test'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf0c12",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dbbe5c",
   "metadata": {},
   "source": [
    "## C. `d.reset_format()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84bf9d",
   "metadata": {},
   "source": [
    "`# 예시1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a9285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd141777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e59e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316085ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516c634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670667b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4c295",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80f462",
   "metadata": {},
   "source": [
    "`# 예시2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebab77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c58ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'],padding=True)\n",
    "    result['label'] = examples['label']\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bd89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefa6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9103728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'label': [0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cfd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': [0, 0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ed0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.set_format(type=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f6f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': tensor(0)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': tensor([0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake'],\n",
       " 'label': tensor([0, 0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526488ec",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1b003",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "`.with_transform` 은 `.set_format` 궁합이 안맞음\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd31b06",
   "metadata": {},
   "source": [
    "# 7. 미묘한 차이 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b532af",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646a092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text':xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...] 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = examples | result\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74f9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': tensor([0]),\n",
       " 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.set_format(type='pt')\n",
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35701795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': tensor([0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d3 = d.with_transform(w_transform)\n",
    "d3.set_format(type='pt')\n",
    "d3[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919f93a",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b2da6",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1c454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text':xxx, 'label':yyy}\n",
    "    result = tokenizer(example['text'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text':[xxx,xxxx,...] 'label':[yyy,yyyy,...]}\n",
    "    result = tokenizer(examples['text'],return_tensors=\"pt\")\n",
    "    result = examples | result\n",
    "    result['label'] = torch.tensor(result['label'])\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f4d37",
   "metadata": {},
   "source": [
    "*여기까지는 두 코드 같아보이는데*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a33e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': tensor([0]),\n",
       " 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.set_format(type='pt')\n",
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf82c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': tensor([0]), 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d3 = d.with_transform(w_transform)\n",
    "d3[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72b584",
   "metadata": {},
   "source": [
    "*아래는 미묘하게 다름*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a3175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake'],\n",
       " 'label': tensor([0, 0]),\n",
       " 'input_ids': [tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       "  tensor([  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "           9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "           2003,  8300,   102])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.set_format(type='pt')\n",
    "d2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb059a3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:776\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n",
      "\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n",
      "\u001b[0;32m--> 776\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n",
      "\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n",
      "\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n",
      "\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n",
      "\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n",
      "\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:738\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n",
      "\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(value))\n",
      "\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 23)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[194], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m d3 \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mwith_transform(w_transform)\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43md3\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n",
      "\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n",
      "\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n",
      "\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n",
      "\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n",
      "\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n",
      "\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:516\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n",
      "\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n",
      "\u001b[1;32m    515\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n",
      "\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[185], line 3\u001b[0m, in \u001b[0;36mw_transform\u001b[0;34m(examples)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mw_transform\u001b[39m(examples):\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# examples = {'text':[xxx,xxxx,...] 'label':[yyy,yyyy,...]}\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m     result \u001b[38;5;241m=\u001b[39m examples \u001b[38;5;241m|\u001b[39m result\n",
      "\u001b[1;32m      5\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n",
      "\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3109\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   3104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m   3105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   3106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   3107\u001b[0m         )\n",
      "\u001b[1;32m   3108\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n",
      "\u001b[0;32m-> 3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n",
      "\u001b[1;32m   3132\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n",
      "\u001b[1;32m   3133\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   3151\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
      "\u001b[1;32m   3152\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3311\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   3301\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n",
      "\u001b[1;32m   3302\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n",
      "\u001b[1;32m   3303\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n",
      "\u001b[1;32m   3304\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   3308\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
      "\u001b[1;32m   3309\u001b[0m )\n",
      "\u001b[0;32m-> 3311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   3331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:577\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n",
      "\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n",
      "\u001b[0;32m--> 577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:240\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n",
      "\u001b[1;32m    236\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n",
      "\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n",
      "\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:792\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n",
      "\u001b[1;32m    787\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;32m    788\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    789\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    791\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;32m--> 792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    795\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    796\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    797\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "d3 = d.with_transform(w_transform)\n",
    "d3[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467e6df",
   "metadata": {},
   "source": [
    "`#`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
