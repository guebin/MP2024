{"title":"**Quiz-2 (2024.09.24)**  // 범위: 02wk-1 까지","markdown":{"yaml":{"title":"**Quiz-2 (2024.09.24)**  // 범위: 02wk-1 까지","author":"최규빈","date":"09/24/2024","comments":false},"headingText":"`1`. `emotion` 자료 탐색 -- 10점","containsRefs":false,"markdown":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/quiz/Quiz-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n| **항목**               | **허용 여부**        | **비고**                                          |\n|------------------------|----------------------|---------------------------------------------------|\n| **강의노트 참고**      | 허용                 | 수업 중 제공된 강의노트나 본인이 정리한 자료를 참고 가능       |\n| **구글 검색**          | 허용                 | 인터넷을 통한 자료 검색 및 정보 확인 가능        |\n| **생성 모형 사용**           | 허용 안함            | 인공지능 기반 도구(GPT 등) 사용 불가            |\n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-zC5AHlxLrDjjYJRbFt7SoJ&si=vVf4ikZJSLGVsNvB >}}\n\n\n> (1)-(2) 모두 부분점수 없음.\n\n아래는 Hugging Face의 `emotion` 데이터셋을 로드하는 코드이다: \n\n`emotion['train'][-2]`는 훈련 데이터의 두 번째 마지막 항목을 출력한다. 출력된 샘플은 다음과 같다.\n\n출력된 샘플은 딕셔너리 형식으로, text에는 문장 \"i feel like this was such a rude comment and im glad that t\"이 담겨 있다. 이 문장의 감정은 label 항목에 저장되어 있으며, 값은 3으로 나타난다. label 값은 해당 텍스트가 표현하는 감정을 숫자로 표현한 것이다.\n\n감정 레이블은 총 6가지로 나뉘며, 각각의 감정은 다음과 같이 정의된다:\n\n따라서, 문장 \"i feel like this was such a rude comment and im glad that t\" 의 감정은 `label`이 3이므로, \"anger\"에 해당한다.\n\n`(1)` `emotion` 데이터셋의 각 분할(train, validation, test)에서 감정별로 몇 개의 데이터가 있는지를 조사하라. 즉 아래의 표에서 빈칸에 해당하는 숫자를 계산할 수 있는 코드를 제시하라. -- 5점\n\n| Dataset    | 0:Sadness | 1:Joy   | 2:Love  | 3:Anger | 4:Fear  | 5:Surprise | Total  |\n|------------|-----------|---------|---------|---------|---------|------------|--------|\n| Train      | ??      | ??    | ??    | ??    | ??    | ??       | 16000  |\n| Validation | ??      | ??    | ??    | ??    | ??    | ??       | 2000   |\n| Test       | ??      | ??    | ??    | ??    | ??    | ??       | 2000   |\n\n**note:** 정답예시: 아래와 같은 형식으로 출력하는 코드를 작성하면 정답으로 인정\n\n```\ntrain\n{0: 4666, 1: 5362, 2: 1304, 3: 2159, 4: 1937, 5: 572}\n--\nvalidation\n{0: 550, 1: 704, 2: 178, 3: 275, 4: 212, 5: 81}\n--\ntest\n{0: 581, 1: 695, 2: 159, 3: 275, 4: 224, 5: 66}\n--\n```\n\n**hint**: 아래중 원하는 형태를 이용하여 풀이하면 편리하다. \n\n- `emotion['train']['label']`\n- `emotion['train'].to_dict()`\n- `emotion['train'].to_pandas()`\n\n(풀이)\n\n`(2)` `emotion` 데이터셋의 `test`셋에서 각 감정(label)별로 가장 짧은 길이를 가진 텍스트를 출력하는 코드를 작성하라. -- 5점\n\n**note**: 정답예시는 아래와 같다. \n\n```\n['i feels so lame',\n 'i feel any better',\n 'i just feel tender',\n 'i feel so damn agitated',\n 'i feel alarmed',\n 'i feel all funny sometimes']\n```\n\n(풀이1)\n\n(풀이2)\n\n# `2`. `emotion` 자료 감성분석 -- 80점\n\n> (1)은 부분점수 있음, (2)는 부분점수 없음. \n\n`(1)` 아래의 reference 를 참고하여 `emotion`에 대한 감성분석모델을 학습하는 코드를 작성하라. -- 60점\n\nref: \n\n- <https://guebin.github.io/MP2024/posts/02wk-1.html>\n- <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n\n**세부지침** -- 세부지침을 따르지 않을시 감점이 있음 (지침1은 30점감점 지침2는 5점감점)\n\n`지침1`. `Trainer`생성시 `eval_dataset`에는 `emotion['validation']`를 전처리한 데이터를 이용하라. (`emotion['test']` 가 아니라)\n\n`지침2`. `TrainingArguments`에서 `num_train_epochs`은 1로 설정하라. \n\n**hint**: `imdb` 자료의 경우 `num_labels = 2` 이지만, `emotion` 자료의 경우 그렇지 않음을 유의하라. \n\n(풀이)\n\n`(2)` `1-(2)`에서 구해진 text에 대하여 감성분석을 수행하라. -- 20점\n\n**힌트** `1-(2)`를 풀지못하였다면 아래의 코드를 이용하여 강제설정할 것 \n\n```Python\n['i feels so lame',\n 'i feel any better',\n 'i just feel tender',\n 'i feel so damn agitated',\n 'i feel alarmed',\n 'i feel all funny sometimes']\n```\n\n# `3`. O/X. -- 10점\n\n> 모두 맞출경우만 정답으로 인정 \n\n아래의 제시문을 읽고 올바르게 해석한 사람을 모두 고르라.\n\n:::{.callout-note}\n\n나는 50,000개의 \"텍스트-라벨\" 데이터를 인공지능에게 학습시켰다. 학습이 끝난 후, 50,000개의 데이터 중 20개의 샘플을 무작위로 뽑아 테스트한 결과, 인공지능은 20개의 텍스트에 대한 라벨을 모두 정확히 맞췄다. 이 결과만으로 인공지능이 영화 리뷰에 대한 감성 분석(긍정/부정)을 성공적으로 학습했다고 결론을 내려도 될까?\n:::\n\n`민지`: 제시문에 따르면 50,000개의 훈련 데이터를 사용하여 인공지능을 학습시켰으니, `train_data`의 크기는 50,000이라고 볼 수 있어.\n\n`하니`: 50,000개의 데이터 중 일부를 무작위로 샘플링하여 평가하는 것은 올바른 방법이 아니야. 학습에 사용되지 않은 별도의 테스트 데이터를 사용해 성능을 평가해야 인공지능이 제대로 학습했는지 알 수 있어.\n\n`다니엘`: 하니의 말이 맞아. 50,000개의 데이터 중 20개를 샘플링한 게 아니라, 50,000개의 데이터를 모두 올바르게 맞췄다고 하더라도, 새로운 데이터에 대해 성능이 좋다고 단정할 수는 없어. 중요한 건 새로운 데이터에 대한 예측 성능이지.\n\n`해린`: 맞아, 훈련 데이터 (=학습 데이터) 를 너무 반복해서 학습하다 보면, 인공지능이 그 데이터에만 지나치게 맞춰져서 새로운 데이터를 잘 처리하지 못할 수 있어. 결국 모델이 학습 데이터에서는 좋은 성능을 내지만, 학습하지 않은 데이터나 실제 환경에서는 성능이 떨어질 위험이 생기는 거야.\"\n\n`혜인`: 그렇구나! 그래서 50,000개의 데이터가 있더라도, 그 중 일부만 학습에 사용하고, 나머지는 평가용으로 따로 남겨두기도 하는 거네. 이렇게 하면 인공지능이 새로운 데이터에서도 잘 작동하는지, 성능을 확인할 수 있는 거잖아?\n\n> 모두 정답\n","srcMarkdownNoYaml":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/quiz/Quiz-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n| **항목**               | **허용 여부**        | **비고**                                          |\n|------------------------|----------------------|---------------------------------------------------|\n| **강의노트 참고**      | 허용                 | 수업 중 제공된 강의노트나 본인이 정리한 자료를 참고 가능       |\n| **구글 검색**          | 허용                 | 인터넷을 통한 자료 검색 및 정보 확인 가능        |\n| **생성 모형 사용**           | 허용 안함            | 인공지능 기반 도구(GPT 등) 사용 불가            |\n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-zC5AHlxLrDjjYJRbFt7SoJ&si=vVf4ikZJSLGVsNvB >}}\n\n# `1`. `emotion` 자료 탐색 -- 10점\n\n> (1)-(2) 모두 부분점수 없음.\n\n아래는 Hugging Face의 `emotion` 데이터셋을 로드하는 코드이다: \n\n`emotion['train'][-2]`는 훈련 데이터의 두 번째 마지막 항목을 출력한다. 출력된 샘플은 다음과 같다.\n\n출력된 샘플은 딕셔너리 형식으로, text에는 문장 \"i feel like this was such a rude comment and im glad that t\"이 담겨 있다. 이 문장의 감정은 label 항목에 저장되어 있으며, 값은 3으로 나타난다. label 값은 해당 텍스트가 표현하는 감정을 숫자로 표현한 것이다.\n\n감정 레이블은 총 6가지로 나뉘며, 각각의 감정은 다음과 같이 정의된다:\n\n따라서, 문장 \"i feel like this was such a rude comment and im glad that t\" 의 감정은 `label`이 3이므로, \"anger\"에 해당한다.\n\n`(1)` `emotion` 데이터셋의 각 분할(train, validation, test)에서 감정별로 몇 개의 데이터가 있는지를 조사하라. 즉 아래의 표에서 빈칸에 해당하는 숫자를 계산할 수 있는 코드를 제시하라. -- 5점\n\n| Dataset    | 0:Sadness | 1:Joy   | 2:Love  | 3:Anger | 4:Fear  | 5:Surprise | Total  |\n|------------|-----------|---------|---------|---------|---------|------------|--------|\n| Train      | ??      | ??    | ??    | ??    | ??    | ??       | 16000  |\n| Validation | ??      | ??    | ??    | ??    | ??    | ??       | 2000   |\n| Test       | ??      | ??    | ??    | ??    | ??    | ??       | 2000   |\n\n**note:** 정답예시: 아래와 같은 형식으로 출력하는 코드를 작성하면 정답으로 인정\n\n```\ntrain\n{0: 4666, 1: 5362, 2: 1304, 3: 2159, 4: 1937, 5: 572}\n--\nvalidation\n{0: 550, 1: 704, 2: 178, 3: 275, 4: 212, 5: 81}\n--\ntest\n{0: 581, 1: 695, 2: 159, 3: 275, 4: 224, 5: 66}\n--\n```\n\n**hint**: 아래중 원하는 형태를 이용하여 풀이하면 편리하다. \n\n- `emotion['train']['label']`\n- `emotion['train'].to_dict()`\n- `emotion['train'].to_pandas()`\n\n(풀이)\n\n`(2)` `emotion` 데이터셋의 `test`셋에서 각 감정(label)별로 가장 짧은 길이를 가진 텍스트를 출력하는 코드를 작성하라. -- 5점\n\n**note**: 정답예시는 아래와 같다. \n\n```\n['i feels so lame',\n 'i feel any better',\n 'i just feel tender',\n 'i feel so damn agitated',\n 'i feel alarmed',\n 'i feel all funny sometimes']\n```\n\n(풀이1)\n\n(풀이2)\n\n# `2`. `emotion` 자료 감성분석 -- 80점\n\n> (1)은 부분점수 있음, (2)는 부분점수 없음. \n\n`(1)` 아래의 reference 를 참고하여 `emotion`에 대한 감성분석모델을 학습하는 코드를 작성하라. -- 60점\n\nref: \n\n- <https://guebin.github.io/MP2024/posts/02wk-1.html>\n- <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n\n**세부지침** -- 세부지침을 따르지 않을시 감점이 있음 (지침1은 30점감점 지침2는 5점감점)\n\n`지침1`. `Trainer`생성시 `eval_dataset`에는 `emotion['validation']`를 전처리한 데이터를 이용하라. (`emotion['test']` 가 아니라)\n\n`지침2`. `TrainingArguments`에서 `num_train_epochs`은 1로 설정하라. \n\n**hint**: `imdb` 자료의 경우 `num_labels = 2` 이지만, `emotion` 자료의 경우 그렇지 않음을 유의하라. \n\n(풀이)\n\n`(2)` `1-(2)`에서 구해진 text에 대하여 감성분석을 수행하라. -- 20점\n\n**힌트** `1-(2)`를 풀지못하였다면 아래의 코드를 이용하여 강제설정할 것 \n\n```Python\n['i feels so lame',\n 'i feel any better',\n 'i just feel tender',\n 'i feel so damn agitated',\n 'i feel alarmed',\n 'i feel all funny sometimes']\n```\n\n# `3`. O/X. -- 10점\n\n> 모두 맞출경우만 정답으로 인정 \n\n아래의 제시문을 읽고 올바르게 해석한 사람을 모두 고르라.\n\n:::{.callout-note}\n\n나는 50,000개의 \"텍스트-라벨\" 데이터를 인공지능에게 학습시켰다. 학습이 끝난 후, 50,000개의 데이터 중 20개의 샘플을 무작위로 뽑아 테스트한 결과, 인공지능은 20개의 텍스트에 대한 라벨을 모두 정확히 맞췄다. 이 결과만으로 인공지능이 영화 리뷰에 대한 감성 분석(긍정/부정)을 성공적으로 학습했다고 결론을 내려도 될까?\n:::\n\n`민지`: 제시문에 따르면 50,000개의 훈련 데이터를 사용하여 인공지능을 학습시켰으니, `train_data`의 크기는 50,000이라고 볼 수 있어.\n\n`하니`: 50,000개의 데이터 중 일부를 무작위로 샘플링하여 평가하는 것은 올바른 방법이 아니야. 학습에 사용되지 않은 별도의 테스트 데이터를 사용해 성능을 평가해야 인공지능이 제대로 학습했는지 알 수 있어.\n\n`다니엘`: 하니의 말이 맞아. 50,000개의 데이터 중 20개를 샘플링한 게 아니라, 50,000개의 데이터를 모두 올바르게 맞췄다고 하더라도, 새로운 데이터에 대해 성능이 좋다고 단정할 수는 없어. 중요한 건 새로운 데이터에 대한 예측 성능이지.\n\n`해린`: 맞아, 훈련 데이터 (=학습 데이터) 를 너무 반복해서 학습하다 보면, 인공지능이 그 데이터에만 지나치게 맞춰져서 새로운 데이터를 잘 처리하지 못할 수 있어. 결국 모델이 학습 데이터에서는 좋은 성능을 내지만, 학습하지 않은 데이터나 실제 환경에서는 성능이 떨어질 위험이 생기는 거야.\"\n\n`혜인`: 그렇구나! 그래서 50,000개의 데이터가 있더라도, 그 중 일부만 학습에 사용하고, 나머지는 평가용으로 따로 남겨두기도 하는 거네. 이렇게 하면 인공지능이 새로운 데이터에서도 잘 작동하는지, 성능을 확인할 수 있는 거잖아?\n\n> 모두 정답\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"Quiz-2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.533","theme":"cosmo","title":"**Quiz-2 (2024.09.24)**  // 범위: 02wk-1 까지","author":"최규빈","date":"09/24/2024","comments":false},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}