{"title":"04wk-1: 감성분석 파고들기 (2)","markdown":{"yaml":{"title":"04wk-1: 감성분석 파고들기 (2)","author":"최규빈","date":"09/27/2024","draft":false},"headingText":"1. 강의영상","containsRefs":false,"markdown":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/04wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-yH7aA3RY7GNf1qNIgU6CDs&si=e4-tQHb8cD0FhrUW >}}\n\n# 2. Imports \n\n# 3. 이전시간 요약\n\n`-` 이전시간의 내용중 이번시간에 기억할것들을 요약 \n\n`-` `DatasetDict`: 임의의 자료에 대한 `DatasetDict` 오브젝트 만들기\n\n`-` `토크나이저`: 토크나이저는 \"`Str` $\\to$ `Dict`\" 인 함수이다.\n\n`-` `토크나이저`: 토크나이저의 \"`Str` $\\to$ `Dict`\" 인 함수는 배치처리가 가능하다. \n\n`-` `인공지능`: 인공지능은 많은 파라메터를 포함하고 있는 어떠한 물체이다. \n\n`-` `인공지능`: 인공지능의 파라메터는 변화할 수 있으며, loss가 더 작은쪽으로 파라메터를 변화시키는 과정을 \"학습\"이라고 부른다. \n\n`-` `인공지능`: 인공지능은 \"`**Dict` $\\to$ `transformers.modeling_outputs.SequenceClassifierOutput`\"인 함수이다. 그런데 쓰기 까다롭다.\n\n- `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`, `attention_mask`) \n- `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`. 따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n- `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음) \n\n`#` 인공지능의 입력예시1 -- 텐서형으로 정리된 텍스트자료만 있는 경우 \n\n`#`\n\n`#` 인공지능의 입력예시2 -- 텐서형으로 정리된 텍스트자료와 `labels`이 같이 있는경우 \n\n`#`\n\n`-` `인공지능`: 인공지능의 출력결과^[`transformers.modeling_outputs.SequenceClassifierOutput` 자료형을 가짐] 에서 확률/예측값을 추출하는 방법 \n\n- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 확률 $\\to$ 인공지능의예측\n- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 인공지능의예측\n\n**예제1:** 인공지능의 출력결과에서 인공지능의 예측값을 계산하자. -- 로짓 $\\to$ 인공지능의예측\n\n**예제2:** 인공지능의 출력결과에서 인공지능의 예측확률을 계산하자 -- 로짓 $\\to$ 확률\n\n`확률게산하기`라는 함수선언하여 외의 과정을 단순화 하기 \n\n`#`\n\n# 4. 데이터전처리하기2\n\n`-` 아래코드를 파고들어보자. \n\n```Python\ndef 데이터전처리하기2(examples):\n    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n```\n\n`-` 인공지능의 입력으로 가정된 두가지 경우: (1) 토크나이징결과, (2) 토크나이징결과 + label\n\n- (2) 와 같은 형태의 입력을 정리하기 위해서는, `{'text':[...], 'label':[...]}` 이러한 형태로 정리된 자료를  `{'text':[...], 'label':[...], 'input_ids':[...], 'attention_mask':[...]}` 이러한 형태로 만들어야 하는데 이를 쉽게처리해주는 함수가 바로 `나의데이터.map()` 임. \n- `나의데이터.map()`의 도움말을 확인해본 결과 map은 (1) function 자체를 입력으로 받는데 (2) function 은 Dict를 입력으로 받고, Dict를 출력하는 함수이어야 한다는 사실을 확인할 수 있었음. \n\n`-` 개념1: Hugging Face의 `datasets` 라이브러리에서 제공하는 `datasets.dataset_dict.DatasetDict`은, 요소들의 변환에 특화된 `map`이라는 메소드가(=함수가) 내장되어있다. \n\n`# 예시1` -- 메롱\n\n`#`\n\n`# 예시2` -- Text의 length 계산 \n\n`#`\n\n`# 예시2` -- 토크나이징결과 \n\n`#`\n\n# 5. 데이터콜렉터 \n\n`-` 전터리된 데이터가 인공지능은 마음에 들지 않는다. \n\n- 이유: 인공지능은 `torch.tensor()` 자료형을 가지며 (n,m)의 행렬로 정리된 \"묶음\" 형태의 자료형을 기대함. \n\n`-` 자료처리과정요약 \n\n||주어진자료| $\\overset{tokenizer,map}{\\Longrightarrow}$ 전처리된자료|$\\overset{datacollector}{\\Longrightarrow}$더전처리된자료|\n|:--:|:--:|:--:|:--:|\n|Dict의 Keys |`text`,`label`| `input_ids`, `attention_mask`, `label`| `input_ids`, `attention_mask`, `labels`| \n|자료의형태|텍스트,라벨|숫자화 O, 행렬화 X  | 숫자화 O, 행렬화 O\n|`torch.tensor`|- | X | O | \n|미니배치| - | X| O| \n|패딩/동적패딩| - | X | O|\n|예측할때|강인공지능의 입력|트레이너의 입력|인공지능의 입력|\n\n`-` 데이터콜렉터에서 우리가 기대하는 것:\n\n- 자료의 형태가 [Dict,Dict,Dict,Dict] 로 되어있는 경우^[`전처리된나의데이터['train']`이 이러한 형태로 되어있음] (4,??) shape 텐서의 `input_ids`, (4,??) shape 텐서의 `attention_mask`, 그리고 (4,) shape 텐서의 `labels`로 변환해줌. \n\n`-` 데이터콜렉터 사용방법 \n\n# 6. 평가하기\n\n`-` `accuracy.compute`의 기능\n\n`-` `평가하기` 함수의 내용 \n\n# 7. 트레이너\n\n`-` 이전코드\n\n## A. 트레이너의 제1역할 -- CPU에서 GPU로.. \n\n### `#` 트레이너 생성전\n\n`-` 인공지능의 파라메터 상태확인 1\n\n- 중요한내용1: 숫자들 = 초기숫자들\n- 중요한내용2: 숫자들이 CPU에 존재한다는 의미\n\n`-` 인공지능을 이용한 예측 1\n\n### `#` 트레이너 생성후 \n\n`-` 트레이너생성 \n\n`-` 인공지능의 파라메터 상태확인 2\n\n- 중요한내용1: 숫자들 = 초기숫자들\n- 중요한내용2: device=\"cuda:0\" // 숫자들이 GPU에 있다는 의미 \n\n`-` 인공지능을 이용한 예측 2\n\n> 트레이너의 제1역할: 트레이너는 생성과 동시에 하는역할이 있는데, 바로 인공지능의 파라메터를 GPU에 올리는 것이다. \n\n## B. 트레이너의 제2역할 -- 예측하기 \n\n> 트레이너의 제2역할: `트레이너.predict()` 사용가능. `트레이너.predict()`의 입력형태는 input_ids, attention_mask, label 이 존재하는 `Dataset`\n\n`# 예제1` 트레이너를 이용한 예측 \n\n`#`\n\n`# 예제2` -- 트레이너를 이용하여 `train_data`, `test_data` 의 prediction 값을 구하라. \n\n`#`\n\n## C. 트레이너의 제3역할 -- 학습 및 결과저장\n\n### `#` 학습\n\n### `#` 학습후\n\n`-` 인공지능이 똑똑해졌을까?\n\n`-` 인공지능의 파라메터 상태확인 3\n\n*인공지능의 파라메터 상태확인 2와 비교삿*\n\n```\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       device='cuda:0', requires_grad=True)\n```\n\n*숫자들이 바뀐걸 확인 $\\to$ 뭔가 다른 계산결과를 준다는 의미겠지? $\\to$ 진짜 그런지 보자..*\n\n`-` 인공지능을 이용한 예측 3\n\n`-` 다시 트레이너를 이용하여 `train_data`, `test_data` 의 prediction 값을 구해보자. \n\n`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O\n\n# 8. 파이프라인\n\n`-` 강인공지능? \n\n> ref: <https://zdnet.co.kr/view/?no=20160622145838>\n","srcMarkdownNoYaml":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/04wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n# 1. 강의영상 \n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-yH7aA3RY7GNf1qNIgU6CDs&si=e4-tQHb8cD0FhrUW >}}\n\n# 2. Imports \n\n# 3. 이전시간 요약\n\n`-` 이전시간의 내용중 이번시간에 기억할것들을 요약 \n\n`-` `DatasetDict`: 임의의 자료에 대한 `DatasetDict` 오브젝트 만들기\n\n`-` `토크나이저`: 토크나이저는 \"`Str` $\\to$ `Dict`\" 인 함수이다.\n\n`-` `토크나이저`: 토크나이저의 \"`Str` $\\to$ `Dict`\" 인 함수는 배치처리가 가능하다. \n\n`-` `인공지능`: 인공지능은 많은 파라메터를 포함하고 있는 어떠한 물체이다. \n\n`-` `인공지능`: 인공지능의 파라메터는 변화할 수 있으며, loss가 더 작은쪽으로 파라메터를 변화시키는 과정을 \"학습\"이라고 부른다. \n\n`-` `인공지능`: 인공지능은 \"`**Dict` $\\to$ `transformers.modeling_outputs.SequenceClassifierOutput`\"인 함수이다. 그런데 쓰기 까다롭다.\n\n- `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`, `attention_mask`) \n- `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`. 따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n- `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다. (그리고 이걸 계산해야지 학습을 할 수 있음) \n\n`#` 인공지능의 입력예시1 -- 텐서형으로 정리된 텍스트자료만 있는 경우 \n\n`#`\n\n`#` 인공지능의 입력예시2 -- 텐서형으로 정리된 텍스트자료와 `labels`이 같이 있는경우 \n\n`#`\n\n`-` `인공지능`: 인공지능의 출력결과^[`transformers.modeling_outputs.SequenceClassifierOutput` 자료형을 가짐] 에서 확률/예측값을 추출하는 방법 \n\n- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 확률 $\\to$ 인공지능의예측\n- 인공지능의 출력결과 $\\to$ 로짓 $\\to$ 인공지능의예측\n\n**예제1:** 인공지능의 출력결과에서 인공지능의 예측값을 계산하자. -- 로짓 $\\to$ 인공지능의예측\n\n**예제2:** 인공지능의 출력결과에서 인공지능의 예측확률을 계산하자 -- 로짓 $\\to$ 확률\n\n`확률게산하기`라는 함수선언하여 외의 과정을 단순화 하기 \n\n`#`\n\n# 4. 데이터전처리하기2\n\n`-` 아래코드를 파고들어보자. \n\n```Python\ndef 데이터전처리하기2(examples):\n    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n```\n\n`-` 인공지능의 입력으로 가정된 두가지 경우: (1) 토크나이징결과, (2) 토크나이징결과 + label\n\n- (2) 와 같은 형태의 입력을 정리하기 위해서는, `{'text':[...], 'label':[...]}` 이러한 형태로 정리된 자료를  `{'text':[...], 'label':[...], 'input_ids':[...], 'attention_mask':[...]}` 이러한 형태로 만들어야 하는데 이를 쉽게처리해주는 함수가 바로 `나의데이터.map()` 임. \n- `나의데이터.map()`의 도움말을 확인해본 결과 map은 (1) function 자체를 입력으로 받는데 (2) function 은 Dict를 입력으로 받고, Dict를 출력하는 함수이어야 한다는 사실을 확인할 수 있었음. \n\n`-` 개념1: Hugging Face의 `datasets` 라이브러리에서 제공하는 `datasets.dataset_dict.DatasetDict`은, 요소들의 변환에 특화된 `map`이라는 메소드가(=함수가) 내장되어있다. \n\n`# 예시1` -- 메롱\n\n`#`\n\n`# 예시2` -- Text의 length 계산 \n\n`#`\n\n`# 예시2` -- 토크나이징결과 \n\n`#`\n\n# 5. 데이터콜렉터 \n\n`-` 전터리된 데이터가 인공지능은 마음에 들지 않는다. \n\n- 이유: 인공지능은 `torch.tensor()` 자료형을 가지며 (n,m)의 행렬로 정리된 \"묶음\" 형태의 자료형을 기대함. \n\n`-` 자료처리과정요약 \n\n||주어진자료| $\\overset{tokenizer,map}{\\Longrightarrow}$ 전처리된자료|$\\overset{datacollector}{\\Longrightarrow}$더전처리된자료|\n|:--:|:--:|:--:|:--:|\n|Dict의 Keys |`text`,`label`| `input_ids`, `attention_mask`, `label`| `input_ids`, `attention_mask`, `labels`| \n|자료의형태|텍스트,라벨|숫자화 O, 행렬화 X  | 숫자화 O, 행렬화 O\n|`torch.tensor`|- | X | O | \n|미니배치| - | X| O| \n|패딩/동적패딩| - | X | O|\n|예측할때|강인공지능의 입력|트레이너의 입력|인공지능의 입력|\n\n`-` 데이터콜렉터에서 우리가 기대하는 것:\n\n- 자료의 형태가 [Dict,Dict,Dict,Dict] 로 되어있는 경우^[`전처리된나의데이터['train']`이 이러한 형태로 되어있음] (4,??) shape 텐서의 `input_ids`, (4,??) shape 텐서의 `attention_mask`, 그리고 (4,) shape 텐서의 `labels`로 변환해줌. \n\n`-` 데이터콜렉터 사용방법 \n\n# 6. 평가하기\n\n`-` `accuracy.compute`의 기능\n\n`-` `평가하기` 함수의 내용 \n\n# 7. 트레이너\n\n`-` 이전코드\n\n## A. 트레이너의 제1역할 -- CPU에서 GPU로.. \n\n### `#` 트레이너 생성전\n\n`-` 인공지능의 파라메터 상태확인 1\n\n- 중요한내용1: 숫자들 = 초기숫자들\n- 중요한내용2: 숫자들이 CPU에 존재한다는 의미\n\n`-` 인공지능을 이용한 예측 1\n\n### `#` 트레이너 생성후 \n\n`-` 트레이너생성 \n\n`-` 인공지능의 파라메터 상태확인 2\n\n- 중요한내용1: 숫자들 = 초기숫자들\n- 중요한내용2: device=\"cuda:0\" // 숫자들이 GPU에 있다는 의미 \n\n`-` 인공지능을 이용한 예측 2\n\n> 트레이너의 제1역할: 트레이너는 생성과 동시에 하는역할이 있는데, 바로 인공지능의 파라메터를 GPU에 올리는 것이다. \n\n## B. 트레이너의 제2역할 -- 예측하기 \n\n> 트레이너의 제2역할: `트레이너.predict()` 사용가능. `트레이너.predict()`의 입력형태는 input_ids, attention_mask, label 이 존재하는 `Dataset`\n\n`# 예제1` 트레이너를 이용한 예측 \n\n`#`\n\n`# 예제2` -- 트레이너를 이용하여 `train_data`, `test_data` 의 prediction 값을 구하라. \n\n`#`\n\n## C. 트레이너의 제3역할 -- 학습 및 결과저장\n\n### `#` 학습\n\n### `#` 학습후\n\n`-` 인공지능이 똑똑해졌을까?\n\n`-` 인공지능의 파라메터 상태확인 3\n\n*인공지능의 파라메터 상태확인 2와 비교삿*\n\n```\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       device='cuda:0', requires_grad=True)\n```\n\n*숫자들이 바뀐걸 확인 $\\to$ 뭔가 다른 계산결과를 준다는 의미겠지? $\\to$ 진짜 그런지 보자..*\n\n`-` 인공지능을 이용한 예측 3\n\n`-` 다시 트레이너를 이용하여 `train_data`, `test_data` 의 prediction 값을 구해보자. \n\n`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O\n\n# 8. 파이프라인\n\n`-` 강인공지능? \n\n> ref: <https://zdnet.co.kr/view/?no=20160622145838>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"reference-location":"margin","toc":true,"output-file":"04wk-1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.533","theme":"cosmo","title-block-banner":false,"comments":{"utterances":{"repo":"guebin/MP2023"}},"cap-location":"margin","citation-location":"margin","bibliography":["ref.bib"],"code-copy":true,"title":"04wk-1: 감성분석 파고들기 (2)","author":"최규빈","date":"09/27/2024","draft":false},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","reference-location":"margin","output-file":"04wk-1.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":false,"comments":{"utterances":{"repo":"guebin/MP2023"}},"cap-location":"margin","citation-location":"margin","bibliography":["ref.bib"],"title":"04wk-1: 감성분석 파고들기 (2)","author":"최규빈","date":"09/27/2024","draft":false}}},"projectFormats":["html"]}