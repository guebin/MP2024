{"title":"03wk-1: 감성분석 파고들기 (1)","markdown":{"yaml":{"title":"03wk-1: 감성분석 파고들기 (1)","author":"최규빈","date":"09/19/2024"},"headingText":"1. 강의영상","containsRefs":false,"markdown":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/03wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-xEmEVHYPB2SRE2WCTskicZ&si=cvDVr_m0CHoHNwvU >}}\n\n# 2. Imports\n\n# 3. 이전코드\n\n`-` Step1~4를 위한 준비\n\n`-` Step 1~4\n\n# 4. DataSet\n\n`-` 가장 중요한 원초적 질문: 데이터 셋을 바꿔치기 하려면? \n\n`-` 내가 원하는 데이터를 아래와 같은 양식(=형태)으로 정리해야함.\n\n`-` `datasets.arrow_dataset.Dataset` 의 인스턴스 만들기 \n\n아래와 같은 함수가 있음. \n\n::: {.callout-note}\n### $\\star$ `datasets.Dataset.from_dict` 사용법 (ref: ChatGPT) \n\n`datasets.Dataset.from_dict`는 Python의 딕셔너리(`dict`)를 `Dataset` 객체로 변환하는 함수입니다. 주로 딕셔너리 형태의 데이터를 빠르게 데이터셋으로 변환할 때 사용됩니다.\n\n**간단한 사용법**\n\n```python\nfrom datasets import Dataset\n\n# 딕셔너리를 Dataset으로 변환\ndata_dict = {\n    'text': [\"Hello world\", \"How are you?\", \"Fine, thanks!\"],\n    'label': [0, 1, 1]\n}\n\n# Dataset 생성\ndataset = Dataset.from_dict(data_dict)\n\n# 출력\nprint(dataset)\n```\n\n**주요 매개변수:**\n\n- `mapping`: 필수, 문자열을 키로 하고 리스트 또는 배열을 값으로 하는 딕셔너리.\n- `features`: 선택, 데이터셋의 각 필드 타입을 정의.\n- `info`: 선택, 데이터셋에 대한 추가 정보(설명, 인용 등).\n- `split`: 선택, 데이터셋의 나누기('train', 'test' 등).\n\n**반환값:**\n\n- `Dataset`: PyArrow 기반의 데이터셋 객체.\n:::\n\n`-` `datasets.dataset_dict.DatasetDict`의 인스턴스 만들기 \n\n`-` 일단 아래와 같은 형태로 분석할 데이터를 저장할 수 있다면, 나머지 분석은 코드를 복/붙하여 진행할 수 있음. \n\n\n```Python\ntrain_dict = {\n    'text': [\n        \"I prefer making decisions based on logic and objective facts.\",\n        \"I always consider how others might feel when making a decision.\",\n        \"Data and analysis drive most of my decisions.\",\n        \"I rely on my empathy and personal values to guide my choices.\"\n    ],\n    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n\ntest_dict = {\n    'text': [\n        \"I find it important to weigh all the pros and cons logically.\",\n        \"When making decisions, I prioritize harmony and people's emotions.\"\n    ],\n    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n```\n\n# 5. 토크나이저\n\n`-` 토크나이저를 불러오는 코드 \n\n::: {.callout-note}\n\n### $\\star$ `토크나이저` 사용법 (ref: ChatGPT)\n\n**주요 파라미터**:\n\n1. **text**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 주어진 텍스트를 토큰화합니다. 이 텍스트는 문자열일 수도 있고, 문자열의 리스트 또는 리스트 안의 리스트일 수도 있습니다.\n\n2. **text_pair**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 두 개의 텍스트를 함께 모델에 입력할 때 사용됩니다. 예를 들어, 질문-답변 쌍 같은 경우 이 두 번째 텍스트를 넣습니다.\n\n3. **text_target**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 토큰화를 할 때 목표(target) 텍스트에 해당하는 부분입니다. 주로 시퀀스 생성 모델에서 활용됩니다.\n\n4. **text_pair_target**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 위의 `text_pair`와 유사하게 목표(target) 텍스트의 두 번째 텍스트를 나타냅니다.\n\n5. **add_special_tokens**: \n   - `bool`\n   - 문장의 시작, 끝, 구분자 같은 특별한 토큰을 추가할지 여부를 결정합니다. 기본값은 `True`입니다.\n\n6. **padding**: \n   - `Union[bool, str, transformers.utils.generic.PaddingStrategy]`\n   - 문장 길이가 다를 때 패딩을 넣어 문장의 길이를 동일하게 맞춥니다. 패딩 전략에는 `True`, `False`, `'longest'`, `'max_length'` 등이 있습니다.\n\n7. **truncation**: \n   - `Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy]`\n   - 문장이 너무 길 경우 지정된 최대 길이에 맞춰 잘라내는 옵션입니다. 전략에는 `True`, `False`, `'longest_first'`, `'only_first'`, `'only_second'` 등이 있습니다.\n\n8. **max_length**: \n   - `Optional[int]`\n   - 문장의 최대 길이를 설정합니다. `None`일 경우 기본 설정을 따릅니다.\n\n9. **stride**: \n   - `int`\n   - 텍스트를 자를 때 중첩을 만들기 위한 옵션입니다. 즉, 자른 부분과 다음 부분 사이의 겹치는 범위를 설정합니다.\n\n10. **is_split_into_words**: \n    - `bool`\n    - 텍스트가 이미 단어 단위로 분리되어 있는지 여부를 나타냅니다. 기본적으로는 `False`로, 텍스트가 단어 단위로 분리되지 않았다고 가정합니다.\n\n11. **return_tensors**: \n    - `Union[str, transformers.utils.generic.TensorType, NoneType]`\n    - 출력 형식으로 텐서를 반환할지 여부를 설정합니다. `'pt'`(PyTorch), `'tf'`(TensorFlow), `'np'`(NumPy) 등을 지정할 수 있습니다.\n\n12. **return_token_type_ids**: \n    - `Optional[bool]`\n    - 토큰 타입 ID를 반환할지 여부를 설정합니다. 주로 두 개의 문장을 함께 처리할 때 문장을 구분하기 위해 사용됩니다.\n\n13. **return_attention_mask**: \n    - `Optional[bool]`\n    - `attention_mask`를 반환할지 여부를 설정합니다. 패딩된 토큰이 모델의 어텐션에 영향을 주지 않도록 마스크를 설정합니다.\n\n14. **return_overflowing_tokens**: \n    - `bool`\n    - 텍스트가 최대 길이를 초과하는 경우, 잘린 토큰을 반환할지 여부를 결정합니다.\n\n15. **return_special_tokens_mask**: \n    - `bool`\n    - 특별한 토큰에 대한 마스크를 반환할지 여부를 설정합니다.\n\n16. **return_offsets_mapping**: \n    - `bool`\n    - 텍스트의 각 토큰이 원본 텍스트에서 어느 위치에 있는지 나타내는 오프셋 맵핑을 반환할지 여부를 설정합니다.\n\n17. **return_length**: \n    - `bool`\n    - 토큰화된 문장의 길이를 반환할지 여부를 설정합니다.\n\n18. **verbose**: \n    - `bool`\n    - 디버깅 메시지를 출력할지 여부를 설정합니다. 기본값은 `True`로 설정되어 있습니다.\n\n**사용 예시**:\n\n```python\nfrom transformers import AutoTokenizer\n\n# 토크나이저 불러오기\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# 텍스트 토큰화\nencoding = tokenizer(\n    text=\"Hello, how are you?\",\n    padding=True,\n    truncation=True,\n    max_length=10,\n    return_tensors='pt'\n)\n\nprint(encoding)\n```\n\n이 코드에서는 \"Hello, how are you?\"라는 텍스트를 `bert-base-uncased` 토크나이저로 토큰화하고, 패딩과 트렁케이션을 적용하며, PyTorch 텐서 형식으로 반환하도록 설정했습니다.\n\n이러한 파라미터는 주로 자연어 처리(NLP) 모델을 훈련하거나 추론할 때 데이터 전처리 과정에서 많이 사용됩니다.\n:::\n\n`-` 기본사용1: 토크나이저의 기능 -- (1) 단어별로 다른숫자를 맵핑 (2) 처음과 끝은 각각 `101`, `102`라는 숫자로 맵핑 \n\n`-` 기본사용2: 여러개의 텍스트도 `[텍스트1, 텍스트2, ... ]` 꼴로 전달하면 토크나이저가 알아서 잘 처리해준다. \n\n`-` `truncation=True` 의 역할 -- 너무 문장이 길면 잘라내는 역할을 한다. \n\n`-` 너무 문장이 짧아서 뭔가를 채우기도 할까? -- `max_length`, `padding`, `attention_mask`\n\n# 6. 인공지능 ($\\star$)\n\n## A. 1단계 \n\n> 인공지능에 대한 이해 \n\n`-` 인공지능 불러오기 \n\n`-` 인공지능의 정체? 엄청나게 많은 숫자들이 포함된 어떠한 물체 (엄청나게 많은 파라메터들이 포함된 네트워크)\n\n`-` 인공지능? \"입력정보 -> 정리된숫자 -> 계산 -> 계산된숫자 -> 출력정보\" 의 과정에서 \"계산\"을 담당. \n\n- 인공지능이 가지고 있는 숫자들은 \"계산\"에 사용된다.\n\n`-` 입력정보에 영화에 대한 부정적 평가에 해당하는 텍스트를 넣는다면? \n\n`-` 입력정보에 영화에 대한 긍정적 평가에 해당하는 텍스트를 넣는다면? \n\n`-` 아무숫자나 뱉어내는 듯 $\\to$ 멍청한 인공지능 (옹호: 멍청한건 당연함. 아직 학습전이니까)\n\n`-` 인공지능에 대한 이해1: 인공지능은 \"정리된숫자\"를 입력으로 하고 일련의 계산을 거쳐서 \"계산된숫자\"를 출력해주는 함수라 생각할 수 있음. \n\n`-` 인공지능에 대한 이해2: 인공지능은 (1) 많은숫자들과 (2) 고유의 계산방식을 가지고 있음. \n\n- 인공지능이 내부에 자체적으로 저장하고 있는 숫자들 \"파라메터\"라고 부름. \n- 인공지능은 나름의 법칙에 따라 \"데이터\"와 \"파라메터\"의 숫자들을 연산함. 즉 인공지능은 자체적으로 데이터와 파라메터를 어떻게 계산할지 알고있는데, 이러한 고유의 계산방식을 \"아키텍처\"라고 말함. \n\n`-` 인공지능에 대한 이해3: 두개의 인공지능이 서로 다른 고유의 계산방식을 가지고 있다면 두 인공지능은 \"다른 모델\" 임. \n\n`-` 인공지능에 대한 이해3': 동일한 생성방식으로 만들어진 인공지능들은 모두 같은 모델임. 예를들면 아래의 인공지능1,2는 같은 모델임 \n\n```Python\n인공지능1 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\n인공지능2 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\n```\n\n`-` 인공지능에 대한 이해4: 두 인공지능이 같은모델이라고 해도, 항상 같은 결과를 주는건 아님. 파라메터에 따라 다른 결과를 줄 수도 있음. (예를들면 위의 인공지능1,2는 같은 모델이지만 다른 파라메터를 가지므로 다른 결과를 줌)\n\n## B. 2단계 \n\n> 미니배치의 이해 \n\n`-` 예비학습 \n\n`-` 예비개념1: 인공지능은 사실 영화평을 하나씩 하나씩 처리하지 않는다. 덩어리로 처리한다. \n\n`-` 예비개념2: 그렇다고 해서 인공지능이 25000개를 모두 덩어리로 처리하는건 아니다 $\\to$ 16개씩 혹은 32개씩 묶어서 작은덩어리를 만든 후 처리한다. \n\n- 16, 32와 같은 숫자를 `batch_size` 라고 한다. \n- 16개, 32개로 모인 작은덩어리를 미니배치라고 한다. \n\n`-` 16개의 입력정보를 한번에 처리 \n\n`-` 기억할 것: `정리된숫자들_토큰화된자료` 는 모두 길이가 512임. (그렇게 되도록 패딩함)\n\n`-` 실제 단어수 \n\n`-` 패딩된단어수\n\n`-` 이러한 변환이 필요한 이유? 인공지능은 항상 `(n,m)` 차원으로 정리된 숫자들만 입력으로 받을 수 있음. \n\n- 왜? 사실 인공지능은 행렬계산을 하도록 설계되어있음. \n- 그래서 할수없이 padding을 하거나 truncation을 하는 것임. (실제로는 행렬이 아니지만 억지로 행렬을 만들기 위해서)\n\n## C. 3단계 \n\n> 동적패딩을 이해하자. \n\n`-` 만약에 `batch_size=4`로 설정하여 처리한다면? \n\n`-` `정리된숫자들_토큰화된자료['input_ids']` 의 차원은 어떠할까? (4,512)\n\n- 끝의 차원이 512가 아니라 363이다.. 왜??\n\n`-` 덩어리의 상태에 따라서 유동적으로 패딩 $\\to$ 이렇게 해도 잘 돌아감 \n\n`-` 싹다 maxlen=512로 가정하고 패딩해서 돌린결과와 비교 $\\to$ 같음 $\\to$ 동적패딩이 효율적 \n\n## D. 4단계 \n\n> 손실(=loss)의 개념을 이해하자 \n\n`-` `정리된숫자들_토큰화된자료`에서 `labels`를 추가 전달하면, `인공지능(**정리된숫자들_토큰화된자료)`의 결과로 `loss`가 추가계산됨.\n\n`-` 정리를 해보자. \n\n`-` loss는 작을수록 주어진 데이터에 대한 정답을 잘 맞추고 있다고 볼 수 있음. (그렇지만 학습이 잘 되었다는걸 보장하지는 못함)\n\n**텍스트0-텍스트3**\n\n**텍스트12498-텍스트12501**\n\n**텍스트12502-텍스트12506**\n\n`-` 똑같이 틀려도 오답에 대한 확신이 강할수록 loss가 크다. \n\n:::{.callout-note}\n\n### $\\star\\star\\star$ 학습이 가능한 이유 (대충 아이디어만)\n\n`1`. 랜덤으로 하나의 인공지능을 생성한다. (아래의 코드로 가능)\n\n```Python \n인공지능 = 인공지능생성기()\n```\n\n`2`. 하나의 미니배치를 선택한다. \n\n`3`. 인공지능의 파라메터중 하나의 숫자를 선택한다. 예를들면 아래와 같은 상황이 있다고 하자. \n\n```Python\n인공지능.classifier.weight\n```\n\n```\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       requires_grad=True)\n```\n\n하나의 숫자 `-0.0234`를 선택한다. \n\n`4`. `-0.0234`의 값을 아주 조금 변화시킨다. 예를들면 `-0.0233`, `-0.0235` 와 같은 숫자로 바꾼다. 2에서 고정된 미니배치에 대하여  `-0.0234`, `-0.0233`, `-0.0235` 에 대한 loss를 계산해보고 비교한다. \n\n- `-0.0234`이 최저 loss라면? 값을 안바꾸는게 좋겠음. \n- `-0.0233`이 최저 loss라면?? 값을 `-0.0233`으로 바꿈.\n- `-0.0235`이 최저 loss라면?? 값을 `-0.0235`으로 바꿈. \n\n`5`. 다음은 다른 모든 파라메터에 대하여 3-4을 반복한다. (과정을 반복할수록 loss는 작아지겠죠, 즉 인공지능은 정답을 잘 맞추겠죠)\n\n`6`. 다른 미니배치에 대하여 2-5를 반복한다.\n\n:::\n\n`-` 인공지능의 학습은 마법같은 신비한 현상이 아니고, 극한의 노가다를 통해 얻어지는 산물일 뿐이다. \n","srcMarkdownNoYaml":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/03wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n# 1. 강의영상 \n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-xEmEVHYPB2SRE2WCTskicZ&si=cvDVr_m0CHoHNwvU >}}\n\n# 2. Imports\n\n# 3. 이전코드\n\n`-` Step1~4를 위한 준비\n\n`-` Step 1~4\n\n# 4. DataSet\n\n`-` 가장 중요한 원초적 질문: 데이터 셋을 바꿔치기 하려면? \n\n`-` 내가 원하는 데이터를 아래와 같은 양식(=형태)으로 정리해야함.\n\n`-` `datasets.arrow_dataset.Dataset` 의 인스턴스 만들기 \n\n아래와 같은 함수가 있음. \n\n::: {.callout-note}\n### $\\star$ `datasets.Dataset.from_dict` 사용법 (ref: ChatGPT) \n\n`datasets.Dataset.from_dict`는 Python의 딕셔너리(`dict`)를 `Dataset` 객체로 변환하는 함수입니다. 주로 딕셔너리 형태의 데이터를 빠르게 데이터셋으로 변환할 때 사용됩니다.\n\n**간단한 사용법**\n\n```python\nfrom datasets import Dataset\n\n# 딕셔너리를 Dataset으로 변환\ndata_dict = {\n    'text': [\"Hello world\", \"How are you?\", \"Fine, thanks!\"],\n    'label': [0, 1, 1]\n}\n\n# Dataset 생성\ndataset = Dataset.from_dict(data_dict)\n\n# 출력\nprint(dataset)\n```\n\n**주요 매개변수:**\n\n- `mapping`: 필수, 문자열을 키로 하고 리스트 또는 배열을 값으로 하는 딕셔너리.\n- `features`: 선택, 데이터셋의 각 필드 타입을 정의.\n- `info`: 선택, 데이터셋에 대한 추가 정보(설명, 인용 등).\n- `split`: 선택, 데이터셋의 나누기('train', 'test' 등).\n\n**반환값:**\n\n- `Dataset`: PyArrow 기반의 데이터셋 객체.\n:::\n\n`-` `datasets.dataset_dict.DatasetDict`의 인스턴스 만들기 \n\n`-` 일단 아래와 같은 형태로 분석할 데이터를 저장할 수 있다면, 나머지 분석은 코드를 복/붙하여 진행할 수 있음. \n\n\n```Python\ntrain_dict = {\n    'text': [\n        \"I prefer making decisions based on logic and objective facts.\",\n        \"I always consider how others might feel when making a decision.\",\n        \"Data and analysis drive most of my decisions.\",\n        \"I rely on my empathy and personal values to guide my choices.\"\n    ],\n    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n\ntest_dict = {\n    'text': [\n        \"I find it important to weigh all the pros and cons logically.\",\n        \"When making decisions, I prioritize harmony and people's emotions.\"\n    ],\n    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n```\n\n# 5. 토크나이저\n\n`-` 토크나이저를 불러오는 코드 \n\n::: {.callout-note}\n\n### $\\star$ `토크나이저` 사용법 (ref: ChatGPT)\n\n**주요 파라미터**:\n\n1. **text**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 주어진 텍스트를 토큰화합니다. 이 텍스트는 문자열일 수도 있고, 문자열의 리스트 또는 리스트 안의 리스트일 수도 있습니다.\n\n2. **text_pair**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 두 개의 텍스트를 함께 모델에 입력할 때 사용됩니다. 예를 들어, 질문-답변 쌍 같은 경우 이 두 번째 텍스트를 넣습니다.\n\n3. **text_target**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 토큰화를 할 때 목표(target) 텍스트에 해당하는 부분입니다. 주로 시퀀스 생성 모델에서 활용됩니다.\n\n4. **text_pair_target**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 위의 `text_pair`와 유사하게 목표(target) 텍스트의 두 번째 텍스트를 나타냅니다.\n\n5. **add_special_tokens**: \n   - `bool`\n   - 문장의 시작, 끝, 구분자 같은 특별한 토큰을 추가할지 여부를 결정합니다. 기본값은 `True`입니다.\n\n6. **padding**: \n   - `Union[bool, str, transformers.utils.generic.PaddingStrategy]`\n   - 문장 길이가 다를 때 패딩을 넣어 문장의 길이를 동일하게 맞춥니다. 패딩 전략에는 `True`, `False`, `'longest'`, `'max_length'` 등이 있습니다.\n\n7. **truncation**: \n   - `Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy]`\n   - 문장이 너무 길 경우 지정된 최대 길이에 맞춰 잘라내는 옵션입니다. 전략에는 `True`, `False`, `'longest_first'`, `'only_first'`, `'only_second'` 등이 있습니다.\n\n8. **max_length**: \n   - `Optional[int]`\n   - 문장의 최대 길이를 설정합니다. `None`일 경우 기본 설정을 따릅니다.\n\n9. **stride**: \n   - `int`\n   - 텍스트를 자를 때 중첩을 만들기 위한 옵션입니다. 즉, 자른 부분과 다음 부분 사이의 겹치는 범위를 설정합니다.\n\n10. **is_split_into_words**: \n    - `bool`\n    - 텍스트가 이미 단어 단위로 분리되어 있는지 여부를 나타냅니다. 기본적으로는 `False`로, 텍스트가 단어 단위로 분리되지 않았다고 가정합니다.\n\n11. **return_tensors**: \n    - `Union[str, transformers.utils.generic.TensorType, NoneType]`\n    - 출력 형식으로 텐서를 반환할지 여부를 설정합니다. `'pt'`(PyTorch), `'tf'`(TensorFlow), `'np'`(NumPy) 등을 지정할 수 있습니다.\n\n12. **return_token_type_ids**: \n    - `Optional[bool]`\n    - 토큰 타입 ID를 반환할지 여부를 설정합니다. 주로 두 개의 문장을 함께 처리할 때 문장을 구분하기 위해 사용됩니다.\n\n13. **return_attention_mask**: \n    - `Optional[bool]`\n    - `attention_mask`를 반환할지 여부를 설정합니다. 패딩된 토큰이 모델의 어텐션에 영향을 주지 않도록 마스크를 설정합니다.\n\n14. **return_overflowing_tokens**: \n    - `bool`\n    - 텍스트가 최대 길이를 초과하는 경우, 잘린 토큰을 반환할지 여부를 결정합니다.\n\n15. **return_special_tokens_mask**: \n    - `bool`\n    - 특별한 토큰에 대한 마스크를 반환할지 여부를 설정합니다.\n\n16. **return_offsets_mapping**: \n    - `bool`\n    - 텍스트의 각 토큰이 원본 텍스트에서 어느 위치에 있는지 나타내는 오프셋 맵핑을 반환할지 여부를 설정합니다.\n\n17. **return_length**: \n    - `bool`\n    - 토큰화된 문장의 길이를 반환할지 여부를 설정합니다.\n\n18. **verbose**: \n    - `bool`\n    - 디버깅 메시지를 출력할지 여부를 설정합니다. 기본값은 `True`로 설정되어 있습니다.\n\n**사용 예시**:\n\n```python\nfrom transformers import AutoTokenizer\n\n# 토크나이저 불러오기\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# 텍스트 토큰화\nencoding = tokenizer(\n    text=\"Hello, how are you?\",\n    padding=True,\n    truncation=True,\n    max_length=10,\n    return_tensors='pt'\n)\n\nprint(encoding)\n```\n\n이 코드에서는 \"Hello, how are you?\"라는 텍스트를 `bert-base-uncased` 토크나이저로 토큰화하고, 패딩과 트렁케이션을 적용하며, PyTorch 텐서 형식으로 반환하도록 설정했습니다.\n\n이러한 파라미터는 주로 자연어 처리(NLP) 모델을 훈련하거나 추론할 때 데이터 전처리 과정에서 많이 사용됩니다.\n:::\n\n`-` 기본사용1: 토크나이저의 기능 -- (1) 단어별로 다른숫자를 맵핑 (2) 처음과 끝은 각각 `101`, `102`라는 숫자로 맵핑 \n\n`-` 기본사용2: 여러개의 텍스트도 `[텍스트1, 텍스트2, ... ]` 꼴로 전달하면 토크나이저가 알아서 잘 처리해준다. \n\n`-` `truncation=True` 의 역할 -- 너무 문장이 길면 잘라내는 역할을 한다. \n\n`-` 너무 문장이 짧아서 뭔가를 채우기도 할까? -- `max_length`, `padding`, `attention_mask`\n\n# 6. 인공지능 ($\\star$)\n\n## A. 1단계 \n\n> 인공지능에 대한 이해 \n\n`-` 인공지능 불러오기 \n\n`-` 인공지능의 정체? 엄청나게 많은 숫자들이 포함된 어떠한 물체 (엄청나게 많은 파라메터들이 포함된 네트워크)\n\n`-` 인공지능? \"입력정보 -> 정리된숫자 -> 계산 -> 계산된숫자 -> 출력정보\" 의 과정에서 \"계산\"을 담당. \n\n- 인공지능이 가지고 있는 숫자들은 \"계산\"에 사용된다.\n\n`-` 입력정보에 영화에 대한 부정적 평가에 해당하는 텍스트를 넣는다면? \n\n`-` 입력정보에 영화에 대한 긍정적 평가에 해당하는 텍스트를 넣는다면? \n\n`-` 아무숫자나 뱉어내는 듯 $\\to$ 멍청한 인공지능 (옹호: 멍청한건 당연함. 아직 학습전이니까)\n\n`-` 인공지능에 대한 이해1: 인공지능은 \"정리된숫자\"를 입력으로 하고 일련의 계산을 거쳐서 \"계산된숫자\"를 출력해주는 함수라 생각할 수 있음. \n\n`-` 인공지능에 대한 이해2: 인공지능은 (1) 많은숫자들과 (2) 고유의 계산방식을 가지고 있음. \n\n- 인공지능이 내부에 자체적으로 저장하고 있는 숫자들 \"파라메터\"라고 부름. \n- 인공지능은 나름의 법칙에 따라 \"데이터\"와 \"파라메터\"의 숫자들을 연산함. 즉 인공지능은 자체적으로 데이터와 파라메터를 어떻게 계산할지 알고있는데, 이러한 고유의 계산방식을 \"아키텍처\"라고 말함. \n\n`-` 인공지능에 대한 이해3: 두개의 인공지능이 서로 다른 고유의 계산방식을 가지고 있다면 두 인공지능은 \"다른 모델\" 임. \n\n`-` 인공지능에 대한 이해3': 동일한 생성방식으로 만들어진 인공지능들은 모두 같은 모델임. 예를들면 아래의 인공지능1,2는 같은 모델임 \n\n```Python\n인공지능1 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\n인공지능2 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\n```\n\n`-` 인공지능에 대한 이해4: 두 인공지능이 같은모델이라고 해도, 항상 같은 결과를 주는건 아님. 파라메터에 따라 다른 결과를 줄 수도 있음. (예를들면 위의 인공지능1,2는 같은 모델이지만 다른 파라메터를 가지므로 다른 결과를 줌)\n\n## B. 2단계 \n\n> 미니배치의 이해 \n\n`-` 예비학습 \n\n`-` 예비개념1: 인공지능은 사실 영화평을 하나씩 하나씩 처리하지 않는다. 덩어리로 처리한다. \n\n`-` 예비개념2: 그렇다고 해서 인공지능이 25000개를 모두 덩어리로 처리하는건 아니다 $\\to$ 16개씩 혹은 32개씩 묶어서 작은덩어리를 만든 후 처리한다. \n\n- 16, 32와 같은 숫자를 `batch_size` 라고 한다. \n- 16개, 32개로 모인 작은덩어리를 미니배치라고 한다. \n\n`-` 16개의 입력정보를 한번에 처리 \n\n`-` 기억할 것: `정리된숫자들_토큰화된자료` 는 모두 길이가 512임. (그렇게 되도록 패딩함)\n\n`-` 실제 단어수 \n\n`-` 패딩된단어수\n\n`-` 이러한 변환이 필요한 이유? 인공지능은 항상 `(n,m)` 차원으로 정리된 숫자들만 입력으로 받을 수 있음. \n\n- 왜? 사실 인공지능은 행렬계산을 하도록 설계되어있음. \n- 그래서 할수없이 padding을 하거나 truncation을 하는 것임. (실제로는 행렬이 아니지만 억지로 행렬을 만들기 위해서)\n\n## C. 3단계 \n\n> 동적패딩을 이해하자. \n\n`-` 만약에 `batch_size=4`로 설정하여 처리한다면? \n\n`-` `정리된숫자들_토큰화된자료['input_ids']` 의 차원은 어떠할까? (4,512)\n\n- 끝의 차원이 512가 아니라 363이다.. 왜??\n\n`-` 덩어리의 상태에 따라서 유동적으로 패딩 $\\to$ 이렇게 해도 잘 돌아감 \n\n`-` 싹다 maxlen=512로 가정하고 패딩해서 돌린결과와 비교 $\\to$ 같음 $\\to$ 동적패딩이 효율적 \n\n## D. 4단계 \n\n> 손실(=loss)의 개념을 이해하자 \n\n`-` `정리된숫자들_토큰화된자료`에서 `labels`를 추가 전달하면, `인공지능(**정리된숫자들_토큰화된자료)`의 결과로 `loss`가 추가계산됨.\n\n`-` 정리를 해보자. \n\n`-` loss는 작을수록 주어진 데이터에 대한 정답을 잘 맞추고 있다고 볼 수 있음. (그렇지만 학습이 잘 되었다는걸 보장하지는 못함)\n\n**텍스트0-텍스트3**\n\n**텍스트12498-텍스트12501**\n\n**텍스트12502-텍스트12506**\n\n`-` 똑같이 틀려도 오답에 대한 확신이 강할수록 loss가 크다. \n\n:::{.callout-note}\n\n### $\\star\\star\\star$ 학습이 가능한 이유 (대충 아이디어만)\n\n`1`. 랜덤으로 하나의 인공지능을 생성한다. (아래의 코드로 가능)\n\n```Python \n인공지능 = 인공지능생성기()\n```\n\n`2`. 하나의 미니배치를 선택한다. \n\n`3`. 인공지능의 파라메터중 하나의 숫자를 선택한다. 예를들면 아래와 같은 상황이 있다고 하자. \n\n```Python\n인공지능.classifier.weight\n```\n\n```\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       requires_grad=True)\n```\n\n하나의 숫자 `-0.0234`를 선택한다. \n\n`4`. `-0.0234`의 값을 아주 조금 변화시킨다. 예를들면 `-0.0233`, `-0.0235` 와 같은 숫자로 바꾼다. 2에서 고정된 미니배치에 대하여  `-0.0234`, `-0.0233`, `-0.0235` 에 대한 loss를 계산해보고 비교한다. \n\n- `-0.0234`이 최저 loss라면? 값을 안바꾸는게 좋겠음. \n- `-0.0233`이 최저 loss라면?? 값을 `-0.0233`으로 바꿈.\n- `-0.0235`이 최저 loss라면?? 값을 `-0.0235`으로 바꿈. \n\n`5`. 다음은 다른 모든 파라메터에 대하여 3-4을 반복한다. (과정을 반복할수록 loss는 작아지겠죠, 즉 인공지능은 정답을 잘 맞추겠죠)\n\n`6`. 다른 미니배치에 대하여 2-5를 반복한다.\n\n:::\n\n`-` 인공지능의 학습은 마법같은 신비한 현상이 아니고, 극한의 노가다를 통해 얻어지는 산물일 뿐이다. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"reference-location":"margin","toc":true,"output-file":"03wk-1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.533","theme":"cosmo","title-block-banner":false,"comments":{"utterances":{"repo":"guebin/MP2023"}},"cap-location":"margin","citation-location":"margin","bibliography":["ref.bib"],"code-copy":true,"title":"03wk-1: 감성분석 파고들기 (1)","author":"최규빈","date":"09/19/2024"},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","reference-location":"margin","output-file":"03wk-1.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":false,"comments":{"utterances":{"repo":"guebin/MP2023"}},"cap-location":"margin","citation-location":"margin","bibliography":["ref.bib"],"title":"03wk-1: 감성분석 파고들기 (1)","author":"최규빈","date":"09/19/2024"}}},"projectFormats":["html"]}