{"title":"01wk-2: IMDB 자료 살펴보기, 지도학습의 개념","markdown":{"yaml":{"title":"01wk-2: IMDB 자료 살펴보기, 지도학습의 개념","author":"최규빈","date":"09/06/2024"},"headingText":"1. 강의영상","containsRefs":false,"markdown":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/01wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-wy1vTgfZfvKlHsxk3WmqKd&si=s6A2z0idIx48cRdD >}}\n\n# 2. 상상 혹은 경험 \n\n`-` 데이터 분석을 하고 싶음. \n\n- 할 줄 아는 것이 별로 없음.\n- 이론적으로 처음부터 익히려고 했는데, 도저히 각이 안나옴. (엄두가 나지 않음) \n- 블로그등을 보면서 데이터를 분석하는 코드를 독학하기로 함. \n- 전략: (1) 블로그의 코드를 돌려본다. (2) 블로그의 코드를 이해한다. (이론을 이해하는게 아님. 코드의 흐름을 이해하는 것임) (3) 블로그의 코드에서 데이터를 읽는 부분만 내가 사용할 데이터로 바꿔침 (4) 돌려서 결과를 제출. \n\n`-` 어려울 것이라 예상되는 점. \n\n- `(1)` 안 돌아감. `import` 부터 잘 안될 것임.\n- `(2)` 이해가 안될걸?? \n- `(3)` 이게 진짜 어려움. 이걸 잘하기 위해서는 파이썬의 기본 문법이 강해야함. \n- `(4)` 돌아는 가지만 결과가 좋지 않을 것임. \n\n`-` 소망: 아래가 되었으면.. \n\n- (1)-(4)의 과정이 매끄럽게 진행되면 좋겠다.. \n- 이 과정이 빠르게 반복되면서 여러코드를 최대한 빨리/많이 정리될 수 있다면.. \n- 그래서 비슷한 분석을 나중에 해야 할 일이 있을때 참고할 거리가 많으면... \n- 나중에는 코드가 동작하는 공통적인 원리를 깨우쳐 스스로 데이터를 보면서 얼개를 잡아나갈수 있고, 어느정도 분석도 할 수 있는 수준이 되었으면.. \n\n`-` 마음가짐: 컨셉을 잘 잡아야함.. \n\n- 나는 어떠한 코드도 짤 수 있는 사람이다. X \n- 나는 어떠한 코드도 이해할 수 있는 사람이다. X \n- 나는 어떠한 코드도 베낄 수 있는 (활용할 수 있는) 사람이다. O \n\n> 느리지만 정확하게 해결하는것은 옳지 않다. 모든 분석은 시간싸움임. 느려지는 순간 이미 뒤쳐진다. (마라톤을 하는게 아님. 100m 달리기임) \n\n`-` 저는 컴공과 교수가 아니에요.. (그럴만한 실력도 없어요) 그냥 먹고살기 위해서 눈치껏 코딩을 할 뿐입니다.. \n\n- 그래서 강의노트도 무식하게 만들예정.. \n- 이전에는 예쁘게 만든 편임.. (빅데이터 혁신공유대학 사업.. 서해안권 어쩌고.. 충남대학생들이 들었음) \n\n# 3. 감성분석 공부재료\n\n`-` 좋은 공부재료 (데이터+분석방법) 를 잘 선정해야함. 이게 사실 어려워요.. \n\n- 수업시간에 하는 예제는 좋은 예제에요. 고르고 고른 자료들입니다. 분석방법도 선별한 중요한 방법들임 (성능이 좋거나, 최신 유행이거나, 고전적인 상식수준의 알고리즘)\n- 그 외에는 몇개의 유명한 사이트를 즐겨찾기 해놓고 시간날때마다 공부하는 것이 좋음. \n- 일단 이번시간에 추천하는 사이트는.. <https://huggingface.co/docs/transformers/index> 입니다. \n\n`-` ref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n- ref는 reference의 약자. \n- 해당 사이트를 참고했다는 의미. \n- 원 작가에 대한 예의 + 나중에 공부할때도 좋음. --> 대학생활하면서 숙제하실때도 참고하세요.. \n- 없어보이는 행동이 아님. 더 빛나게 만들어주는 행동이라 생각함.. \n\n`-` 허깅페이스 \n\n- 대부분의 경진대회 분석은 (1) tabular 를 분석하는 경우 (2) tabular 데이터가 아닌 자료를 분석하는 경우로 나눌 수 있음. \n- Tabular 데이터를 분석하는 여러가지 전통적인 방법이 있으나 우승하려면 거의 무조건 XGBoost, LightGBM, CatBoost 중 하나를 써야함. 의사결정나무 기반의 알고리즘을 사용해야합니다. (의사결정나무가 거의 크랙임. 회귀분석, 로지스틱, SVM 등등.. 다 필요없음)\n- Tabular 데이터가 아닌 자료를 분석하는 경우는 딥러닝 모형을 사용해야함. 여러가지 모형이 있지만 transformer 기반의 모형이 크랙임. \n- 허깅페이스는 transformer 기반의 다양한 모델(=분석방법)을 다운로드 하고 사용하기 용이하게 도와주는 사이트(hub)임. \n\n# 4. Install \n\n`-` Before you begin, make sure you have all the necessary libraries installed:\n\n- 아래가 깔려있는지 확인하라는 의미. \n\n```Python\npip install transformers datasets evaluate accelerate\n```\n\n`-` 저게 뭐하는 코드냐?? \n\n- GPT에게 물어보세요 (분이 풀릴때까지)\n\n> 질문: `pip install transformers datasets evaluate accelerate` 는 뭐하는 코드야?? \n\n> 질문: 코랩에서 저 명령어를 실행하면 어디엣 설치되는거야? 내 윈도우 노트북에 설치되어 있는거야?? \n\n> 질문: 그러면 코랩 끄면 다시 설치해야해? \n\n# 5. Imports \n\n- `from datasets import load_dataset` 의 의미는 `dataset` 모듈안에 있는 여러함수들 중에서 `load_dataset` 이라는 함수만 불러온다는 의미이다. \n- `import dataset` 을 한뒤 `dataset.load_dataset` 와 같은 형식으로 사용해도 무방하지만, 메모리 관리면에서 필요한 함수만 콕 찝어서 불러오는 `from datasets import load_dataset` 이 더 유리하다. \n\n# 6. `load_dataset` 함수의 사용방법 \n\n*복습*: <https://guebin.github.io/PP2024/posts/14wk-2.html>\n\n`-` `load_dataset` 이 뭐지? \n\n- 함수네.. 그렇다면 대충 `load_dataset(???)` 와 같은 방식으로 쓰면 되겠군.. \n\n`-` `load_dataset`은 어떻게 쓰지??\n\n```Python\nload_dataset?\n```\n\n```Python\nSignature:\nload_dataset(\n    path: str,\n    name: Optional[str] = None,\n    data_dir: Optional[str] = None,\n    data_files: Union[str, Sequence[str], Mapping[str, Union[str, Sequence[str]]], NoneType] = None,\n    split: Union[str, datasets.splits.Split, NoneType] = None,\n    cache_dir: Optional[str] = None,\n    features: Optional[datasets.features.features.Features] = None,\n    download_config: Optional[datasets.download.download_config.DownloadConfig] = None,\n    download_mode: Union[datasets.download.download_manager.DownloadMode, str, NoneType] = None,\n    verification_mode: Union[datasets.utils.info_utils.VerificationMode, str, NoneType] = None,\n    ignore_verifications='deprecated',\n    keep_in_memory: Optional[bool] = None,\n    save_infos: bool = False,\n    revision: Union[str, datasets.utils.version.Version, NoneType] = None,\n    token: Union[bool, str, NoneType] = None,\n    use_auth_token='deprecated',\n    task='deprecated',\n    streaming: bool = False,\n    num_proc: Optional[int] = None,\n    storage_options: Optional[Dict] = None,\n    trust_remote_code: bool = None,\n    **config_kwargs,\n) -> Union[datasets.dataset_dict.DatasetDict, datasets.arrow_dataset.Dataset, datasets.dataset_dict.IterableDatasetDict, datasets.iterable_dataset.IterableDataset]\n...\n```\n\n- 하나의 위치인자를 가지고 있음. 따라서 `load_dataset()` 와 같은 형식으로는 쓸 수 없겠음. --> 확인해보니까 진짜 쓸 수 없음. \n- 타입힌트를 보니까 `load_dataset('asdf')` 와 같은 방식으로 하나의 위치인자를 문자열로 전달해야 겠네.. (나머지는 알아서 디폴트값으로 전달되겠지..)\n- 전달한 문자열은 `path`라는 변수에 저장되겠지??\n- 난 `path`에 뭘 써야하지?? --> 생각1: `load_dataset`은 아마 데이터를 불러오는 함수일텐데, 이 데이터가 저장되는 경로를 `path`에 명시하라는거 아닌가? // 생각2: 아니면 불러올 데이터가 저장된 `path`인가? --> GPT문의 \n\n# 7. `IMDB` 탐색\n\n## A. `imdb` \n\n`-` 이제 `imdb`가 뭔지 살펴보자.. \n\n- 아마 데이터가 있겠죠?\n- 그런데 이걸 어떻게 보죠?? \n\n`-` 뜯어보자.. \n\n- 딕셔너리 아니야? \n\n`-` 딕셔너리는 아님 \n\n`-` 그런데 거의 딕셔너리 비슷한 느낌으로 일단 사용되는것 같음. \n\n`-` imdb는 딕셔너리 같은 것이고, `imdb['train']`와 같은 명령어로 세부항목에 접근가능함. 즉 아래의 구조임. \n\n- `imdb['train']` $\\subset$ `imdb`\n- `imdb['test']` $\\subset$ `imdb`\n- `imdb['unsupervised']` $\\subset$ `imdb`\n\n## B. `imdb['train']` \n\n`-` `imdb['train']`을 살펴보자.. \n\n`-` 이건 딕셔너리 처럼 안되는 것 같네.. \n\n`-` 그럼 `imdb['train']`는 어떻게 쓰라는 것이냐?? $\\to$ 쓸만한 기능이 있을지 dir로 체크 $\\to$ `__getitem__`이 있음.. $\\to$ `imdb['train'][0]` 를 써볼 용기가 생김.. \n\n- 실행이 되었음.\n- 기쁨. \n\n`-` `imdb['train'][1]`, `imdb['train'][-1]`, `imdb['train'][:2]` 등을 실행해보자..\n\n`-` `imdb['train'][0]` 을 구체적으로 살펴보자. \n\n`-` `imdb['train'][1]` 을 구체적으로 살펴보자. \n\n`-` `imdb['train'][100]` 을 구체적으로 살펴보자. \n\n> 영어: Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\n\n> 한글: 끔찍한 영화. 더 할 말 없음. 이 줄들은 그냥 채우기일 뿐이다. 영화가 나빴다. 내가 왜 이걸 더 길게 써야 하는지 모르겠다. 이건 이미 내 시간 낭비다. 나는 그저 다른 사람들에게 경고하고 싶었을 뿐이다. 이 영화를 피하라. 연기도 형편없고, 대본도 완전히 멍청하다. 모든 면에서 나쁜 영화다. 영화에서 유일하게 좋은 것은 데니즈 아카야의 가슴뿐이었다. 하지만 그것조차도 끔찍하고 불필요한 강간 장면 때문에 망쳤다. 이 영화는 조잡하게 만들어졌고, 전혀 믿을 수 없는 쓰레기다. 이제 IMDb에 대한 불만을 좀 말하겠다. 10줄 이상 써야 한다는 이 어리석은 규칙 때문에 말이다. 먼저 이 쓰레기를 보면서 내 시간을 낭비했다. 그리고 다른 사람들에게 경고하려고 IMDb 계정을 만들었더니, 영화에 대해 내가 얼마나 나쁘게 생각하는지를 표현하려면 이 따위 에세이를 써야 한다는 걸 알게 되었다. 완전히 불필요하다.\n\n- 영화평인듯..\n- 겁나 뭐라고함.. 부정적임.. \n- 이 text에 대한 label은 0 \n\n`-` `imdb['train'][-1]` 을 구체적으로 살펴보자. \n\n> 영어: The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n\n> 한글: 이 이야기는 유산을 상속받기 위해 영국으로 가야 하는 배리 맥켄지에 초점을 맞추고 있습니다. 배리 맥켄지는 이 위대한 호주를 떠난 사람 중 가장 거친 호주 농부로, 문화적 충돌이 일어나고 다양한 재미와 사건들이 이어집니다. 배리 맥켄지(배리 크로커)가 부르는 노래들이 이 영화의 하이라이트입니다.\n\n`-` 요약: `imdb['train']` 에는 여러개의 영화평이 있고, 각각 긍정평가와 부정평가를 담고 있음. \n\n- 몇개의 영화평이 있냐? 25000 \n- 부정평가는 0, 긍정평가는 1로 라벨링 \n\n## C. `imdb['test']`\n\n`-` `imdb['train']` 과 비슷함.. \n\n## D. `imdb['unsupervised']` \n\n`-` `imdb['unsupervised']` 를 살펴보자. \n\n- `imdb['train']`, `imdb['test']` 와 비슷해 보이지만 살짝 다름. \n- label 값이 특이하게 -1\n\n`-` 혹시 `imdb['unsupervised'][??]` 의 모든 라벨값이 모두 `-1`인가?\n\n- 일단 라벨은 -1 밖에 없음. \n\n`-` 느낌상 `imdb['unsupervised']`는 `imdb['train']` 와 `imdb['test']` 에서 text를 합치고, label은 모두 `-1` 로 바꾼 자료가 아닐까? 하는 의심이 들었음. ---> 아니었음.. \n\n## F. 정리 \n\n`-` 요약: \n\n- `imdb`는 `imdb['train']`, `imdb['test']`, `imdb['unsupervised']` 로 나누어져 있음. \n- `imdb['train']`, `imdb['test']` 에는 각각 (text,label)와 같은 형식으로 정보가 저장되어 있음. 여기에서 label은 0 혹은 1의 값을 가지는데 0은 부정, 1은 긍정을 의미함. \n- `imdb['unsupervised']` 에도 조사해보니 각각 (text,label)와 같은 형식으로 정보가 저장되어 있었지만, 여기에서 label값은 모두 -1의 값만 있었음. 따라서 사살상 `imdb['unsupervised']`는 text에 대한 정보만 있다고 생각해도 무방. 그 text가 영화에 대한 긍정평가인지 부정평가인지 분류가 되어있지 않은 상태. \n\n`-` 외우세요: `train`, `test`, `unsupervised` 와 같은 단어는 매우 중요한 단어니까 일단 눈여겨보세요 \n\n# 8. 지도학습 흐름 \n\n## A. 기계학습/딥러닝 과업\n\n`-` 왜 데이터가 `imdb['train']`, `imdb['test']`, `imdb['unsupervised']` 와 같이 나누어져 있는가? \n\n- 개념: 기계학습/딥러닝은 과업은 크게 지도학습과 비지도학습이 있음. \n- 데이터에서 `imdb['train']`, `imdb['test']` 는 지도학습 모델을 배우기 위한 예제데이터이고, `imdb['unsupervised']`는 비지도학습모델을 배우기 위한 예제데이터임. \n- 아무튼 우리가 하는 \"감성분석\"은 지도학습이고, 따라서 우리는 `imdb['train']`, `imdb['test']` 에만 관심을 가질 예정임. \n\n## B. 지도학습 \n\n`-` 지도학습이란? (이 예제에 한정하여 설명)\n\n- 자료가 \"(텍스트, 라벨)\" 의 형태로 정리가 되어 있을때, \"텍스트\"를 입력으로 주면 \"라벨\"을 출력해주는 함수 `f`를 찾는 일 \n- 코드로 예를들어 설명하면 적당히 `f`라는 함수가 존재하여 아래와 같은 동작이 가능하도록 해야함. \n\n```Python\nf(\"영화가 너무 재미없어요\")\n> \"부정평가입니다\"\n\nf(\"영화, 괜찮은데요??\")\n> \"긍정평가입니다\"\n\nf(\"배우들 연기 진짜 잘함. 영상미도 있음. 그런데 스토리 때문에 망했네.\")\n> \"부정평가입니다\"\n\n```\n\n`-` 이러한 함수 `f`를 우리가 잘 정의한다면 좋겠음. (가능한가??)\n\n`-` 대충 아래와 같은 과정을 거친다고 생각하면 편리함. \n\n> 정보(숫자,텍스트,이미지,...) $\\to$ 숫자 $\\to$ 계산 $\\to$ 계산된숫자 $\\to$ 정보\n\n`-` 예를들면 아래와 같은 방식이 가능 \n\n- 긍정평가군!\n\n`-` 당연히 현재는 많은 문제점이 있음. \n\n`-` 다행인점: 좋은 `f`를 만들기 위해서 우리가 고민할 필요 없음. (똑똑한 사람들이 다 만들어 놓음. 그리고 만들고 있음.)\n\n- 옛날방식: `f` 를 한땀한땀 설계. 초고수가 밤새 코딩해서 진짜 잘 맞추는 `f`를 한번에 제시. \n- 최근방식: `f` 를 대충 설계. 거의 멍청이 수준의 `f`임. 그런데 데이터를 줄수록 `f`가 점점 똑똑해짐. 나중에는 다 맞춤. --> 인공지능??? \n\n## C. train/test 자료의 의미 \n\n`-` 초고수가 `f`를 직접 설계하던 시대에는 별로 문제가 없었음. 그런데 최근 컴퓨터가 데이터를 보고 `f`를 스스로 수정하기 시작하면서 이상한 방식으로 `f`가 수정되는 경우가 보고되고 있음. `f`가 똑똑해 보이는데, 사실 멍청한 상태..\n\n- 어떻게 이런일이 가능하지?? \n\n`-` 최규빈 교수의 착각 \n\n- 상상: 나는 학생들에게 파이썬프로그래밍을 잘 강의하고 싶었다. 나는 학생들에게 다양한 문제를 풀어줬으며, 문제를 풀면서 학생들이 스스로 개념을 깨우치길 원했다. 나는 다양한 예시를 통해서 이해하는 것이 좋다고 생각했기 때문이다. 예시는 많을수록 좋으니까 한 학기동안 총 1000개의 문제를 풀어줬다. 기말고사는 풀어준 문제중에서 약 20문항을 샘플링하여 출제했다. 놀랍게도 학생들이 모두 만점을 받았으며 나는 아주 만족스러웠다. 한 학기 동안 고생한 보람이 있어보였다. 눈물이 흘렀다. \n- 질문: 최규빈 교수는 잘 평가한 걸까요? 학생들이 진짜 파이썬프로그래밍을 잘 이해했을까요?? (학과교수님들께 자랑해도 될까요?)\n- 이렇게 질문하고 싶지 않아요?: 1000개의 문제에서 샘플링하여 출제하지 않고, 새로운 문항을 개발하여 학생들에게 제시했다면??\n- 요령이 있는 교수라면 이렇게 했을거에요: 50000개의 문제세트가 있다고 하자. 수업시간에는 학생들에게 예시로 25000개 정도의 문항을 풀이하며 설명. 기말고사는 수업시간에 풀이하지 않은 25000개의 문항을 출제함. \n- 만약에 학생들이 수업시간에 풀어준 25000개의 문제를 올바르게 이해했다면, 수업시간에 풀이하지 않은 문항 25000개 역시 잘 풀었을 것임. \n\n`-` 이 상황을 살짝 말만 바꿔볼게요. \n\n- 상상: 나는 인공지능에게 \"영화평가 텍스트를 주면 그것이 긍정평가인지 부정평가인지 판단하는 능력\"을 잘 학습시키고 싶었다. 나는 인공지능에게 다양한 데이터를 제공했으며, 데이터를 보고 인공지능이 스스로 원리를 깨우치길 원했다. 데이터는 많을수록 좋으니까 약 50000개의 \"(텍스트,라벨)\" 쌍을 제공했다. 그리고 50000개의 \"(텍스트.라벨)\" 쌍에서 약 20문항을 샘플링하여 테스트했다. 놀랍게도 인공지능은 20문항을 모두 맞추었다. 나는 아주 만족스러웠다. 눈물이 흘렀다. \n- 질문: 저는 인공지능을 잘 학습시켰을까요? \n- 이렇게 하고 싶지 않아요?: 50000개의 데이터중, 25000개의 \"(텍스트,라벨)\"만 인공지능에게 제공하여 학습시킴. 그리고 나머지 25000개는 평가용으로 테스트해봄. \n- 만약에 인공지능이 진짜 영화평가 텍스트를 바탕으로 그것이 긍정평가인지 부정평가인지 판단하는 능력을 길렀다면?? 내가 인공지능에게 제공하지 않은 25000개의 데이터에 대해서도 함수 `f` 가 올바르게 동작해야함. \n\n`-` train data / test data \n\n- train data 는 인공지능에게 학습용으로 제공하는 데이터 \n- test data 는 인공지능이 진짜 잘 학습했는지 평가하기 위해 학습시 제공하지 않는 자료 \n\n## D. train/val/test 자료의 의미 \n\n`-` 학생들 입장에서 생각해본다면??\n\n- 소망: 내가 외우려고 한게 아니고, 하도 공부를 많이 하다보니 문제가 외워졌음. 나도 그러기 싫음. 나도 내가 올바르게 공부했는지 체크하고 싶어. \n- 아이디어: 교수님이 풀어준 25000개의 문항중, 15000개만 전략적으로 공부함. 그리고 나머지 10000개는 나 스스로 올바르게 공부했는지 체크하는 용도로 삼음. \n- 진행사항: \n    - 1일차: `{15000문항: 50%맞음, 10000문항: 45%맞음}`  \n    - 2일차: `{15000문항: 90%맞음, 10000문항: 85%맞음}`\n    - 3일차: `{15000문항: 100%맞음, 10000문항: 70%맞음}` <--- 이런 경험 있어요?? \n- 판단: 이게 한 3일차쯤 공부하다보니까 문제를 내가 너무 외운것 같네? 오히려 2일차일때의 느낌이 더 좋음. 그냥 2일차의 느낌으로 시험보러 가자!!\n\n\n`-` 이럴경우 아래와 같이 상황이 정리된다. \n\n- 원래: 교수가 수업시간에 풀어준 25000문제 = 학생이 공부할 25000문제 = train // 교수가 기말시험으로 제출할 25000문제 = test \n- 바뀐상황: 학생이 공부할 15000문제 = train / 학생이 자가진단용으로 으로 뺀 10000문제 = test // 교수가 기말시험으로 제출할 25000문제 = 찐test \n\n`-` 학생이 자가진단용으로 빼둔 10000개의 문항을 보통 validation set 이라고 부른다. 따라서 아래와 같이 정리 가능하다. \n\n- train = 15000문제 = 학생이 스스로 공부 \n- validation = 10000문제 = 학생이 공부할때 사용하지 않음. 자가진단용. \n- test = 25000문제 = 교수가 출제하는 시험 \n\n`-` train / validation / test 에 대한 용어는 엄밀하지 않게 사용되는 경우가 많아 그때그때 상황에 맞게 알아서 해석해야 한다. \n\n- 억지상황1: 교수가 시험보지 않음. 그런데 내가 스스로 공부하면서 잘 공부하고 있는지 체크하고 싶어서 1000개의 문제를 구하고 그중 매일 800개만 학습하고 200개는 검증용으로 사용함. 이 경우 200개의 문항을 validation 이라고 부르기도 하고 test 라고 부르기도 함. (엄밀하게는 validation이 맞다고 생각하지만, 외부데이터가 없는 상황이므로 validation과 test의 경계가 흐릿해짐)\n- 억지상황2: 나 혼자 1000개의 문항을 800/200으로 나누어 매일 공부하고 있었음. 이때 나는 200개의 문항을 test라고 부르기도 하고, validation이라고 부르기도 했음. 그런데 갑자기 교수가 나보고 외부 코딩대회에 나가라고 함. 이 경우 200개의 문항은 validation 이 되고 외부코딩대회에서 출제된 문항이 test가 됨. \n\n`-` 느낌: 아래가 가장 정확한 설명임 \n\n- train: 학습에 사용하는 자료 \n- validation: 학습에 사용하지 않는 자료. 왜 안써? 더 좋은 훈련을 위한 목적. \n- test: 학습에 사용하지 않는 자료. 왜 안써? 올바르게 학습됨을 평가하기 위한 목적. \n\n> 헷갈리는 이유는 더 좋은 훈련을 위한 목적과 올바르게 학습됨을 평가하기 위한 목적이 무 자르듯이 구분되지 않기 때문. \n\n`-` 이상한 분류법\n\n- 데이터를 보통 2개의 셋으로 나누면 train/test 로 3개로 나누면 train/test/validation 으로 많이 표현. \n- 딱 맞는 정의는 아님. 의미상 구분해야함. \n","srcMarkdownNoYaml":"\n\n<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/01wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n\n# 1. 강의영상 \n\n{{<video https://youtu.be/playlist?list=PLQqh36zP38-wy1vTgfZfvKlHsxk3WmqKd&si=s6A2z0idIx48cRdD >}}\n\n# 2. 상상 혹은 경험 \n\n`-` 데이터 분석을 하고 싶음. \n\n- 할 줄 아는 것이 별로 없음.\n- 이론적으로 처음부터 익히려고 했는데, 도저히 각이 안나옴. (엄두가 나지 않음) \n- 블로그등을 보면서 데이터를 분석하는 코드를 독학하기로 함. \n- 전략: (1) 블로그의 코드를 돌려본다. (2) 블로그의 코드를 이해한다. (이론을 이해하는게 아님. 코드의 흐름을 이해하는 것임) (3) 블로그의 코드에서 데이터를 읽는 부분만 내가 사용할 데이터로 바꿔침 (4) 돌려서 결과를 제출. \n\n`-` 어려울 것이라 예상되는 점. \n\n- `(1)` 안 돌아감. `import` 부터 잘 안될 것임.\n- `(2)` 이해가 안될걸?? \n- `(3)` 이게 진짜 어려움. 이걸 잘하기 위해서는 파이썬의 기본 문법이 강해야함. \n- `(4)` 돌아는 가지만 결과가 좋지 않을 것임. \n\n`-` 소망: 아래가 되었으면.. \n\n- (1)-(4)의 과정이 매끄럽게 진행되면 좋겠다.. \n- 이 과정이 빠르게 반복되면서 여러코드를 최대한 빨리/많이 정리될 수 있다면.. \n- 그래서 비슷한 분석을 나중에 해야 할 일이 있을때 참고할 거리가 많으면... \n- 나중에는 코드가 동작하는 공통적인 원리를 깨우쳐 스스로 데이터를 보면서 얼개를 잡아나갈수 있고, 어느정도 분석도 할 수 있는 수준이 되었으면.. \n\n`-` 마음가짐: 컨셉을 잘 잡아야함.. \n\n- 나는 어떠한 코드도 짤 수 있는 사람이다. X \n- 나는 어떠한 코드도 이해할 수 있는 사람이다. X \n- 나는 어떠한 코드도 베낄 수 있는 (활용할 수 있는) 사람이다. O \n\n> 느리지만 정확하게 해결하는것은 옳지 않다. 모든 분석은 시간싸움임. 느려지는 순간 이미 뒤쳐진다. (마라톤을 하는게 아님. 100m 달리기임) \n\n`-` 저는 컴공과 교수가 아니에요.. (그럴만한 실력도 없어요) 그냥 먹고살기 위해서 눈치껏 코딩을 할 뿐입니다.. \n\n- 그래서 강의노트도 무식하게 만들예정.. \n- 이전에는 예쁘게 만든 편임.. (빅데이터 혁신공유대학 사업.. 서해안권 어쩌고.. 충남대학생들이 들었음) \n\n# 3. 감성분석 공부재료\n\n`-` 좋은 공부재료 (데이터+분석방법) 를 잘 선정해야함. 이게 사실 어려워요.. \n\n- 수업시간에 하는 예제는 좋은 예제에요. 고르고 고른 자료들입니다. 분석방법도 선별한 중요한 방법들임 (성능이 좋거나, 최신 유행이거나, 고전적인 상식수준의 알고리즘)\n- 그 외에는 몇개의 유명한 사이트를 즐겨찾기 해놓고 시간날때마다 공부하는 것이 좋음. \n- 일단 이번시간에 추천하는 사이트는.. <https://huggingface.co/docs/transformers/index> 입니다. \n\n`-` ref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n- ref는 reference의 약자. \n- 해당 사이트를 참고했다는 의미. \n- 원 작가에 대한 예의 + 나중에 공부할때도 좋음. --> 대학생활하면서 숙제하실때도 참고하세요.. \n- 없어보이는 행동이 아님. 더 빛나게 만들어주는 행동이라 생각함.. \n\n`-` 허깅페이스 \n\n- 대부분의 경진대회 분석은 (1) tabular 를 분석하는 경우 (2) tabular 데이터가 아닌 자료를 분석하는 경우로 나눌 수 있음. \n- Tabular 데이터를 분석하는 여러가지 전통적인 방법이 있으나 우승하려면 거의 무조건 XGBoost, LightGBM, CatBoost 중 하나를 써야함. 의사결정나무 기반의 알고리즘을 사용해야합니다. (의사결정나무가 거의 크랙임. 회귀분석, 로지스틱, SVM 등등.. 다 필요없음)\n- Tabular 데이터가 아닌 자료를 분석하는 경우는 딥러닝 모형을 사용해야함. 여러가지 모형이 있지만 transformer 기반의 모형이 크랙임. \n- 허깅페이스는 transformer 기반의 다양한 모델(=분석방법)을 다운로드 하고 사용하기 용이하게 도와주는 사이트(hub)임. \n\n# 4. Install \n\n`-` Before you begin, make sure you have all the necessary libraries installed:\n\n- 아래가 깔려있는지 확인하라는 의미. \n\n```Python\npip install transformers datasets evaluate accelerate\n```\n\n`-` 저게 뭐하는 코드냐?? \n\n- GPT에게 물어보세요 (분이 풀릴때까지)\n\n> 질문: `pip install transformers datasets evaluate accelerate` 는 뭐하는 코드야?? \n\n> 질문: 코랩에서 저 명령어를 실행하면 어디엣 설치되는거야? 내 윈도우 노트북에 설치되어 있는거야?? \n\n> 질문: 그러면 코랩 끄면 다시 설치해야해? \n\n# 5. Imports \n\n- `from datasets import load_dataset` 의 의미는 `dataset` 모듈안에 있는 여러함수들 중에서 `load_dataset` 이라는 함수만 불러온다는 의미이다. \n- `import dataset` 을 한뒤 `dataset.load_dataset` 와 같은 형식으로 사용해도 무방하지만, 메모리 관리면에서 필요한 함수만 콕 찝어서 불러오는 `from datasets import load_dataset` 이 더 유리하다. \n\n# 6. `load_dataset` 함수의 사용방법 \n\n*복습*: <https://guebin.github.io/PP2024/posts/14wk-2.html>\n\n`-` `load_dataset` 이 뭐지? \n\n- 함수네.. 그렇다면 대충 `load_dataset(???)` 와 같은 방식으로 쓰면 되겠군.. \n\n`-` `load_dataset`은 어떻게 쓰지??\n\n```Python\nload_dataset?\n```\n\n```Python\nSignature:\nload_dataset(\n    path: str,\n    name: Optional[str] = None,\n    data_dir: Optional[str] = None,\n    data_files: Union[str, Sequence[str], Mapping[str, Union[str, Sequence[str]]], NoneType] = None,\n    split: Union[str, datasets.splits.Split, NoneType] = None,\n    cache_dir: Optional[str] = None,\n    features: Optional[datasets.features.features.Features] = None,\n    download_config: Optional[datasets.download.download_config.DownloadConfig] = None,\n    download_mode: Union[datasets.download.download_manager.DownloadMode, str, NoneType] = None,\n    verification_mode: Union[datasets.utils.info_utils.VerificationMode, str, NoneType] = None,\n    ignore_verifications='deprecated',\n    keep_in_memory: Optional[bool] = None,\n    save_infos: bool = False,\n    revision: Union[str, datasets.utils.version.Version, NoneType] = None,\n    token: Union[bool, str, NoneType] = None,\n    use_auth_token='deprecated',\n    task='deprecated',\n    streaming: bool = False,\n    num_proc: Optional[int] = None,\n    storage_options: Optional[Dict] = None,\n    trust_remote_code: bool = None,\n    **config_kwargs,\n) -> Union[datasets.dataset_dict.DatasetDict, datasets.arrow_dataset.Dataset, datasets.dataset_dict.IterableDatasetDict, datasets.iterable_dataset.IterableDataset]\n...\n```\n\n- 하나의 위치인자를 가지고 있음. 따라서 `load_dataset()` 와 같은 형식으로는 쓸 수 없겠음. --> 확인해보니까 진짜 쓸 수 없음. \n- 타입힌트를 보니까 `load_dataset('asdf')` 와 같은 방식으로 하나의 위치인자를 문자열로 전달해야 겠네.. (나머지는 알아서 디폴트값으로 전달되겠지..)\n- 전달한 문자열은 `path`라는 변수에 저장되겠지??\n- 난 `path`에 뭘 써야하지?? --> 생각1: `load_dataset`은 아마 데이터를 불러오는 함수일텐데, 이 데이터가 저장되는 경로를 `path`에 명시하라는거 아닌가? // 생각2: 아니면 불러올 데이터가 저장된 `path`인가? --> GPT문의 \n\n# 7. `IMDB` 탐색\n\n## A. `imdb` \n\n`-` 이제 `imdb`가 뭔지 살펴보자.. \n\n- 아마 데이터가 있겠죠?\n- 그런데 이걸 어떻게 보죠?? \n\n`-` 뜯어보자.. \n\n- 딕셔너리 아니야? \n\n`-` 딕셔너리는 아님 \n\n`-` 그런데 거의 딕셔너리 비슷한 느낌으로 일단 사용되는것 같음. \n\n`-` imdb는 딕셔너리 같은 것이고, `imdb['train']`와 같은 명령어로 세부항목에 접근가능함. 즉 아래의 구조임. \n\n- `imdb['train']` $\\subset$ `imdb`\n- `imdb['test']` $\\subset$ `imdb`\n- `imdb['unsupervised']` $\\subset$ `imdb`\n\n## B. `imdb['train']` \n\n`-` `imdb['train']`을 살펴보자.. \n\n`-` 이건 딕셔너리 처럼 안되는 것 같네.. \n\n`-` 그럼 `imdb['train']`는 어떻게 쓰라는 것이냐?? $\\to$ 쓸만한 기능이 있을지 dir로 체크 $\\to$ `__getitem__`이 있음.. $\\to$ `imdb['train'][0]` 를 써볼 용기가 생김.. \n\n- 실행이 되었음.\n- 기쁨. \n\n`-` `imdb['train'][1]`, `imdb['train'][-1]`, `imdb['train'][:2]` 등을 실행해보자..\n\n`-` `imdb['train'][0]` 을 구체적으로 살펴보자. \n\n`-` `imdb['train'][1]` 을 구체적으로 살펴보자. \n\n`-` `imdb['train'][100]` 을 구체적으로 살펴보자. \n\n> 영어: Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\n\n> 한글: 끔찍한 영화. 더 할 말 없음. 이 줄들은 그냥 채우기일 뿐이다. 영화가 나빴다. 내가 왜 이걸 더 길게 써야 하는지 모르겠다. 이건 이미 내 시간 낭비다. 나는 그저 다른 사람들에게 경고하고 싶었을 뿐이다. 이 영화를 피하라. 연기도 형편없고, 대본도 완전히 멍청하다. 모든 면에서 나쁜 영화다. 영화에서 유일하게 좋은 것은 데니즈 아카야의 가슴뿐이었다. 하지만 그것조차도 끔찍하고 불필요한 강간 장면 때문에 망쳤다. 이 영화는 조잡하게 만들어졌고, 전혀 믿을 수 없는 쓰레기다. 이제 IMDb에 대한 불만을 좀 말하겠다. 10줄 이상 써야 한다는 이 어리석은 규칙 때문에 말이다. 먼저 이 쓰레기를 보면서 내 시간을 낭비했다. 그리고 다른 사람들에게 경고하려고 IMDb 계정을 만들었더니, 영화에 대해 내가 얼마나 나쁘게 생각하는지를 표현하려면 이 따위 에세이를 써야 한다는 걸 알게 되었다. 완전히 불필요하다.\n\n- 영화평인듯..\n- 겁나 뭐라고함.. 부정적임.. \n- 이 text에 대한 label은 0 \n\n`-` `imdb['train'][-1]` 을 구체적으로 살펴보자. \n\n> 영어: The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n\n> 한글: 이 이야기는 유산을 상속받기 위해 영국으로 가야 하는 배리 맥켄지에 초점을 맞추고 있습니다. 배리 맥켄지는 이 위대한 호주를 떠난 사람 중 가장 거친 호주 농부로, 문화적 충돌이 일어나고 다양한 재미와 사건들이 이어집니다. 배리 맥켄지(배리 크로커)가 부르는 노래들이 이 영화의 하이라이트입니다.\n\n`-` 요약: `imdb['train']` 에는 여러개의 영화평이 있고, 각각 긍정평가와 부정평가를 담고 있음. \n\n- 몇개의 영화평이 있냐? 25000 \n- 부정평가는 0, 긍정평가는 1로 라벨링 \n\n## C. `imdb['test']`\n\n`-` `imdb['train']` 과 비슷함.. \n\n## D. `imdb['unsupervised']` \n\n`-` `imdb['unsupervised']` 를 살펴보자. \n\n- `imdb['train']`, `imdb['test']` 와 비슷해 보이지만 살짝 다름. \n- label 값이 특이하게 -1\n\n`-` 혹시 `imdb['unsupervised'][??]` 의 모든 라벨값이 모두 `-1`인가?\n\n- 일단 라벨은 -1 밖에 없음. \n\n`-` 느낌상 `imdb['unsupervised']`는 `imdb['train']` 와 `imdb['test']` 에서 text를 합치고, label은 모두 `-1` 로 바꾼 자료가 아닐까? 하는 의심이 들었음. ---> 아니었음.. \n\n## F. 정리 \n\n`-` 요약: \n\n- `imdb`는 `imdb['train']`, `imdb['test']`, `imdb['unsupervised']` 로 나누어져 있음. \n- `imdb['train']`, `imdb['test']` 에는 각각 (text,label)와 같은 형식으로 정보가 저장되어 있음. 여기에서 label은 0 혹은 1의 값을 가지는데 0은 부정, 1은 긍정을 의미함. \n- `imdb['unsupervised']` 에도 조사해보니 각각 (text,label)와 같은 형식으로 정보가 저장되어 있었지만, 여기에서 label값은 모두 -1의 값만 있었음. 따라서 사살상 `imdb['unsupervised']`는 text에 대한 정보만 있다고 생각해도 무방. 그 text가 영화에 대한 긍정평가인지 부정평가인지 분류가 되어있지 않은 상태. \n\n`-` 외우세요: `train`, `test`, `unsupervised` 와 같은 단어는 매우 중요한 단어니까 일단 눈여겨보세요 \n\n# 8. 지도학습 흐름 \n\n## A. 기계학습/딥러닝 과업\n\n`-` 왜 데이터가 `imdb['train']`, `imdb['test']`, `imdb['unsupervised']` 와 같이 나누어져 있는가? \n\n- 개념: 기계학습/딥러닝은 과업은 크게 지도학습과 비지도학습이 있음. \n- 데이터에서 `imdb['train']`, `imdb['test']` 는 지도학습 모델을 배우기 위한 예제데이터이고, `imdb['unsupervised']`는 비지도학습모델을 배우기 위한 예제데이터임. \n- 아무튼 우리가 하는 \"감성분석\"은 지도학습이고, 따라서 우리는 `imdb['train']`, `imdb['test']` 에만 관심을 가질 예정임. \n\n## B. 지도학습 \n\n`-` 지도학습이란? (이 예제에 한정하여 설명)\n\n- 자료가 \"(텍스트, 라벨)\" 의 형태로 정리가 되어 있을때, \"텍스트\"를 입력으로 주면 \"라벨\"을 출력해주는 함수 `f`를 찾는 일 \n- 코드로 예를들어 설명하면 적당히 `f`라는 함수가 존재하여 아래와 같은 동작이 가능하도록 해야함. \n\n```Python\nf(\"영화가 너무 재미없어요\")\n> \"부정평가입니다\"\n\nf(\"영화, 괜찮은데요??\")\n> \"긍정평가입니다\"\n\nf(\"배우들 연기 진짜 잘함. 영상미도 있음. 그런데 스토리 때문에 망했네.\")\n> \"부정평가입니다\"\n\n```\n\n`-` 이러한 함수 `f`를 우리가 잘 정의한다면 좋겠음. (가능한가??)\n\n`-` 대충 아래와 같은 과정을 거친다고 생각하면 편리함. \n\n> 정보(숫자,텍스트,이미지,...) $\\to$ 숫자 $\\to$ 계산 $\\to$ 계산된숫자 $\\to$ 정보\n\n`-` 예를들면 아래와 같은 방식이 가능 \n\n- 긍정평가군!\n\n`-` 당연히 현재는 많은 문제점이 있음. \n\n`-` 다행인점: 좋은 `f`를 만들기 위해서 우리가 고민할 필요 없음. (똑똑한 사람들이 다 만들어 놓음. 그리고 만들고 있음.)\n\n- 옛날방식: `f` 를 한땀한땀 설계. 초고수가 밤새 코딩해서 진짜 잘 맞추는 `f`를 한번에 제시. \n- 최근방식: `f` 를 대충 설계. 거의 멍청이 수준의 `f`임. 그런데 데이터를 줄수록 `f`가 점점 똑똑해짐. 나중에는 다 맞춤. --> 인공지능??? \n\n## C. train/test 자료의 의미 \n\n`-` 초고수가 `f`를 직접 설계하던 시대에는 별로 문제가 없었음. 그런데 최근 컴퓨터가 데이터를 보고 `f`를 스스로 수정하기 시작하면서 이상한 방식으로 `f`가 수정되는 경우가 보고되고 있음. `f`가 똑똑해 보이는데, 사실 멍청한 상태..\n\n- 어떻게 이런일이 가능하지?? \n\n`-` 최규빈 교수의 착각 \n\n- 상상: 나는 학생들에게 파이썬프로그래밍을 잘 강의하고 싶었다. 나는 학생들에게 다양한 문제를 풀어줬으며, 문제를 풀면서 학생들이 스스로 개념을 깨우치길 원했다. 나는 다양한 예시를 통해서 이해하는 것이 좋다고 생각했기 때문이다. 예시는 많을수록 좋으니까 한 학기동안 총 1000개의 문제를 풀어줬다. 기말고사는 풀어준 문제중에서 약 20문항을 샘플링하여 출제했다. 놀랍게도 학생들이 모두 만점을 받았으며 나는 아주 만족스러웠다. 한 학기 동안 고생한 보람이 있어보였다. 눈물이 흘렀다. \n- 질문: 최규빈 교수는 잘 평가한 걸까요? 학생들이 진짜 파이썬프로그래밍을 잘 이해했을까요?? (학과교수님들께 자랑해도 될까요?)\n- 이렇게 질문하고 싶지 않아요?: 1000개의 문제에서 샘플링하여 출제하지 않고, 새로운 문항을 개발하여 학생들에게 제시했다면??\n- 요령이 있는 교수라면 이렇게 했을거에요: 50000개의 문제세트가 있다고 하자. 수업시간에는 학생들에게 예시로 25000개 정도의 문항을 풀이하며 설명. 기말고사는 수업시간에 풀이하지 않은 25000개의 문항을 출제함. \n- 만약에 학생들이 수업시간에 풀어준 25000개의 문제를 올바르게 이해했다면, 수업시간에 풀이하지 않은 문항 25000개 역시 잘 풀었을 것임. \n\n`-` 이 상황을 살짝 말만 바꿔볼게요. \n\n- 상상: 나는 인공지능에게 \"영화평가 텍스트를 주면 그것이 긍정평가인지 부정평가인지 판단하는 능력\"을 잘 학습시키고 싶었다. 나는 인공지능에게 다양한 데이터를 제공했으며, 데이터를 보고 인공지능이 스스로 원리를 깨우치길 원했다. 데이터는 많을수록 좋으니까 약 50000개의 \"(텍스트,라벨)\" 쌍을 제공했다. 그리고 50000개의 \"(텍스트.라벨)\" 쌍에서 약 20문항을 샘플링하여 테스트했다. 놀랍게도 인공지능은 20문항을 모두 맞추었다. 나는 아주 만족스러웠다. 눈물이 흘렀다. \n- 질문: 저는 인공지능을 잘 학습시켰을까요? \n- 이렇게 하고 싶지 않아요?: 50000개의 데이터중, 25000개의 \"(텍스트,라벨)\"만 인공지능에게 제공하여 학습시킴. 그리고 나머지 25000개는 평가용으로 테스트해봄. \n- 만약에 인공지능이 진짜 영화평가 텍스트를 바탕으로 그것이 긍정평가인지 부정평가인지 판단하는 능력을 길렀다면?? 내가 인공지능에게 제공하지 않은 25000개의 데이터에 대해서도 함수 `f` 가 올바르게 동작해야함. \n\n`-` train data / test data \n\n- train data 는 인공지능에게 학습용으로 제공하는 데이터 \n- test data 는 인공지능이 진짜 잘 학습했는지 평가하기 위해 학습시 제공하지 않는 자료 \n\n## D. train/val/test 자료의 의미 \n\n`-` 학생들 입장에서 생각해본다면??\n\n- 소망: 내가 외우려고 한게 아니고, 하도 공부를 많이 하다보니 문제가 외워졌음. 나도 그러기 싫음. 나도 내가 올바르게 공부했는지 체크하고 싶어. \n- 아이디어: 교수님이 풀어준 25000개의 문항중, 15000개만 전략적으로 공부함. 그리고 나머지 10000개는 나 스스로 올바르게 공부했는지 체크하는 용도로 삼음. \n- 진행사항: \n    - 1일차: `{15000문항: 50%맞음, 10000문항: 45%맞음}`  \n    - 2일차: `{15000문항: 90%맞음, 10000문항: 85%맞음}`\n    - 3일차: `{15000문항: 100%맞음, 10000문항: 70%맞음}` <--- 이런 경험 있어요?? \n- 판단: 이게 한 3일차쯤 공부하다보니까 문제를 내가 너무 외운것 같네? 오히려 2일차일때의 느낌이 더 좋음. 그냥 2일차의 느낌으로 시험보러 가자!!\n\n\n`-` 이럴경우 아래와 같이 상황이 정리된다. \n\n- 원래: 교수가 수업시간에 풀어준 25000문제 = 학생이 공부할 25000문제 = train // 교수가 기말시험으로 제출할 25000문제 = test \n- 바뀐상황: 학생이 공부할 15000문제 = train / 학생이 자가진단용으로 으로 뺀 10000문제 = test // 교수가 기말시험으로 제출할 25000문제 = 찐test \n\n`-` 학생이 자가진단용으로 빼둔 10000개의 문항을 보통 validation set 이라고 부른다. 따라서 아래와 같이 정리 가능하다. \n\n- train = 15000문제 = 학생이 스스로 공부 \n- validation = 10000문제 = 학생이 공부할때 사용하지 않음. 자가진단용. \n- test = 25000문제 = 교수가 출제하는 시험 \n\n`-` train / validation / test 에 대한 용어는 엄밀하지 않게 사용되는 경우가 많아 그때그때 상황에 맞게 알아서 해석해야 한다. \n\n- 억지상황1: 교수가 시험보지 않음. 그런데 내가 스스로 공부하면서 잘 공부하고 있는지 체크하고 싶어서 1000개의 문제를 구하고 그중 매일 800개만 학습하고 200개는 검증용으로 사용함. 이 경우 200개의 문항을 validation 이라고 부르기도 하고 test 라고 부르기도 함. (엄밀하게는 validation이 맞다고 생각하지만, 외부데이터가 없는 상황이므로 validation과 test의 경계가 흐릿해짐)\n- 억지상황2: 나 혼자 1000개의 문항을 800/200으로 나누어 매일 공부하고 있었음. 이때 나는 200개의 문항을 test라고 부르기도 하고, validation이라고 부르기도 했음. 그런데 갑자기 교수가 나보고 외부 코딩대회에 나가라고 함. 이 경우 200개의 문항은 validation 이 되고 외부코딩대회에서 출제된 문항이 test가 됨. \n\n`-` 느낌: 아래가 가장 정확한 설명임 \n\n- train: 학습에 사용하는 자료 \n- validation: 학습에 사용하지 않는 자료. 왜 안써? 더 좋은 훈련을 위한 목적. \n- test: 학습에 사용하지 않는 자료. 왜 안써? 올바르게 학습됨을 평가하기 위한 목적. \n\n> 헷갈리는 이유는 더 좋은 훈련을 위한 목적과 올바르게 학습됨을 평가하기 위한 목적이 무 자르듯이 구분되지 않기 때문. \n\n`-` 이상한 분류법\n\n- 데이터를 보통 2개의 셋으로 나누면 train/test 로 3개로 나누면 train/test/validation 으로 많이 표현. \n- 딱 맞는 정의는 아님. 의미상 구분해야함. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"reference-location":"margin","toc":true,"output-file":"01wk-2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.533","theme":"cosmo","title-block-banner":false,"comments":{"utterances":{"repo":"guebin/MP2023"}},"cap-location":"margin","citation-location":"margin","bibliography":["ref.bib"],"code-copy":true,"title":"01wk-2: IMDB 자료 살펴보기, 지도학습의 개념","author":"최규빈","date":"09/06/2024"},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","reference-location":"margin","output-file":"01wk-2.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":false,"comments":{"utterances":{"repo":"guebin/MP2023"}},"cap-location":"margin","citation-location":"margin","bibliography":["ref.bib"],"title":"01wk-2: IMDB 자료 살펴보기, 지도학습의 개념","author":"최규빈","date":"09/06/2024"}}},"projectFormats":["html"]}