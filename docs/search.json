[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "기계학습활용 (2024)",
    "section": "",
    "text": "질문하는 방법\n\n카카오톡: 질문하러 가기\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 카카오톡이나 이메일로 미리 시간을 정할 것\nLMS쪽지: https://ieilms.jbnu.ac.kr/\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 6, 2024\n\n\n01wk-3: IMDB 자료 살펴보기, 지도학습의 개념\n\n\n최규빈 \n\n\n\n\nSep 5, 2024\n\n\n01wk-2: Quiz\n\n\n최규빈 \n\n\n\n\nSep 3, 2024\n\n\n01wk-1: 강의소개\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01wk-1-강의소개.html",
    "href": "posts/01wk-1-강의소개.html",
    "title": "01wk-1: 강의소개",
    "section": "",
    "text": "1. 강의영상\n{{&lt; video:  https://youtu.be/playlist?list=PLQqh36zP38-y_Wv9ErIPPdZwrxdTrerUM&si=lJFCcFxkqf2tKh_c&gt;}}\n\n\n2. 이 수업을 들어야 하는 이유\n\npass\n\n\n\n3. 이 수업을 듣지 말아야 하는 이유\n1. F학점을 줄 수 있음.\n\n모든 퀴즈를 보더라도 성적미달시 F학점 부여\n졸업이 임박한 경우 수강을 권장하지 않음\n\n2. 플립러닝\n\n수업은 비대면수업으로 진행하며, 수업 시간에는 퀴즈를 봄.\n대면 수업에 익숙하고 비대면 수업에 익숙하지 않은 학생들의 경우 수강을 권장하지 않음.\n매주 진행되는 퀴즈가 부담스러운 학생은 수강을 권장하지 않음.\n\n3. 기계학습, 기계학습활용\n\n기계학습활용: 이론적인 설명을 최소화하고, 실습 및 활용에 중점을 둔 수업\n기계학습: 이론과 실습을 같이 배우는 수업\n기계학습활용과 기계학습은 선수과목관계가 아니며, 기계학습활용을 듣지 않고도 기계학습을 이해하는데 문제가 없음.\n\n4. 잘하는 사람들이 많다.\n\n통계학과 고학년, 타학과 고수들\n\n5. 학점이 짜다.\n\n짜게 느껴진다가 더 정확한 표현같아요\n\n6. 파이썬문법이 선행되어야 함.\n\n리스트를 만드는 방법, numpy array가 무엇인지, colab 사용방법 등을 설명하지 않음.\n\n7. cost-effective 하지 않다.\n\n여러가지 이유로..\n이 교과목을 위해서 너무 많은 노력을 해야한다면 드랍하는 것이 좋다고 생각함.\n\n\n\n4. 학점산정방식\n- 강의계획서: 중간40, 기말40, 출석10, 과제10\n- 실제운영: 퀴즈90, 과제10\n\n매주 퀴즈를 보므로 출석은 퀴즈에 포함\n중간/기말 대신 매주 퀴즈로 평가하므로 중간/기말 점수도 퀴즈에 포함된다고 볼 수 있음."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/01wk-2-Quiz.html",
    "href": "posts/01wk-2-Quiz.html",
    "title": "01wk-2: Quiz",
    "section": "",
    "text": "항목\n허용 여부\n비고\n\n\n\n\n강의노트 참고\n허용\n수업 중 제공된 강의노트나 본인이 정리한 자료를 참고 가능\n\n\n구글 검색\n허용\n인터넷을 통한 자료 검색 및 정보 확인 가능\n\n\n생성 모형 사용\n허용 안함\n인공지능 기반 도구(GPT 등) 사용 불가\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n모든 문항은 부분점수 없음.\n일부문항은 부분문제를 모두 맞출경우만 정답으로 인정함.\n.ipynb 파일 형태로 LMS에 제출된 답안지만 채점하며 그 외의 형식 (.hwp등)은 채점하지 않음. 즉 0점 처리함. 제출방법 모르면 물어볼것!\n\n\n\n\n공지사항: (1) 부정행위 적발시 F학점 처리. 부정행위는 판단하는 기준은 교수주관임. (2) 지연제출은 별다른 감점이 없을 예정. 지속적인 지연제출은 감점 대상이 댈 수 있음. (3) 지각역시 별다른 패널티가 없을 예정이나 반복적인 지각은 지양할 것. (4) 모든 퀴즈를 응시하더라도 성적미달시 F가 나올 수 있음.\n\n\n1. 10점\n아래의 코드를 관찰하고 올바르게 해석한 학생을 모두 골라라.\n\n올바르게 해석한 학생을 모두 정확하게 맞출경우만 20점으로 인정하고 그 외의는 0점 처리함\n\n\ndef double_result(func):\n    def wrapper(*args, **kwargs):\n        result = func(*args, **kwargs)\n        return result * 2\n    return wrapper\n\ndef add(a, b):\n    return a + b\n\n@double_result\ndef add2(a, b):\n    return a + b\n\n민수: 데코레이터는 함수 결과를 두 배로 만들어 반환하므로 add2(4, 4)의 결과는 8 * 2 = 16이다. 출력 결과는 16이다.\n선철: add(-2, 2) 와 add2(-2, 2)의 출력결과는 같다.\n예지: 데코레이터는 매개변수(=함수의 입력값)를 두 배로 해서 함수에 전달한다. 그래서 add2(4, 4)는 (4 * 2) + (4 * 2)가 되어 출력 결과는 16이다.\n준현: 데코레이터는 add2 함수의 입력값을 곱해서 리턴하도록 동작한다. 따라서 add2(4, 4)의 결과는 (4 * 4) = 16 이 출력된다.\n\n\n2. 10점\n아래의 코드를 관찰하고 올바르게 해석한 학생을 모두 골라라.\n\n올바르게 해석한 학생을 모두 정확하게 맞출경우만 20점으로 인정하고 그 외의는 0점 처리함\n\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\n\nfor _ in range(5):\n    print(next(gen))\n\n0\n1\n2\n3\n4\n\n\n\nset(dir(gen)) & {'__next__'}\n\n{'__next__'}\n\n\n토르: infinite_sequence()는 무한 루프를 돌며 num 값을 하나씩 yield로 반환하고, next()로 값을 호출할 때마다 그 값을 증가시킨다. 따라서 이 코드는 (0, 1, 2, 3, 4)를 순서대로 출력한다.\n캡틴: infinite_sequence()는 5개의 값을 반환한 후 더 이상 값을 생성하지 않고 종료된다. 즉, 그 이후에 next(gen)을 호출하면 더 이상 값이 반환되지 않고 StopIteration 예외가 발생한다.\n위도우: gen은 호출가능한 객체 (callable object) 이다.\n헐크: 이 코드에서 추가로 아래의 코드를 실행하면\nfor _ in range(10):\n    print(next(gen))\n다음 10개의 값(5, 6, 7, 8, 9, 10, 11, 12, 13, 14)이 순서대로 출력된다.\n\n\n3. 20점\n아래의 코드를 관찰하고 올바르게 해석한 학생을 모두 골라라.\n\n올바르게 해석한 학생을 모두 정확하게 맞출경우만 20점으로 인정하고 그 외의는 0점 처리함\n\n\nclass Dummy:\n    def __init__(self, a):\n        self.a = a\n\nclass Dummy2(Dummy):\n    def __init__(self, a):\n        super().__init__(a)\n        self.a = self.a + 1\n\nclass Dummy3(Dummy):\n    def __init__(self, a):\n        super().__init__(a)\n        self.a = self.a + 2\n\nclass Dummy4(Dummy3, Dummy2):\n    def __init__(self, a):\n        super(Dummy2, self).__init__(a)\n        self.a = self.a + 3\n\n민지: Dummy4 인스턴스를 생성할 때 super(Dummy2, self).__init__(a)가 호출되어, MRO에 따라 먼저 Dummy3의 __init__ 메소드가 실행된다. 그 후 Dummy4의 __init__ 에서 self.a = self.a + 3 이 실행된다.\n시혁: Dummy4 인스턴스를 생성할 때 super(Dummy2, self).__init__(a)가 호출되면 Dummy2의 __init__이 실행된다. 그 후 Dummy4의 __init__ 에서 self.a = self.a + 3 이 실행된다.\n희진: Dummy4는 다중 상속을 받았으므로 Dummy2, 3의 __init__이 모두 실행된다. 그 후 Dummy4의 __init__ 에서 self.a = self.a + 3 이 실행된다.\n팜하니: Dummy4는 다중 상속을 사용하므로 Dummy, Dummy2, Dummy3 의 __init__ 순서대로 모두 호출한다. 그리고 마지막으로 Dummy4의 __init__ 에서 self.a = self.a + 3 이 실행된다.\n\n\n4. 20점\n\n!pip install datasets # 우선 이걸 실행해서 패키지 설치하세요, 못하겠으면 손들고 저를 부르세요\n\n아래의 코드를 관찰하고 올바르게 해석한 학생을 모두 골라라.\n\n올바르게 해석한 학생을 모두 정확하게 맞출경우만 20점으로 인정하고 그 외의는 0점 처리함\n\n\nfrom datasets import load_dataset\nimdb = load_dataset(\"imdb\")\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n동용: load_dataset은 function 클래스에서 생성된 인스턴스이다.\n태한: imdb 는 __len__ 메소드를 가지고 있다. 따라서 len(imdb) 는 실행가능한 코드임을 알 수 있다.\n대영: imdb['train'], imdb['test'] 역시 모두 __len__ 메소드를 가지고 있다. 그리고 len(imdb['train']) + len(imdb['train']) 의 값은 len(imbd)의 값과 같다.\n현수: imdb['train']는 __iter__ 메소드를 가지고 있다. 따라서 아래의 코드가 실행가능하다.\niterator = iter(imdb['train'])\nprint(next(iterator))\nprint(next(iterator))\n\n\n5. 40점\n주어진 load_dataset() 함수의 도움말에 대한 설명을 보고, 설명이 맞으면 O, 틀리면 X를 선택하라.\n\n모두 맞출 경우만 정답으로 인정\n\nload_dataset?\nSignature:\nload_dataset(\n    path: str,\n    name: Optional[str] = None,\n    data_dir: Optional[str] = None,\n    data_files: Union[str, Sequence[str], Mapping[str, Union[str, Sequence[str]]], NoneType] = None,\n    split: Union[str, datasets.splits.Split, NoneType] = None,\n    cache_dir: Optional[str] = None,\n    features: Optional[datasets.features.features.Features] = None,\n    download_config: Optional[datasets.download.download_config.DownloadConfig] = None,\n    download_mode: Union[datasets.download.download_manager.DownloadMode, str, NoneType] = None,\n    verification_mode: Union[datasets.utils.info_utils.VerificationMode, str, NoneType] = None,\n    ignore_verifications='deprecated',\n    keep_in_memory: Optional[bool] = None,\n    save_infos: bool = False,\n    revision: Union[str, datasets.utils.version.Version, NoneType] = None,\n    token: Union[bool, str, NoneType] = None,\n    use_auth_token='deprecated',\n    task='deprecated',\n    streaming: bool = False,\n    num_proc: Optional[int] = None,\n    storage_options: Optional[Dict] = None,\n    trust_remote_code: bool = None,\n    **config_kwargs,\n) -&gt; Union[datasets.dataset_dict.DatasetDict, datasets.arrow_dataset.Dataset, datasets.dataset_dict.IterableDatasetDict, datasets.iterable_dataset.IterableDataset]\nDocstring:\n여기서 부터는 너무 기니까 생략~\n1 path는 위치 인자로 전달될 수 있다.\n2. name 인자는 함수 호출 시 키워드 인자로 전달될 수 있으며, 기본값은 None이다.\n3. load_dataset() 함수는 가변 위치 인자를 허용하지 않는다.\n4. config_kwargs는 가변 키워드 인자이며, 추가적인 키워드 인자를 받기 위한 것이다.\n5. path의 타입 힌트는 str이다. 하지만 이것이path 인자의 값을 문자열 값만 전달될 수 있다는 의미는 아니다. Python에서 타입 힌트는 강제적인 제약이 아니라 개발자에게 코드의 의도를 알리기 위한 도구일 뿐이다. 따라서 Python에서는 타입 힌트를 무시하고 다른 타입의 값을 전달할 수 있다.\n6. split 인자의 타입 힌트는 Union[str, datasets.splits.Split, NoneType]이므로, 문자열(str), datasets.Split 객체, 또는 None의 형태를 입력으로 권장한다.\n7. download_config 인자는 가변 키워드 인자로 전달된다.\n8. data_dir은 위치 인자로도 전달될 수 있다.\n9. cache_dir 인자의 타입 힌트는 Optional[str]이므로, 문자열(str) 또는 None의 형태를 입력으로 권장한다.\n10. **config_kwargs는 함수 호출 시 몇 개의 키워드 인자를 받을 수 있는지 미리 알 필요가 없다."
  },
  {
    "objectID": "posts/01wk-3.html",
    "href": "posts/01wk-3.html",
    "title": "01wk-3: IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "",
    "text": "1. 상상 혹은 경험\n- 데이터 분석을 하고 싶음.\n\n할 줄 아는 것이 별로 없음.\n이론적으로 처음부터 익히려고 했는데, 도저히 각이 안나옴. (엄두가 나지 않음)\n블로그등을 보면서 데이터를 분석하는 코드를 독학하기로 함.\n전략: (1) 블로그의 코드를 돌려본다. (2) 블로그의 코드를 이해한다. (이론을 이해하는게 아님. 코드의 흐름을 이해하는 것임) (3) 블로그의 코드에서 데이터를 읽는 부분만 내가 사용할 데이터로 바꿔침 (4) 돌려서 결과를 제출.\n\n- 어려울 것이라 예상되는 점.\n\n(1) 안 돌아감. import 부터 잘 안될 것임.\n(2) 이해가 안될걸??\n(3) 이게 진짜 어려움. 이걸 잘하기 위해서는 파이썬의 기본 문법이 강해야함.\n(4) 돌아는 가지만 결과가 좋지 않을 것임.\n\n- 소망: 아래가 되었으면..\n\n(1)-(4)의 과정이 매끄럽게 진행되면 좋겠다..\n이 과정이 빠르게 반복되면서 여러코드를 최대한 빨리/많이 정리될 수 있다면..\n그래서 비슷한 분석을 나중에 해야 할 일이 있을때 참고할 거리가 많으면…\n나중에는 코드가 동작하는 공통적인 원리를 깨우쳐 스스로 데이터를 보면서 얼개를 잡아나갈수 있고, 어느정도 분석도 할 수 있는 수준이 되었으면..\n\n- 마음가짐: 컨셉을 잘 잡아야함..\n\n나는 어떠한 코드도 짤 수 있는 사람이다. X\n나는 어떠한 코드도 이해할 수 있는 사람이다. X\n나는 어떠한 코드도 베낄 수 있는 (활용할 수 있는) 사람이다. O\n\n\n느리지만 정확하게 해결하는것은 옳지 않다. 모든 분석은 시간싸움임. 느려지는 순간 이미 뒤쳐진다. (마라톤을 하는게 아님. 100m 달리기임)\n\n- 저는 컴공과 교수가 아니에요.. (그럴만한 실력도 없어요) 그냥 먹고살기 위해서 눈치껏 코딩을 할 뿐입니다..\n\n그래서 강의노트도 무식하게 만들예정..\n이전에는 예쁘게 만든 편임.. (빅데이터 혁신공유대학 사업.. 서해안권 어쩌고.. 충남대학생들이 들었음)\n\n\n\n2. 감성분석 공부재료\n- 좋은 공부재료 (데이터+분석방법) 를 잘 선정해야함. 이게 사실 어려워요..\n\n수업시간에 하는 예제는 좋은 예제에요. 고르고 고른 자료들입니다. 분석방법도 선별한 중요한 방법들임 (성능이 좋거나, 최신 유행이거나, 고전적인 상식수준의 알고리즘)\n그 외에는 몇개의 유명한 사이트를 즐겨찾기 해놓고 시간날때마다 공부하는 것이 좋음.\n일단 이번시간에 추천하는 사이트는.. https://huggingface.co/docs/transformers/index 입니다.\n\n- ref: https://huggingface.co/docs/transformers/tasks/sequence_classification\n\nref는 reference의 약자.\n해당 사이트를 참고했다는 의미.\n원 작가에 대한 예의 + 나중에 공부할때도 좋음. –&gt; 대학생활하면서 숙제하실때도 참고하세요..\n없어보이는 행동이 아님. 더 빛나게 만들어주는 행동이라 생각함..\n\n- 허깅페이스\n\n대부분의 경진대회 분석은 (1) tabular 를 분석하는 경우 (2) tabular 데이터가 아닌 자료를 분석하는 경우로 나눌 수 있음.\nTabular 데이터를 분석하는 여러가지 전통적인 방법이 있으나 우승하려면 거의 무조건 XGBoost, LightGBM, CatBoost 중 하나를 써야함. 의사결정나무 기반의 알고리즘을 사용해야합니다. (의사결정나무가 거의 크랙임. 회귀분석, 로지스틱, SVM 등등.. 다 필요없음)\nTabular 데이터가 아닌 자료를 분석하는 경우는 딥러닝 모형을 사용해야함. 여러가지 모형이 있지만 transformer 기반의 모형이 크랙임.\n허깅페이스는 transformer 기반의 다양한 모델(=분석방법)을 다운로드 하고 사용하기 용이하게 도와주는 사이트(hub)임.\n\n\n\n3. Install"
  }
]