{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11wk-1: `data_collator`\n",
        "\n",
        "최규빈  \n",
        "2024-11-22\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/11wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상\n",
        "\n",
        "<https://youtu.be/playlist?list=PLQqh36zP38-yntkaNrZmlqWVX-ineTf4k&si=xZ1WZainJuXiHheC>\n",
        "\n",
        "# 2. Imports"
      ],
      "id": "dfdc067d-1818-4a46-a285-d9ce2df9687b"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\""
      ],
      "id": "dad4c88c-28b7-4606-aede-bec8621faa8b"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets \n",
        "import transformers\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils\n",
        "import evaluate"
      ],
      "id": "31afc0f9-ad5d-4919-847c-9b89fcd87c55"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. `data_collator` 이해\n",
        "\n",
        "## A. 외우세요 $(\\star\\star\\star)$\n",
        "\n",
        "`-` `data_collator`를 잘 설계하는 방법: `trainer_input`과 `model`이\n",
        "주어졌을때 `data_collator`는 아래의 코드가 동작하도록 설계하면 된다.\n",
        "\n",
        "``` python\n",
        "trainer_input = ~~~\n",
        "model = ~~~~ \n",
        "#---#\n",
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x\n",
        ") # 이 과정에서 model이 cuda로 감 \n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "model.to(\"cpu\") # 경우에 따라 생략해야할수도있음\n",
        "model(**data_collator(single_batch))\n",
        "```\n",
        "\n",
        "`-` 위의 코드가 오류없이 실행되었다면 아래의 코드를 사용할 수 있다.\n",
        "\n",
        "``` python\n",
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = data_collator\n",
        ")\n",
        "trainer.predict(trainer_input)\n",
        "```\n",
        "\n",
        "> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제\n",
        "\n",
        "> **Important**\n",
        ">\n",
        "> 코랩사용자의 경우 아래와 같이 wandb(Weights & Biases) 로그인을\n",
        "> 요구하는 문제가 있습니다.\n",
        ">\n",
        "> ``` bash\n",
        "> wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
        "> wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
        "> wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
        "> wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
        "> wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n",
        "> ```\n",
        ">\n",
        "> 이를 해결하기 위해서는 아래의 코드를 코랩처음에 실행하면 됩니다.\n",
        ">\n",
        "> ``` python\n",
        "> import os\n",
        "> os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "> ```\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> 주의: `trainer_input`의 type이 꼭 `Dataset` 일 필요는 없다..\n",
        "\n",
        "## B. IMDB – 복습\n",
        "\n",
        "ref:\n",
        "<https://huggingface.co/docs/transformers/tasks/sequence_classification>\n",
        "\n",
        "*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*"
      ],
      "id": "64f233c3-a46e-4587-b791-8e205116f07d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|█████████████████████████████| 10/10 [00:00<00:00, 1694.39 examples/s]"
          ]
        }
      ],
      "source": [
        "imdb = datasets.load_dataset(\"guebin/imdb-tiny\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "tokenized_imdb = imdb.map(preprocess_function,batched=True)\n",
        "trainer_input = tokenized_imdb['train']\n",
        "trainer_input"
      ],
      "id": "71cd490d-ae86-4920-b487-79c7c45fec7b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*"
      ],
      "id": "594a8db7-6a86-4073-8634-edb7e76bdbba"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
        ")"
      ],
      "id": "0610264c-a333-4ea1-9e1d-8108817eea00"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*3. 데이터콜렉터: `DataCollatorWithPadding()` $\\to$ `data_collator`*"
      ],
      "id": "b388ac3e-03b2-4b44-97b7-f9aa5fa6d172"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "data_collator"
      ],
      "id": "87136dce-a4be-4a18-9db6-8f346a989d78"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어\n",
        "\n",
        "``` python\n",
        "trainer.predict(trainer_input)\n",
        "```\n",
        "\n",
        "이 정상동작하는지 확인하라.\n",
        "\n",
        "`(풀이)`"
      ],
      "id": "8abc9d6c-b7b2-476e-ad64-de5ebd29d1cb"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x\n",
        ") # 이 과정에서 model이 cuda로 감 \n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "model.to(\"cpu\") # 경우에 따라 생략해야할수도있음\n",
        "model(**data_collator(single_batch))"
      ],
      "id": "483da651-055e-4807-b126-fd510eb4f931"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   잘 돌아갔음. (=여기에서 사용된 데이터콜렉터는 잘 설계된\n",
        "    `data_collator` 라는 의미)"
      ],
      "id": "05d59b3d-1735-43df-89b9-52e48cbeefc0"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = data_collator\n",
        ")\n",
        "out = trainer.predict(trainer_input)\n",
        "out "
      ],
      "id": "c6a72b78-ddbb-4945-a1ae-19651f01427c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "`-` 관찰1: `batched_data[-1]` 는 하나의배치(single_batch)를 의미함.\n",
        "모델의 입력으로는 부적절한 형식임."
      ],
      "id": "cb0100cd-f1ef-41ae-af72-b4d181d0d0fb"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# batched_data[-1] -- 부적절해보이는 모델입력.."
      ],
      "id": "4c813562-c818-4365-af02-11dcd5c8ea25"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "model(**batched_data[-1])"
      ],
      "id": "8d87a224-68ce-4a3d-9be3-1404224e5e39"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 관찰2: `data_collator(batched_data[-1])` 역시\n",
        "하나의배치(single_batch)를 의미함. 그런데 이것은 모델의 입력으로도\n",
        "적절한 형식."
      ],
      "id": "40a327b9-b822-4ab8-9d27-f567a770ea68"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator(batched_data[-1]) # 모델의 입력으로 매우 바람직해 보이는 형식임 "
      ],
      "id": "d481e53e-4099-4fc0-b3f4-7c400d99fb7a"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(\"cpu\")\n",
        "model(**data_collator(batched_data[1]))"
      ],
      "id": "c0fef91b-a769-40f3-9682-69111b7f99f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **`data_collator` – 심화이해**\n",
        ">\n",
        "> 아래의 형식으로 정리된 배치화된 자료가 있다고 하자. (주의:\n",
        "> `batched_data`는 항상 list비슷한 오브젝트이어야함)\n",
        ">\n",
        "> ``` python\n",
        "> batched_data = [batch_1, batch_2, ...,batch_n]\n",
        "> ```\n",
        ">\n",
        "> `data_collator` 는 각각의 `single_batch`, 즉 `batch_1`, `batch_2` 등을\n",
        "> `model`이 처리가능한 형태로 “형식”을 맞춰주는 역할을 한다. 즉 아래가\n",
        "> 실행되도록 만들어주는 역할을 한다.\n",
        ">\n",
        "> ``` python\n",
        "> model(**data_collator(batch_1))\n",
        "> ```\n",
        "\n",
        "> **`trainer`와 `model`의 자료처리과정 비교**\n",
        ">\n",
        "> ***#. `model`의 자료처리과정***\n",
        ">\n",
        "> -코드: `model.forward(model_input)`\n",
        ">\n",
        "> -처리과정: `model_input`에 정리된 입력을 단순히 `model.forward()`\n",
        "> 함수가 처리.\n",
        ">\n",
        "> ***#. `trainer`의 자료처리과정***\n",
        ">\n",
        "> -코드: `trainer.predict(trainer_input)`\n",
        ">\n",
        "> -처리과정: 배치화 $\\to$ 데이터콜렉팅 $\\to$ 추론의 3단계를 거친다.\n",
        ">\n",
        "> 1.  `trainer_input`을 배치(batch)로 나눈다.\n",
        "> 2.  각 배치(=`single_batch`)를 `data_collator`를 통해 형식을 맞춘다.\n",
        "> 3.  형식이 조정된 데이터를 `model.forward`의 입력으로 전달한다.\n",
        ">\n",
        "> -슈도코드:\n",
        ">\n",
        "> ``` python\n",
        "> ## 이 코드는.. \n",
        "> trainer.predict(trainer_input)\n",
        ">\n",
        "> ## 대략 아래의 느낌으로 해석하면 된다.. (동일X. 결과정리, GPU처리 등 세부로직이 더 있음)\n",
        "> batched_data = some_function(trainer_input)\n",
        "> for single_batch in batched_data:\n",
        ">     collated_data = data_collator(single_batch)\n",
        ">     model(**collated_data)\n",
        "> ```\n",
        "\n",
        "> **`trainer.predict()` 의 분해**\n",
        ">\n",
        "> `trainer.predict()`의 동작은 개념적으로 (1) 배치화 (2) 데이터콜렝팅\n",
        "> (3) 추론의 과정으로 분해할 수 있지만, 실제이러한 과정으로 코드를\n",
        "> 정확하게 분리하는건 어렵다. (그리고 저 사이사이에는 다른 자잘한\n",
        "> 과정들이 많다..) 하지만 이해를 위해서 코드조각을 억지로 분리해본다면\n",
        "> 아래 3개의 코드조각으로 분리할 수 있을것이다.\n",
        ">\n",
        "> `1`. 배치화: `trainer_input` $\\to$ `batched_data`\n",
        ">\n",
        "> ``` python\n",
        "> batch_maker = transformers.Trainer(\n",
        ">     model = model,\n",
        ">     data_collator = lambda x: x\n",
        "> )\n",
        "> _batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
        "> batched_data = list(_batched_data)\n",
        "> ```\n",
        ">\n",
        "> `2`. 데이터콜렉팅: `single_batch` $\\to$ `collated_data`\n",
        ">\n",
        "> ``` python\n",
        "> #for single_batch in batched_data:\n",
        ">     collated_data = data_collator(single_batch)\n",
        "> ```\n",
        ">\n",
        "> `3`. 추론: `collated_data` $\\to$ `model_out`\n",
        ">\n",
        "> ``` python\n",
        "> #for single_batch in batched_data:\n",
        ">     #collated_data = data_collator(single_batch)\n",
        ">     model_out = model(**collated_data)\n",
        "> ```\n",
        "\n",
        "## C. FOOD101 – 복습\n",
        "\n",
        "ref:\n",
        "<https://huggingface.co/docs/transformers/tasks/image_classification>\n",
        "\n",
        "*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*"
      ],
      "id": "0a712006-4f7a-47f8-ab25-e922ff13e45f"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`."
          ]
        }
      ],
      "source": [
        "food = datasets.load_dataset(\"guebin/food101-tiny\")\n",
        "image_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "normalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomResizedCrop(size), \n",
        "    torchvision.transforms.ToTensor(), \n",
        "    normalize\n",
        "])\n",
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples\n",
        "trainer_input = food['train'].with_transform(transforms)\n",
        "trainer_input"
      ],
      "id": "8c095a8f-c132-4ed2-8413-1d7e2d08198a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*"
      ],
      "id": "9bd3e01d-0ddf-4a39-b4d9-61eb1051b2d2"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "labels = food[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\",\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "id": "de8bcc77-0431-4a6f-80d1-27b838cc947b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*3. 데이터콜렉터: `DefaultDataCollator()` $\\to$ `data_collator`*"
      ],
      "id": "359b8be4-8ed4-4ec9-910c-67514db93a46"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = transformers.DefaultDataCollator()\n",
        "data_collator"
      ],
      "id": "b9cbb38e-0504-4cd9-a28d-1f85eb100d9a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어\n",
        "\n",
        "``` python\n",
        "trainer.predict(trainer_input)\n",
        "```\n",
        "\n",
        "이 정상동작하는지 확인하라.\n",
        "\n",
        "`(풀이1)` – 실패"
      ],
      "id": "d6ebc750-18ed-47e8-bd11-011488412546"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x \n",
        ")\n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "model(**data_collator(single_batch))"
      ],
      "id": "71c727a7-7799-4c1d-a1cb-e385e32ca26d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 왜 실패했지?? (예전에는 분명히 되었던 것 같은뎅..)\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> **<에러메시지의 해석>**\n",
        ">\n",
        "> `-` 아래가 동작하지 않음.\n",
        ">\n",
        "> ``` python\n",
        "> batched_data = list(_batched_data)\n",
        "> ```\n",
        ">\n",
        "> `-` 그 이유는 아래가 동작하지 않기 때문임.\n",
        ">\n",
        "> ``` python\n",
        "> next(dataloader_iter)\n",
        "> ```\n",
        ">\n",
        "> `-` …(생략)…\n",
        ">\n",
        "> `-` 최종적으로는 아래가 동작하지 않기 때문에 생긴 문제였음. (그런데\n",
        "> 이건 `.with_transform()`에 있는 코드인데?)\n",
        ">\n",
        "> ``` python\n",
        "> examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "> ```\n",
        ">\n",
        "> `-` 결국\n",
        ">\n",
        "> ``` python\n",
        "> [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "> ```\n",
        ">\n",
        "> 를 실행하는 시점에서 `examples[\"image\"]`가 없었다는 의미.\n",
        "\n",
        "> 눈치: `with_transform`이 지금 실행되는거였어?\n",
        "\n",
        "`-` 왜 이런일이 생기지?\n",
        "\n",
        "`-` 배치화를 하는 코드\n",
        "\n",
        "``` python\n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
        "```\n",
        "\n",
        "에서 아래의 column_names:\n",
        "\n",
        "-   `pixel_values`\n",
        "-   `head_mask`\n",
        "-   `labels`\n",
        "-   `output_attentions`\n",
        "-   `output_hidden_states`\n",
        "-   `interpolate_pos_encoding`\n",
        "-   `return_dict`\n",
        "\n",
        "를 제외하고는 모두 트레이너(`batch_maker = trainer`)가 강제로 제거하는\n",
        "로직이 있음.[1]\n",
        "\n",
        "`-` `image`라는 column_name은 위에 해당되지 않으므로 제거됨.\n",
        "\n",
        "`-` 그리고 `image` 칼럼이 제거된 이후에 `with_transform` 이 나중에\n",
        "실행되면서 (지연실행) 문제가 발생.\n",
        "\n",
        "> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제\n",
        "\n",
        "> **중간정리**\n",
        ">\n",
        "> `trainer.predict()` 은 (1) 배치화 (2) 데이터콜렉팅 (3) 추론의 과정을\n",
        "> 거친다. 그리고 배치화와 데이터콜렉팅 사이에 “싱글배치”를 만드는 과정이\n",
        "> 있다.\n",
        ">\n",
        "> -   세부사항1: 그런데 “**배치화**”단계에서 `model.forward()`의\n",
        ">     입력으로 사용되지 않는 columns는 지워지는 내부로직이 존재한다.\n",
        "> -   세부사항2: `trainer_input`에 걸려있는 `.with_transform()`은\n",
        ">     “**배치화**”이후 싱글배치가 만들어지는 과정에서 실행된다.\n",
        ">\n",
        "> 따라서 `.with_transform()` 에서 특정컬럼의 변화시키는 동작이 약속된\n",
        "> 경우, 그 컬럼이 **배치화**의 단계에서 자동제거되어 코드가 돌아가지\n",
        "> 않을 수 있는 위험성이 존재한다.\n",
        "\n",
        "`(풀이2)` – `image`를 `return_dict` 로 위장.. // 완전 테크니컬한 풀이\n",
        "\n",
        "`-` 현재상황: `food['train']`에 `.with_transform(transforms)`을\n",
        "걸어두고(?) `trainer_input`을 만든상황\n",
        "\n",
        "`-` 문제: `trainer.predict()` 내부동작에서 `.with_transform(transform)`\n",
        "이 실현될때\n",
        "\n",
        "[1] 왜 이런 로직이 있을까? 이런 로직이 없다면 model의 args를 강제로\n",
        "외우고 있어야 하니까.."
      ],
      "id": "10e90990-c588-4001-a18c-2415f16e351b"
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Signature: transforms(examples)\n",
            "Docstring: <no docstring>\n",
            "Source:   \n",
            "def transforms(examples):\n",
            "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
            "    del examples[\"image\"]\n",
            "    return examples\n",
            "File:      /tmp/ipykernel_706133/1515420127.py\n",
            "Type:      function"
          ]
        }
      ],
      "source": [
        "transforms??"
      ],
      "id": "9208c47c-a073-4bbc-97f5-e77c440693c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 내용이 실행되어야하는데, `image`는 model의 입력으로 유하하지 않은\n",
        "키라서 트레이너가 이미 제거한 상태임.\n",
        "\n",
        "`-` 전략: 제거가 안되게 막아보자.."
      ],
      "id": "c6b6627f-ddcb-4ebc-b69c-0ded2e7508b9"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model.forward?"
      ],
      "id": "557b831d-a9c0-4403-ba4e-12dba33f7989"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trainer_input = food['train'].with_transform(transforms)\n",
        "trainer_input2 = trainer_input.rename_columns({'image':'return_dict'})\n",
        "trainer_input2"
      ],
      "id": "690817e9-aa83-45dd-b673-29a17c38f6ec"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transforms2(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"return_dict\"]]\n",
        "    del examples[\"return_dict\"]\n",
        "    return examples"
      ],
      "id": "aea39a00-b799-4f67-bdee-812febf8f8eb"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input3 = trainer_input2.with_transform(transforms2)\n",
        "trainer_input3"
      ],
      "id": "fe3a7a79-f6ef-44d2-be7f-7e105bf8357d"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x \n",
        ")\n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input3)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "model(**data_collator(single_batch))"
      ],
      "id": "4e39e170-787a-404c-b81c-9538e42ccdf7"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator= data_collator\n",
        ")\n",
        "trainer.predict(trainer_input3)"
      ],
      "id": "055cd7ea-3f07-46d9-a44d-4ce6b531360c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(풀이3)` – trainer_input 에 예약된 `with_transform`을 지연실행하지 않고\n",
        "즉시 실행"
      ],
      "id": "32f38d0a-15e5-498b-9407-152b9605dd41"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input"
      ],
      "id": "eee109ec-36f1-4d2c-9433-2c27d5a007a6"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input2 = [l for l in trainer_input]\n",
        "#trainer_input2"
      ],
      "id": "b7bce360-8f9c-4152-bd24-62d3dad7419a"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x \n",
        ")\n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input2)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "model(**data_collator(single_batch))"
      ],
      "id": "5d96fe9a-4ec3-44b0-b6da-d5037d5493c7"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator= data_collator\n",
        ")\n",
        "trainer.predict(trainer_input2)"
      ],
      "id": "29fdb21c-bec8-4ee1-bc87-05d4df1562f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(풀이4)` – 트레이너가 가진 “사용하지 않는 column을 제거하는 기능”을\n",
        "`False` 시킴.."
      ],
      "id": "138d3c3b-cdaa-468f-9bcb-500bf59454b5"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input"
      ],
      "id": "3793d6db-8d64-4305-b884-440ffffa2ba0"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "model(**data_collator(single_batch))"
      ],
      "id": "199dec4b-139d-4104-b1a5-34f0abcf117d"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator= data_collator,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )    \n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "11a793e7-e305-4ad1-a399-14edee7f59ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "`(풀이5)` – 트레이너가 가진 “사용하지 않는 column을 제거하는 기능”을\n",
        "`False` 시킬꺼면, `batch_maker`를 고려할 필요도 없이 아래와 같이 바로\n",
        "`single_batch`를 얻을 수 있음.\n",
        "\n",
        "*풀이4: 실제로 trainer가 싱글배치를 얻는 과정과 유사하게 얻는 방법*"
      ],
      "id": "96e50b44-346f-49a9-a18a-37c40c3c1100"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir= \"asdf\", # 아무거나 써야함. \n",
        "        remove_unused_columns= False # 이 부분이 포인트!!\n",
        "    )        \n",
        ")\n",
        "_batched_data = batch_maker.get_test_dataloader(trainer_input)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[0]\n",
        "# single_batch = [\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "#     {'label':int, 'pixel_values': 3d-tsr},\n",
        "# ]    "
      ],
      "id": "7659eb7c-82f7-4113-87ed-2aaa19d53290"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 형식관찰: `single_batch`는 `[Dict, Dict, Dict, .... Dict]` 꼴임을\n",
        "> 주목하라.\n",
        "\n",
        "*풀이5: 형식관찰에 힌트를 얻어 무식하게 얻은 싱글배치*"
      ],
      "id": "5f1887cb-31c2-4cee-a453-231af459a0f9"
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "single_batch = [\n",
        "    trainer_input[0],\n",
        "    trainer_input[1],\n",
        "    trainer_input[2],\n",
        "    trainer_input[3],\n",
        "    trainer_input[4],\n",
        "    trainer_input[5],\n",
        "    trainer_input[6],\n",
        "    trainer_input[7],\n",
        "]"
      ],
      "id": "d43aae24-8606-4256-98d5-bbcdbfc00f2f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*아무튼 풀이5 스타일로 싱글배치를 얻었다면? 이후의 코드는 동일*"
      ],
      "id": "0d86091d-3824-4360-b794-6b95a4c0b09f"
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(\"cpu\")\n",
        "model(**data_collator(single_batch));"
      ],
      "id": "18693c6e-fa15-499d-bb91-b71542ae5f79"
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator= data_collator,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )    \n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "920e15ac-7809-4abd-b9dc-96b572c0e5f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*참고1: 아래의 방식으로 싱글배치를 얻을 수 없음. – 이유?\n",
        "지연실행때문에..*"
      ],
      "id": "0e776e23-718d-4da2-b891-1cf9444c94d6"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "#single_batch = trainer_input.to_list()[:8]"
      ],
      "id": "1ba8c39e-5b82-462a-86a2-e4917b016ed5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*참고2: 아래의 방식으로도 싱글배치를 얻을 수 없음.*"
      ],
      "id": "f6a0347d-36e5-4b7a-9778-5342b10bf675"
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "#single_batch = trainer_input[:8]"
      ],
      "id": "8994af4b-8096-498d-8f19-6cc45554a036"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*이유?*"
      ],
      "id": "976120c1-3cd9-4ff3-8818-4c9281c29f16"
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input[:2] == [trainer_input[0],trainer_input[1]]"
      ],
      "id": "f87f2e15-742a-4063-a979-d291334de790"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. FOOD101 – DefaultDataCollator 구현\n",
        "\n",
        "*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*"
      ],
      "id": "30485fcb-3891-4499-a2c8-a51468d3a356"
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`."
          ]
        }
      ],
      "source": [
        "food = datasets.load_dataset(\"guebin/food101-tiny\")\n",
        "image_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "normalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomResizedCrop(size), \n",
        "    torchvision.transforms.ToTensor(), \n",
        "    normalize\n",
        "])\n",
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples\n",
        "trainer_input = food['train'].with_transform(transforms)\n",
        "trainer_input"
      ],
      "id": "b830cfc2-bb28-41f9-9968-9ef4cd7f9e21"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*"
      ],
      "id": "9dccd94b-56df-42b7-943d-8df29b2923df"
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "labels = food[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\",\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "id": "c01621bd-0365-4636-8913-5b04512ad2b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*3. 데이터콜렉터: `collate_fn` 직접설계*"
      ],
      "id": "8f57667f-dd03-42d4-b8b2-90a3e41435fa"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_collator = transformers.DefaultDataCollator()\n",
        "# data_collator"
      ],
      "id": "4ff687af-d42e-4b3e-ac7e-f3db3d181f34"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(single_batch):\n",
        "    pass"
      ],
      "id": "8ea9b134-9f9a-4597-8038-0389165c9093"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`DefaultDataCollator()` 와 동일한 역할을 하는 `collate_fn`을 설계하라.\n",
        "이를 이용하여 적당한 `trainer`를 만들어\n",
        "\n",
        "``` python\n",
        "trainer.predict(trainer_input)\n",
        "```\n",
        "\n",
        "이 정상동작하는지 확인하라.\n",
        "\n",
        "`(풀이)`"
      ],
      "id": "a4ab39f0-a19e-43a5-8f3a-c63e0c729a55"
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input"
      ],
      "id": "293ba961-f650-42b8-8e50-447fecbceead"
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "# batch_maker = transformers.Trainer(\n",
        "#     model= model,\n",
        "#     data_collator= lambda x: x,\n",
        "#     args = transformers.TrainingArguments(\n",
        "#         output_dir=\"asdf\",\n",
        "#         remove_unused_columns=False\n",
        "#     )\n",
        "# )\n",
        "# _batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
        "# batched_data = list(_batched_data)\n",
        "# single_batch = batched_data[-1]\n",
        "#---#\n",
        "single_batch = [trainer_input[-2],trainer_input[-1]]\n",
        "single_batch"
      ],
      "id": "ea9418a6-b8ab-44a4-866c-39b399a85aed"
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(single_batch):\n",
        "    #single_batch = [Dict,Dict] \n",
        "    #Dict = {'label': 6, 'pixel_values': [3, 224, 224]-tensor\n",
        "    collated_data = dict()\n",
        "    collated_data['labels'] = torch.tensor([dct['label'] for dct in single_batch])    \n",
        "    collated_data['pixel_values'] = torch.stack([dct['pixel_values'] for dct in single_batch])\n",
        "    return collated_data"
      ],
      "id": "9a6f6c3e-0168-4a6b-9fae-e88f368885d5"
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(\"cpu\")\n",
        "model(**collate_fn(single_batch))"
      ],
      "id": "a3657c6b-7843-487b-92be-10fd09c4a283"
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "\n",
            "***** Running Prediction *****\n",
            "  Num examples = 10\n",
            "  Batch size = 8"
          ]
        }
      ],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=collate_fn,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "b8c4ede6-e568-44b5-b1b7-155d90f15143"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## E. IMDB – DataCollatorWithPadding 구현\n",
        "\n",
        "ref:\n",
        "<https://huggingface.co/docs/transformers/tasks/sequence_classification>\n",
        "\n",
        "*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*"
      ],
      "id": "d57b3b82-6c34-4a36-b7f5-d890876a6599"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "imdb = datasets.load_dataset(\"guebin/imdb-tiny\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "tokenized_imdb = imdb.map(preprocess_function,batched=True)\n",
        "trainer_input = tokenized_imdb['train']"
      ],
      "id": "222fed30-5759-4bd2-9921-bbd6734ee144"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*"
      ],
      "id": "c66a9bec-25c5-4596-9926-327fd02bc76f"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
        ")"
      ],
      "id": "2b403722-789e-453b-87be-9971c838ab75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*3. 데이터콜렉터: `collate_fn` 직접설계*"
      ],
      "id": "9869dab8-d498-4c01-9aa5-bd0add21f5d7"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "# data_collator"
      ],
      "id": "33d01cdf-2962-43cf-8b65-97817eb2504c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(single_batch):\n",
        "    pass"
      ],
      "id": "a69b5ba3-44fc-45d0-ac0a-06066250100c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "`DataCollatorWithPadding()` 와 동일한 역할을 하는 `collate_fn`을\n",
        "설계하라. 이를 이용하여 적당한 `trainer`를 만들어\n",
        "\n",
        "``` python\n",
        "trainer.predict(trainer_input)\n",
        "```\n",
        "\n",
        "이 정상동작하는지 확인하라.\n",
        "\n",
        "`(풀이)`"
      ],
      "id": "b6af9b24-99d6-4a40-91b6-20310b8dbf39"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input"
      ],
      "id": "56ce3b1f-e0d0-4cab-9f3d-42a4d44b7568"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model= model,\n",
        "    data_collator= lambda x: x,\n",
        ")\n",
        "_batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]"
      ],
      "id": "a78cb791-bd51-4132-8718-fdf4bf5afe66"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = torch.tensor([dct['label'] for dct in single_batch])\n",
        "labels"
      ],
      "id": "bbb4fcf9-3be1-42e2-a9b3-87559a7bb899"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['input_ids']) for dct in single_batch]).t()\n",
        "input_ids"
      ],
      "id": "17ddcdb8-58be-47cd-9137-936ca2c4a5b1"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_mask = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['attention_mask']) for dct in single_batch]).t()\n",
        "attention_mask"
      ],
      "id": "ce76a9b2-96e0-4e5b-a91d-f463fee7e151"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# single_batch = [Dict, Dict]\n",
        "# Dict = {\n",
        "#     'label': int \n",
        "#     'input_ids': 1d-list \n",
        "#     'attention_mask': 1d-list \n",
        "# }\n",
        "def collate_fn(single_batch):\n",
        "    collated_data = dict()\n",
        "    collated_data['input_ids'] = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['input_ids']) for dct in single_batch]).t()    \n",
        "    collated_data['attention_mask'] = torch.nn.utils.rnn.pad_sequence([torch.tensor(dct['attention_mask']) for dct in single_batch]).t()\n",
        "    collated_data['labels'] = torch.tensor([dct['label'] for dct in single_batch])\n",
        "    return collated_data"
      ],
      "id": "403b9ed5-31e0-4c74-985f-3a0baebbf04e"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "collate_fn(single_batch)"
      ],
      "id": "57f69284-1bdc-421c-a99f-2a46c97e4111"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(\"cpu\")\n",
        "model(**collate_fn(single_batch))"
      ],
      "id": "05281a70-8b3c-4d2a-a3e6-2415b15930ea"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=collate_fn,\n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "858e44c9-63ed-4f54-aeed-68fc254b1b05"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 연습 – `sms_spam`"
      ],
      "id": "c74a3a54-e0b5-4c90-9384-bc7df4a5db6b"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
        ")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "spam = datasets.load_dataset('guebin/spam-tiny')\n",
        "spam"
      ],
      "id": "0395f64b-c3a5-4deb-94c6-3e0730b8fe8b"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam"
      ],
      "id": "108db8a9-0d44-46d5-8808-6b7395174874"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A. 방법1: 고정패딩, `collate_fn`"
      ],
      "id": "372de319-cd73-48f1-aeda-79ce435edb11"
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "def m_trans(example_batch):\n",
        "    # example_batch = {'sms':[xxx,xxxx,...], 'label':[yyy,yyyy] \n",
        "    # example_batch = spam['train'][:8]\n",
        "    out = tokenizer(example_batch['sms'],padding=True,truncation=True)\n",
        "    return out "
      ],
      "id": "58affb00-6c85-4a18-9329-5aabb2b52b26"
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1538.07 examples/s]"
          ]
        }
      ],
      "source": [
        "spam2 = spam.map(m_trans,batched=True,batch_size=8)\n",
        "spam2"
      ],
      "id": "2be22233-3cee-4f88-8bf8-2d0845df16f8"
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam2.set_format(\"pt\")\n",
        "#spam2['train']['input_ids'] -- list of tensor with length 10 "
      ],
      "id": "f08a00a5-2afd-4bc8-8b37-8a94cd8ae8ed"
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam2['train'][8:]['input_ids'] # 2d-tensor "
      ],
      "id": "7786cde4-e7ef-4986-98e2-b6eeaf3704d5"
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam2['train'][7:]['input_ids'] # list of 1d-tensor "
      ],
      "id": "eb8cb797-2cdc-4dc1-a252-530d4bb6496c"
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input = spam2['train'].remove_columns(['sms']).rename_columns({'label':'labels'})\n",
        "trainer_input"
      ],
      "id": "9074786d-b628-4fb6-be8e-73b38451c012"
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model= model,\n",
        "    data_collator=lambda x:x\n",
        ") \n",
        "_batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "single_batch"
      ],
      "id": "69a835e7-664f-4f4e-bf9a-c7957dfc097e"
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.stack([single_batch[0]['labels'],single_batch[1]['labels']])"
      ],
      "id": "7bafe764-bcca-4897-ad6f-b657c91f86d6"
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(single_batch):\n",
        "    out = dict()\n",
        "    out['labels'] = torch.stack([dct['labels'] for dct in single_batch])\n",
        "    out['input_ids'] = torch.stack([dct['input_ids'] for dct in single_batch])\n",
        "    out['attention_mask'] = torch.stack([dct['attention_mask'] for dct in single_batch])\n",
        "    return out "
      ],
      "id": "c4d5117d-75b5-4bf7-aa93-e1ac062693ad"
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [],
      "source": [
        "model(**collate_fn(single_batch))"
      ],
      "id": "046f3ba6-748c-4f9a-bacd-9cf0b44bb392"
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model= model,\n",
        "    data_collator=collate_fn\n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "ce2d70cd-b2f9-4523-a8d4-a853aee7b5b8"
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=collate_fn,\n",
        "    train_dataset=trainer_input,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.train()"
      ],
      "id": "3bd7329b-008f-458e-a3b9-20053070823e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 방법2: 고정패딩, DefaultDataCollator"
      ],
      "id": "59d598d9-15c8-4dd9-8494-59c2fa1b41ed"
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1685.61 examples/s]"
          ]
        }
      ],
      "source": [
        "def m_trans(example_batch):\n",
        "    # example_batch = {'sms':[xxx,xxxx,...], 'label':[yyy,yyyy] \n",
        "    # example_batch = spam['train'][:8]\n",
        "    out = tokenizer(example_batch['sms'],padding=True,truncation=True)\n",
        "    return out \n",
        "spam2 = spam.map(m_trans,batched=True,batch_size=8)\n",
        "spam2.set_format(\"pt\")\n",
        "trainer_input = spam2['train'].remove_columns(['sms']).rename_columns({'label':'labels'})"
      ],
      "id": "563dc0cc-c97a-4fd6-8aeb-2fcfc1abcd0a"
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model= model,\n",
        "    data_collator=lambda x:x\n",
        ") \n",
        "_batched_data = batch_maker.get_eval_dataloader(trainer_input)\n",
        "batched_data = list(_batched_data)\n",
        "single_batch = batched_data[-1]\n",
        "single_batch"
      ],
      "id": "7991c069-f7dc-4bf4-8f6e-6f8ce6cd32b3"
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def collate_fn(single_batch):\n",
        "#     out = dict()\n",
        "#     out['labels'] = torch.stack([dct['labels'] for dct in single_batch])\n",
        "#     out['input_ids'] = torch.stack([dct['input_ids'] for dct in single_batch])\n",
        "#     out['attention_mask'] = torch.stack([dct['attention_mask'] for dct in single_batch])\n",
        "#     return out \n",
        "data_collator = transformers.DefaultDataCollator()"
      ],
      "id": "0e1c0c20-1ab2-4a6c-a94f-4a8bde92455c"
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [],
      "source": [
        "model(**data_collator(single_batch))"
      ],
      "id": "8037ca7f-7a42-486d-9a8d-fad91ca725b3"
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model= model,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "97b50ea9-c014-470d-bec0-16b0cf3d2fa4"
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=trainer_input,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.train()"
      ],
      "id": "c15fbecc-4534-4688-a826-f5233f1beaef"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 방법3: 동적패딩, `DataCollatorWithPadding`"
      ],
      "id": "5812c5bf-17a9-4f5a-9bf5-922225e93fd3"
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam"
      ],
      "id": "97a969bd-7dd5-429e-80c4-36a004dffabd"
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "def w_trans(examples):\n",
        "    # examples = spam['train'][:8] = {'sms': [xxx,xxxx,...], 'label':[yyy,yyyy,...]\n",
        "    out = tokenizer(examples['sms'],truncation=True)\n",
        "    out['labels'] = torch.tensor(examples['label'])\n",
        "    return out "
      ],
      "id": "ae148560-cc29-4e3e-8ff0-42d40d7303a7"
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input = spam.with_transform(w_trans)['train']\n",
        "trainer_input"
      ],
      "id": "5ccad917-bba0-4b84-8e5e-5642b380c7b0"
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_maker = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = lambda x: x,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "single_batch = next(iter(batch_maker.get_eval_dataloader(trainer_input)))\n",
        "#sigle_batch"
      ],
      "id": "3bc25669-91a4-4239-8ec9-103ce4526691"
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = transformers.DataCollatorWithPadding(tokenizer)\n",
        "model.to(\"cpu\")\n",
        "model(**data_collator(single_batch))"
      ],
      "id": "fb2db1de-78e6-4d6d-be0b-48b75376494a"
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model = model,\n",
        "    data_collator = data_collator,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "a2c83652-2ea6-468d-b68b-7677771465a6"
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=trainer_input,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.train()"
      ],
      "id": "4b5f31d9-6f9b-4893-9d0b-f5b18d86793a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. 방법4: 동적패딩, 전처리X $(\\star)$"
      ],
      "id": "dd9a6ccc-b77d-4af5-a259-5672f0eb310c"
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_input = spam['train']\n",
        "trainer_input"
      ],
      "id": "4c7a52d1-83d9-4b5e-97ea-6066a7446490"
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "single_batch = [trainer_input[-2],trainer_input[-1]]\n",
        "single_batch"
      ],
      "id": "66d327a3-32b1-4630-abd9-7f13e4a40a30"
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(single_batch):\n",
        "    out = tokenizer(\n",
        "        [dct['sms'] for dct in single_batch],\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    out['labels'] = torch.tensor([dct['label'] for dct in single_batch])\n",
        "    return out "
      ],
      "id": "73dce43d-3b9c-442f-b44e-b3cf807f3bb1"
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(\"cpu\")\n",
        "model(**collate_fn(single_batch))"
      ],
      "id": "ebf41195-f28c-41ca-969c-1ef5bf37d37c"
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=collate_fn,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.predict(trainer_input)"
      ],
      "id": "017fe106-c414-4f91-9f0a-43c974324129"
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    data_collator=collate_fn,\n",
        "    train_dataset=trainer_input,\n",
        "    args = transformers.TrainingArguments(\n",
        "        output_dir=\"asdf\",\n",
        "        remove_unused_columns=False\n",
        "    )\n",
        ")\n",
        "trainer.train()"
      ],
      "id": "db46e799-021a-4915-ba06-60fbab9808af"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# A1. 공지\n",
        "\n",
        "> **강의시간 이슈**\n",
        ">\n",
        "> 안녕하세요, 제가 촬영하고 강의시간을 살펴보니 원래 강의시간보다 약\n",
        "> 20분정도 초과되었습니다. (3시간 분량인데 3시간20분 소요됨) 죄송합니다.\n",
        "> 이후의 강의에서 이를 반영하여 조금 강의시간을 줄여서\n",
        "> 올리도록하겠습니다.\n",
        "\n",
        "> **깊은복사 얕은복사**\n",
        ">\n",
        "> 아래의 코드\n",
        ">\n",
        "> ``` python\n",
        "> lst = [1,2,3]\n",
        "> lst2 = lst \n",
        "> lst2.append(4)\n",
        "> ```\n",
        ">\n",
        "> 를 실행하였을 경우 `lst`와 `lst2`에 동일한 값이 저장되는 현상에 대한\n",
        "> 설명은\n",
        ">\n",
        "> > <https://guebin.github.io/PP2023/posts/2023-06-21-13wk-1.html>\n",
        ">\n",
        "> 에 있으니 관심있으신 학생들은 참고하시기 바랍니다. (이 수업에서는 저\n",
        "> 내용을 몰라도 학점받는데 영향없습니다)"
      ],
      "id": "e11c08b4-0955-4d55-967f-2b1ea6de1cee"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  }
}