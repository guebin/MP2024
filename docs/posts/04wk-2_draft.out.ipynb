{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04wk-2: 감성분석 파고들기 (2)\n",
        "\n",
        "최규빈  \n",
        "2024-09-27\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/02wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "24535691-7f37-4139-8518-462d56f50c7a"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-xZ2p62reZCCgZsyMQLsOqY&si=bHkFTktvJIGoD0ni >}}"
      ],
      "id": "cell-3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "89ff49c9-7e18-4cad-841b-e70cc411471d"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import torch # 파이토치"
      ],
      "id": "cell-5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets.load_dataset\n",
        "datasets.Dataset.from_dict, \n",
        "datasets.dataset_dict.DatasetDict,\n",
        "transformers.AutoTokenizer.from_pretrained,\n",
        "transformers.AutoModelForSequenceClassification.from_pretrained,\n",
        "transformers.DataCollatorWithPadding,\n",
        "transformers.TrainingArguments,\n",
        "transformers.Trainer,\n",
        "transformers.pipeline,\n",
        "evaluate.load"
      ],
      "id": "cell-6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 이전시간 요약\n",
        "\n",
        "`-` 이전시간의 내용중 이번시간에 기억할것들을 요약\n",
        "\n",
        "`-` `DatasetDict`: 임의의 자료에 대한 `DatasetDict` 오브젝트 만들기"
      ],
      "id": "8ecb42da-c98f-4a60-a58c-4892bc22efff"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dict = {\n",
        "    'text': [\n",
        "        \"I prefer making decisions based on logic and objective facts.\",\n",
        "        \"I always consider how others might feel when making a decision.\",\n",
        "        \"Data and analysis drive most of my decisions.\",\n",
        "        \"I rely on my empathy and personal values to guide my choices.\"\n",
        "    ],\n",
        "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
        "}\n",
        "\n",
        "test_dict = {\n",
        "    'text': [\n",
        "        \"I find it important to weigh all the pros and cons logically.\",\n",
        "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
        "    ],\n",
        "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
        "}\n",
        "train_data = datasets.Dataset.from_dict(train_dict)\n",
        "test_data = datasets.Dataset.from_dict(test_dict)\n",
        "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
      ],
      "id": "cell-10"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `DatasetDict`: 아래의 코드도 가능"
      ],
      "id": "de210538-52a5-460f-abf7-c99aefb3fb0a"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "나의데이터['train']['text']"
      ],
      "id": "cell-12"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `토크나이저`: 토크나이저는 “`Str` $\\to$ `Dict`” 인 함수이다."
      ],
      "id": "4ed4ca6c-966c-4765-9c3d-da18f56a0ae3"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn("
          ]
        }
      ],
      "source": [
        "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") "
      ],
      "id": "cell-14"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "토크나이저(나의데이터['train']['text'][0])"
      ],
      "id": "cell-15"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `토크나이저`: 토크나이저의 “Str $\\to$ Dict” 인 함수는 배치처리가\n",
        "가능하다."
      ],
      "id": "356f9da9-a996-488c-bd64-473866c900e0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "토크나이저(나의데이터['train']['text'])"
      ],
      "id": "cell-17"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` `인공지능`: 인공지능은 많은 파라메터를 포함하고 있는 어떠한\n",
        "물체이다.\n",
        "\n",
        "`-` `인공지능`: 인공지능의 파라메터는 변화할 수 있으며, loss가 더\n",
        "작은쪽으로 파라메터를 변화시키는 과정을 “학습”이라고 부른다.\n",
        "\n",
        "`-` `인공지능`: 인공지능은 “`**Dict` $\\to$\n",
        "`transformers.modeling_outputs.SequenceClassifierOutput`”인 함수이다.\n",
        "그런데 쓰기 까다롭다.\n",
        "\n",
        "-   `1`. `Dict`에는 특정한 key를 포함하고 있어야한다. (`input_ids`,\n",
        "    `attention_mask`)\n",
        "-   `2`. key에 대응하는 숫자는 파이토치 텐서형태이어야 한다. (`3`.\n",
        "    따라서 (m,n)꼴의 차원을 **반드시** 가져야 한다)\n",
        "-   `4`. `Dict`에 `labels`이 (텐서형으로) 포함된 경우 loss가 계산된다.\n",
        "    (그리고 이걸 계산해야지 학습을 할 수 있음)"
      ],
      "id": "996c92e0-899b-4d13-99f1-f81ed6bff6cf"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "인공지능 = model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
        ")"
      ],
      "id": "cell-21"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#` 입력예시1"
      ],
      "id": "4865eb8b-c152-4dbf-b5ad-fb890678e50d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "인공지능(\n",
        "    **{\n",
        "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
        "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]) # 생략가능\n",
        "    }\n",
        ")\n",
        "# 인공지능이 문제를 푸는 상황으로 비유할 수 있음"
      ],
      "id": "cell-23"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "`#` 입력예시2"
      ],
      "id": "ca0155bb-8f3a-4bc4-b96e-6e4cd4b97448"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "인공지능(\n",
        "    **{\n",
        "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
        "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]), # 생략가능\n",
        "        'labels': torch.tensor([1, 0]) # 생략가능\n",
        "    }\n",
        ")\n",
        "# 인공지능이 문제를 풀고 자기 스스로 채점까지 하는 상황으로 비유할 수 있음"
      ],
      "id": "cell-26"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "`-` `인공지능`: 인공지능의 출력결과\n",
        "“`transformers.modeling_outputs.SequenceClassifierOutput`” 에서\n",
        "확률/예측값을 추출하는 방법\n",
        "\n",
        "-   인공지능의 출력결과 $\\to$ 로짓 $\\to$ 확률 $\\to$ 인공지능의예측\n",
        "-   인공지능의 출력결과 $\\to$ 로짓 $\\to$ 인공지능의예측"
      ],
      "id": "db55c5d2-741f-4a14-ac0f-ec23b89f359a"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "계산된숫자들_로짓 = 인공지능(\n",
        "    **{\n",
        "        'input_ids': torch.tensor([[ 101, 1045, 102],[101, 9544, 102]]), \n",
        "        'attention_mask': torch.tensor([[1, 1, 1],[1, 1, 1]]), # 생략가능\n",
        "        'labels': torch.tensor([1, 0]) # 생략가능\n",
        "    }\n",
        ").logits"
      ],
      "id": "cell-29"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "로짓 $\\to$ 확률"
      ],
      "id": "12220f55-9b52-44da-bdff-d7446d1c5514"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "계산된숫자들_로짓"
      ],
      "id": "cell-31"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.exp(계산된숫자들_로짓) / torch.exp(계산된숫자들_로짓).sum(axis=1)"
      ],
      "id": "cell-32"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def 확률계산하기(인공지능출력):\n",
        "    계산된숫자들_로짓 = 인공지능출력.logits\n",
        "    return torch.exp(계산된숫자들_로짓) / torch.exp(계산된숫자들_로짓).sum(axis=1)"
      ],
      "id": "cell-33"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "로짓 $\\to$ 인공지능의예측"
      ],
      "id": "ae5f9bc7-a267-4ec8-a48c-13861c362a7f"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "계산된숫자들_로짓.argmax(axis=1)"
      ],
      "id": "cell-35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 데이터전처리하기2\n",
        "\n",
        "`-` 아래코드를 파고들어보자.\n",
        "\n",
        "``` python\n",
        "def 데이터전처리하기2(examples):\n",
        "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
        "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n",
        "```\n",
        "\n",
        "`-` `examples['text']`의 쓰임으로 유추해본결과 examples에 가정된 입력의\n",
        "형태??"
      ],
      "id": "4939f965-cea6-49e4-8c71-add91cd3fc3e"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data['text']"
      ],
      "id": "cell-39"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[0]['text']"
      ],
      "id": "cell-40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 개념1: Hugging Face의 `datasets` 라이브러리에서 제공하는\n",
        "`datasets.dataset_dict.DatasetDict`은, 요소들의 변환에 특화된\n",
        "`map`이라는 메소드가(=함수가) 내장되어있다.\n",
        "\n",
        "`# 예시1`"
      ],
      "id": "c95be687-9184-4564-ab67-6dc05d9df574"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dict = {\n",
        "    'text': [\n",
        "        \"I prefer making decisions based on logic and objective facts.\",\n",
        "        \"I always consider how others might feel when making a decision.\",\n",
        "        \"Data and analysis drive most of my decisions.\",\n",
        "        \"I rely on my empathy and personal values to guide my choices.\"\n",
        "    ],\n",
        "    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
        "}\n",
        "\n",
        "test_dict = {\n",
        "    'text': [\n",
        "        \"I find it important to weigh all the pros and cons logically.\",\n",
        "        \"When making decisions, I prioritize harmony and people's emotions.\"\n",
        "    ],\n",
        "    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n",
        "}\n",
        "train_data = datasets.Dataset.from_dict(train_dict)\n",
        "test_data = datasets.Dataset.from_dict(test_dict)\n",
        "나의데이터 = datasets.dataset_dict.DatasetDict({'train':train_data, 'test':test_data})"
      ],
      "id": "cell-43"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets.dataset_dict.DatasetDict"
      ],
      "id": "cell-44"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets.dataset_dict.DatasetDict"
      ],
      "id": "cell-45"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#cell-46 .cell execution_count=21}\n",
        "\n",
        "``` python\n",
        "나의데이터.map?\n",
        "```\n",
        "\n",
        "::: {.cell-output .cell-output-display}\n",
        "\n",
        "<pre><span class=\"ansi-red-fg\">Signature:</span>\n",
        "나의데이터<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>\n",
        "    function<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>Callable<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    with_indices<span class=\"ansi-blue-fg\">:</span> bool <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    with_rank<span class=\"ansi-blue-fg\">:</span> bool <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    input_columns<span class=\"ansi-blue-fg\">:</span> Union<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">,</span> List<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> NoneType<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    batched<span class=\"ansi-blue-fg\">:</span> bool <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    batch_size<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>int<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-cyan-fg\">1000</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    drop_last_batch<span class=\"ansi-blue-fg\">:</span> bool <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    remove_columns<span class=\"ansi-blue-fg\">:</span> Union<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">,</span> List<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> NoneType<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    keep_in_memory<span class=\"ansi-blue-fg\">:</span> bool <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    load_from_cache_file<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>bool<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    cache_file_names<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>Dict<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">,</span> Optional<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    writer_batch_size<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>int<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-cyan-fg\">1000</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    features<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>datasets<span class=\"ansi-blue-fg\">.</span>features<span class=\"ansi-blue-fg\">.</span>features<span class=\"ansi-blue-fg\">.</span>Features<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    disable_nullable<span class=\"ansi-blue-fg\">:</span> bool <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    fn_kwargs<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>dict<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    num_proc<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>int<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "    desc<span class=\"ansi-blue-fg\">:</span> Optional<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span>\n",
        "<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-blue-fg\">'DatasetDict'</span>\n",
        "<span class=\"ansi-red-fg\">Docstring:</span>\n",
        "Apply a function to all the elements in the table (individually or in batches)\n",
        "and update the table (if function does updated examples).\n",
        "The transformation is applied to all the datasets of the dataset dictionary.\n",
        "Args:\n",
        "    function (`callable`): with one of the following signature:\n",
        "        - `function(example: Dict[str, Any]) -&gt; Dict[str, Any]` if `batched=False` and `with_indices=False`\n",
        "        - `function(example: Dict[str, Any], indices: int) -&gt; Dict[str, Any]` if `batched=False` and `with_indices=True`\n",
        "        - `function(batch: Dict[str, List]) -&gt; Dict[str, List]` if `batched=True` and `with_indices=False`\n",
        "        - `function(batch: Dict[str, List], indices: List[int]) -&gt; Dict[str, List]` if `batched=True` and `with_indices=True`\n",
        "        For advanced usage, the function can also return a `pyarrow.Table`.\n",
        "        Moreover if your function returns nothing (`None`), then `map` will run your function and return the dataset unchanged.\n",
        "    with_indices (`bool`, defaults to `False`):\n",
        "        Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.\n",
        "    with_rank (`bool`, defaults to `False`):\n",
        "        Provide process rank to `function`. Note that in this case the\n",
        "        signature of `function` should be `def function(example[, idx], rank): ...`.\n",
        "    input_columns (`[Union[str, List[str]]]`, *optional*, defaults to `None`):\n",
        "        The columns to be passed into `function` as\n",
        "        positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.\n",
        "    batched (`bool`, defaults to `False`):\n",
        "        Provide batch of examples to `function`.\n",
        "    batch_size (`int`, *optional*, defaults to `1000`):\n",
        "        Number of examples per batch provided to `function` if `batched=True`,\n",
        "        `batch_size &lt;= 0` or `batch_size == None` then provide the full dataset as a single batch to `function`.\n",
        "    drop_last_batch (`bool`, defaults to `False`):\n",
        "        Whether a last batch smaller than the batch_size should be\n",
        "        dropped instead of being processed by the function.\n",
        "    remove_columns (`[Union[str, List[str]]]`, *optional*, defaults to `None`):\n",
        "        Remove a selection of columns while doing the mapping.\n",
        "        Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding\n",
        "        columns with names in `remove_columns`, these columns will be kept.\n",
        "    keep_in_memory (`bool`, defaults to `False`):\n",
        "        Keep the dataset in memory instead of writing it to a cache file.\n",
        "    load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):\n",
        "        If a cache file storing the current computation from `function`\n",
        "        can be identified, use it instead of recomputing.\n",
        "    cache_file_names (`[Dict[str, str]]`, *optional*, defaults to `None`):\n",
        "        Provide the name of a path for the cache file. It is used to store the\n",
        "        results of the computation instead of the automatically generated cache file name.\n",
        "        You have to provide one `cache_file_name` per dataset in the dataset dictionary.\n",
        "    writer_batch_size (`int`, default `1000`):\n",
        "        Number of rows per write operation for the cache file writer.\n",
        "        This value is a good trade-off between memory usage during the processing, and processing speed.\n",
        "        Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.\n",
        "    features (`[datasets.Features]`, *optional*, defaults to `None`):\n",
        "        Use a specific [`Features`] to store the cache file\n",
        "        instead of the automatically generated one.\n",
        "    disable_nullable (`bool`, defaults to `False`):\n",
        "        Disallow null values in the table.\n",
        "    fn_kwargs (`Dict`, *optional*, defaults to `None`):\n",
        "        Keyword arguments to be passed to `function`\n",
        "    num_proc (`int`, *optional*, defaults to `None`):\n",
        "        Number of processes for multiprocessing. By default it doesn't\n",
        "        use multiprocessing.\n",
        "    desc (`str`, *optional*, defaults to `None`):\n",
        "        Meaningful description to be displayed alongside with the progress bar while mapping examples.\n",
        "Example:\n",
        "```py\n",
        "&gt;&gt;&gt; from datasets import load_dataset\n",
        "&gt;&gt;&gt; ds = load_dataset(\"rotten_tomatoes\")\n",
        "&gt;&gt;&gt; def add_prefix(example):\n",
        "...     example[\"text\"] = \"Review: \" + example[\"text\"]\n",
        "...     return example\n",
        "&gt;&gt;&gt; ds = ds.map(add_prefix)\n",
        "&gt;&gt;&gt; ds[\"train\"][0:3][\"text\"]\n",
        "['Review: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
        " 'Review: the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .',\n",
        " 'Review: effective but too-tepid biopic']\n",
        "# process a batch of examples\n",
        "&gt;&gt;&gt; ds = ds.map(lambda example: tokenizer(example[\"text\"]), batched=True)\n",
        "# set number of processors\n",
        "&gt;&gt;&gt; ds = ds.map(add_prefix, num_proc=4)\n",
        "\n",
        "<span class=\"ansi-red-fg\">File:</span>\n",
        "~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/dataset_dict.py\n",
        "<span class=\"ansi-red-fg\">Type:</span> method\n",
        "\n",
        "</pre>\n",
        "\n",
        "    :::\n",
        "\n",
        "    :::\n",
        "    :::\n",
        "\n",
        "\n",
        "    - 당장필요한내용: `datasets.dataset_dict.DatasetDict.map()`은 (1) `function`을 입력으로 받는데, (2) `function`은 Dict를 입력으로 받고 Dict를 출력하는 함수이어야 한다. \n",
        "\n",
        "    ::: {#cell-48 .cell execution_count=22}\n",
        "    ``` {.python .cell-code}\n",
        "    전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy': '메롱'})\n",
        "\n",
        "    Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2347.12 examples/s]\n",
        "    Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1523.54 examples/s]"
      ],
      "id": "c9a86a91-817c-4cd6-87b0-654b82ff6724"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "나의데이터['train'][0], 전처리된나의데이터['train'][0]"
      ],
      "id": "cell-49"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'I prefer making decisions based on logic and objective facts.', 'label': 0, 'dummy': '메롱'}\n",
            "{'text': 'I always consider how others might feel when making a decision.', 'label': 1, 'dummy': '메롱'}\n",
            "{'text': 'Data and analysis drive most of my decisions.', 'label': 0, 'dummy': '메롱'}\n",
            "{'text': 'I rely on my empathy and personal values to guide my choices.', 'label': 1, 'dummy': '메롱'}"
          ]
        }
      ],
      "source": [
        "for d in 전처리된나의데이터['train']:\n",
        "    print(d)"
      ],
      "id": "cell-50"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'I find it important to weigh all the pros and cons logically.', 'label': 0, 'dummy': '메롱'}\n",
            "{'text': \"When making decisions, I prioritize harmony and people's emotions.\", 'label': 1, 'dummy': '메롱'}"
          ]
        }
      ],
      "source": [
        "for d in 전처리된나의데이터['test']:\n",
        "    print(d)"
      ],
      "id": "cell-51"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "`# 예시2`"
      ],
      "id": "627399a5-0a37-4bbe-917e-5dfae974f7ad"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2474.15 examples/s]\n",
            "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1539.19 examples/s]"
          ]
        }
      ],
      "source": [
        "전처리된나의데이터 = 나의데이터.map(lambda x: {'dummy':'메롱', 'label2': '사고형(T)'} if x['label'] == 0 else {'dummy':'메롱','label2': '감정형(F)'})"
      ],
      "id": "cell-54"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'I prefer making decisions based on logic and objective facts.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
            "{'text': 'I always consider how others might feel when making a decision.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}\n",
            "{'text': 'Data and analysis drive most of my decisions.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
            "{'text': 'I rely on my empathy and personal values to guide my choices.', 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}"
          ]
        }
      ],
      "source": [
        "for d in 전처리된나의데이터['train']:\n",
        "    print(d)"
      ],
      "id": "cell-55"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'I find it important to weigh all the pros and cons logically.', 'label': 0, 'dummy': '메롱', 'label2': '사고형(T)'}\n",
            "{'text': \"When making decisions, I prioritize harmony and people's emotions.\", 'label': 1, 'dummy': '메롱', 'label2': '감정형(F)'}"
          ]
        }
      ],
      "source": [
        "for d in 전처리된나의데이터['test']:\n",
        "    print(d)"
      ],
      "id": "cell-56"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "`# 예시3`"
      ],
      "id": "5e45ca8b-7cdb-4f31-8d69-22deb7e959b7"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def 데이터전처리하기2(examples):\n",
        "    return 데이터전처리하기1(examples[\"text\"], truncation=True)"
      ],
      "id": "cell-59"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1189.87 examples/s]\n",
            "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1161.37 examples/s]"
          ]
        }
      ],
      "source": [
        "전처리된나의데이터 = 나의데이터.map(데이터전처리하기2,batched=True)"
      ],
      "id": "cell-60"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "전처리된나의데이터['train'][0]"
      ],
      "id": "cell-61"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#`\n",
        "\n",
        "# 5. 데이터콜렉터\n",
        "\n",
        "|                |    주어진자료     | $\\overset{tokenizer,map}{\\Longrightarrow}$ 전처리된자료 | $\\overset{datacollector}{\\Longrightarrow}$더전처리된자료 |\n",
        "|:----------------:|:----------------:|:----------------:|:----------------:|\n",
        "|  Dict의 Keys   |  `text`,`label`   |         `input_ids`, `attention_mask`, `label`          |         `input_ids`, `attention_mask`, `labels`          |\n",
        "|   자료의형태   |    텍스트,라벨    |                   숫자화 O, 행렬화 X                    |                    숫자화 O, 행렬화 O                    |\n",
        "| `torch.tensor` |        \\-         |                            X                            |                            O                             |\n",
        "|    미니배치    |        \\-         |                            X                            |                            O                             |\n",
        "| 패딩/동적패딩  |        \\-         |                            X                            |                            O                             |\n",
        "|    예측할때    | 강인공지능의 입력 |                     트레이너의 입력                     |                     인공지능의 입력                      |\n",
        "\n",
        "`-` 데이터콜렉터 사용방법"
      ],
      "id": "ce12ef08-8bbe-4611-8ec3-6aa568c5fd3d"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저,return_tensors='pt')\n",
        "데이터콜렉터?"
      ],
      "id": "cell-66"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   당장필요한것: 입력은 `[딕셔너리, 딕셔너리, 딕셔너리, ...]` 의 형태"
      ],
      "id": "6ad63e56-6be9-43ab-a978-92eb0e35faa3"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "데이터콜렉터(\n",
        "    [\n",
        "        dict(label=0,input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
        "        dict(label=0,input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
        "    ]\n",
        ")"
      ],
      "id": "cell-68"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "인공지능(**데이터콜렉터(\n",
        "    [\n",
        "        dict(label=0,input_ids=[101,1045,102],attention_mask=[1,1,1]),\n",
        "        dict(label=0,input_ids=[101,1045,9544,102],attention_mask=[1,1,1,1]),\n",
        "    ]\n",
        "))"
      ],
      "id": "cell-69"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. 평가하기\n",
        "\n",
        "`-` `accuracy.compute`의 기능"
      ],
      "id": "3703fe07-5ea6-4638-81be-9afb2f81e0bc"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "id": "cell-72"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy.compute(references=[0, 0, 0], predictions=[0, 1, 1])"
      ],
      "id": "cell-73"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 함수내용"
      ],
      "id": "31a6fc6f-f7d1-4b42-b6a9-b43dddd98ade"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def 평가하기(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     accuracy = evaluate.load(\"accuracy\")\n",
        "#     return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "id": "cell-75"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def 평가하기(eval_pred):\n",
        "    계산된숫자들_로짓, 실제정답 = eval_pred\n",
        "    인공지능의예측 = np.argmax(계산된숫자들_로짓, axis=1)\n",
        "    accuracy = evaluate.load(\"accuracy\")\n",
        "    return accuracy.compute(predictions=인공지능의예측, references=실제정답)"
      ],
      "id": "cell-76"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. 트레이너\n",
        "\n",
        "## A. 트레이너의 제1역할 – CPU에서 GPU로..\n",
        "\n",
        "`-` Step1~4 를 위한 준비"
      ],
      "id": "6c685410-336c-49cc-99d4-4d7374fc1018"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn("
          ]
        }
      ],
      "source": [
        "## Step1 \n",
        "데이터불러오기 = datasets.load_dataset\n",
        "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \n",
        "def 데이터전처리하기2(examples):\n",
        "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
        "## Step2 \n",
        "인공지능생성하기 = transformers.AutoModelForSequenceClassification.from_pretrained\n",
        "## Step3 \n",
        "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저)\n",
        "def 평가하기(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy = evaluate.load(\"accuracy\")\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "트레이너세부지침생성기 = transformers.TrainingArguments\n",
        "트레이너생성기 = transformers.Trainer\n",
        "## Step4 \n",
        "강인공지능생성하기 = transformers.pipeline"
      ],
      "id": "cell-80"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` Step1~2 까지의 코드 실행"
      ],
      "id": "c4803e2a-fa9b-4574-bfbc-8d052e7962cf"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'plain_text' at /home/cgb3/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Thu Sep 26 23:35:50 2024).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "데이터 = 데이터불러오기('imdb')\n",
        "전처리된데이터 = 데이터.map(데이터전처리하기2,batched=True)\n",
        "전처리된훈련자료, 전처리된검증자료 = 전처리된데이터['train'], 전처리된데이터['test']\n",
        "## Step2 \n",
        "torch.manual_seed(43052)\n",
        "인공지능 = 인공지능생성하기(\"distilbert/distilbert-base-uncased\", num_labels=2)"
      ],
      "id": "cell-82"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 인공지능의 파라메터 상태확인 1"
      ],
      "id": "73b35a9e-50e4-4d2c-a73d-6700fd22b2f9"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "인공지능.classifier.weight"
      ],
      "id": "cell-84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   중요한내용1: 숫자들\n",
        "-   중요한내용2: 나 CPU에 있어요..\n",
        "\n",
        "`-` 인공지능을 이용한 예측 1"
      ],
      "id": "a2e9216f-1726-4bb7-aaf9-9ef6e0457d2c"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")])))"
      ],
      "id": "cell-87"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 트레이너 생성: 생성되자마자 하는일 = 모델을 CPU에서 GPU로 옮긴다."
      ],
      "id": "1f261d13-91e6-45b5-9382-5ae46c84c0e2"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step3 \n",
        "트레이너세부지침 = 트레이너세부지침생성기(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2, # 전체문제세트를 2번 공부하라..\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "트레이너 = 트레이너생성기(\n",
        "    model=인공지능,\n",
        "    args=트레이너세부지침,\n",
        "    train_dataset=전처리된훈련자료,\n",
        "    eval_dataset=전처리된검증자료,\n",
        "    tokenizer=토크나이저,\n",
        "    data_collator=데이터콜렉터,\n",
        "    compute_metrics=평가하기,\n",
        ")\n",
        "# 트레이너.train()\n",
        "# ## Step4 \n",
        "# 강인공지능 = 강인공지능생성하기(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n",
        "# print(강인공지능(\"This movie was a huge disappointment.\"))\n",
        "# print(강인공지능(\"This was a masterpiece.\"))"
      ],
      "id": "cell-89"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 인공지능의 파라메터 상태확인 2"
      ],
      "id": "bdd58ec6-88e5-4fec-9cb3-ed3a7915d827"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "인공지능.classifier.weight"
      ],
      "id": "cell-91"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   중요한내용1: 숫자들 (똑같나?)\n",
        "-   중요한내용2: `device='cuda:0'`, (나 GPU에 있어요)\n",
        "\n",
        "`-` 인공지능을 이용한 예측 2"
      ],
      "id": "b1674a88-eed7-49fe-ad73-eaf10c7f1164"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]))) # 에러발생"
      ],
      "id": "cell-94"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   인공지능은 GPU에 있는데, 데이터는 CPU에 있음.. $\\to$ 에러발생"
      ],
      "id": "396a7f59-0c17-4027-bfd1-94c3ec5dd103"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
      ],
      "id": "cell-96"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 트레이너의 제1역할: 트레이너는 생성과 동시에 하는역할이 있는데, 바로\n",
        "인공지능을 GPU에 올리는 것이다.\n",
        "\n",
        "## B. 트레이너의 제2역할 – 예측하기\n",
        "\n",
        "`-` 트레이너의 제2역할: `트레이너.predict()` 사용가능\n",
        "\n",
        "-   `트레이너.predict()`의 입력형태는 input_ids, attention_mask, label\n",
        "    이 존재하는 `Dataset`"
      ],
      "id": "3c8b6592-25da-4d28-adae-efd86218d5b8"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_dict = {\n",
        "    'text': [\"This movie was a huge disappointment.\"],\n",
        "    'label': [0],\n",
        "    'input_ids': [[101, 2023, 3185, 2001, 1037, 4121, 10520, 1012, 102]],\n",
        "    'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
        "}\n",
        "sample_dataset = datasets.Dataset.from_dict(sample_dict)\n",
        "sample_dataset"
      ],
      "id": "cell-100"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "트레이너.predict(sample_dataset)"
      ],
      "id": "cell-101"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits = np.array([[-0.11731032,  0.02610314]])\n",
        "np.exp(logits)/np.exp(logits).sum(axis=1)"
      ],
      "id": "cell-102"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "아래의 결과와 동일"
      ],
      "id": "aaf97e04-9aad-4add-a396-80f0d9989249"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
      ],
      "id": "cell-104"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 이렇게 쓰면 좋음."
      ],
      "id": "04e6d715-2dd5-44f5-b3da-b17cffca76f6"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "트레이너.predict(전처리된데이터['train'])"
      ],
      "id": "cell-106"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `train`에서 문제 품"
      ],
      "id": "3474ba8b-3634-4ac7-85d2-2d93edb7401a"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "트레이너.predict(전처리된데이터['test'])"
      ],
      "id": "cell-108"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `test`에서 문제 품\n",
        "\n",
        "## C. 트레이너의 제3역할 – 학습 및 결과저장"
      ],
      "id": "b081c51b-00e9-4cdf-9bb2-9b57084ca95c"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "트레이너.train()"
      ],
      "id": "cell-111"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "25000 / 16 "
      ],
      "id": "cell-112"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "1563 * 2 "
      ],
      "id": "cell-113"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 인공지능이 똑똑해졌을까?\n",
        "\n",
        "`-` 인공지능의 파라메터 상태확인 3"
      ],
      "id": "87754558-6db9-4a78-b099-e9c40c6b419f"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "인공지능.classifier.weight # 진짜 살짝 바뀐것 같은데?"
      ],
      "id": "cell-116"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   중요한내용1: 숫자들\n",
        "-   중요한내용2: `device='cuda:0'`, (나 GPU에 있어요)\n",
        "\n",
        "`-` 인공지능의 파라메터 상태확인 2와 비교삿\n",
        "\n",
        "``` python\n",
        "인공지능.classifier.weight\n",
        "```\n",
        "\n",
        "    Parameter containing:\n",
        "    tensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n",
        "            [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n",
        "           device='cuda:0', requires_grad=True)\n",
        "\n",
        "`-` 숫자들이 바뀐걸 확인 $\\to$ 뭔가 다른 계산결과를 준다는 의미겠지?\n",
        "$\\to$ 진짜 그런지 보자.."
      ],
      "id": "ead537d5-83d9-4965-8df5-3d7bb5ea47d3"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This movie was a huge disappointment.\")]).to(\"cuda:0\")))"
      ],
      "id": "cell-121"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "확률계산하기(인공지능(**데이터콜렉터([토크나이저(\"This was a masterpiece.\")]).to(\"cuda:0\")))"
      ],
      "id": "cell-122"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O\n",
        "\n",
        "# 8. 파이프라인\n",
        "\n",
        "`-` 강인공지능?\n",
        "\n",
        "> ref: <https://zdnet.co.kr/view/?no=20160622145838>"
      ],
      "id": "5447f049-9fc4-4fad-ac1f-f264d6c1158e"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.9885253310203552}]\n",
            "[{'label': 'LABEL_1', 'score': 0.978060781955719}]"
          ]
        }
      ],
      "source": [
        "강인공지능 = transformers.pipeline(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n",
        "print(강인공지능(\"This movie was a huge disappointment.\"))\n",
        "print(강인공지능(\"This was a masterpiece.\"))"
      ],
      "id": "cell-127"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  }
}