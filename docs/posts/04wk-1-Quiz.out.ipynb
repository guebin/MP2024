{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04wk-1: Quiz\n",
        "\n",
        "최규빈  \n",
        "2024-09-24\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/04wk-1-Quiz.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "| **항목**           | **허용 여부** | **비고**                                                 |\n",
        "|------------------|-----------------|-------------------------------------|\n",
        "| **강의노트 참고**  | 허용          | 수업 중 제공된 강의노트나 본인이 정리한 자료를 참고 가능 |\n",
        "| **구글 검색**      | 허용          | 인터넷을 통한 자료 검색 및 정보 확인 가능                |\n",
        "| **생성 모형 사용** | 허용 안함     | 인공지능 기반 도구(GPT 등) 사용 불가                     |\n",
        "\n",
        "<https://youtu.be/playlist?list=PLQqh36zP38-zC5AHlxLrDjjYJRbFt7SoJ&si=vVf4ikZJSLGVsNvB>"
      ],
      "id": "c68fe0c6-3ad5-4a62-b192-993acdb4b9a3"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install datasets evaluate accelerate"
      ],
      "id": "afc188c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `1`. `emotion` 자료 탐색 – 10점\n",
        "\n",
        "> (1)-(2) 모두 부분점수 없음.\n",
        "\n",
        "아래는 Hugging Face의 `emotion` 데이터셋을 로드하는 코드이다:"
      ],
      "id": "6e5ed60c-bf51-41d8-b516-4ee848286bfb"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "emotion = load_dataset('emotion')"
      ],
      "id": "1b9d2926-1bab-4922-8cce-dbac3f8ddcc0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`emotion['train'][-2]`는 훈련 데이터의 두 번째 마지막 항목을 출력한다.\n",
        "출력된 샘플은 다음과 같다."
      ],
      "id": "eeecf4a3-b231-46e4-a48a-d35b7264cb68"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion['train'][-2]"
      ],
      "id": "cebb76be-9552-4d9f-bc2d-896fa052a877"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "출력된 샘플은 딕셔너리 형식으로, text에는 문장 “i feel like this was\n",
        "such a rude comment and im glad that t”이 담겨 있다. 이 문장의 감정은\n",
        "label 항목에 저장되어 있으며, 값은 3으로 나타난다. label 값은 해당\n",
        "텍스트가 표현하는 감정을 숫자로 표현한 것이다.\n",
        "\n",
        "감정 레이블은 총 6가지로 나뉘며, 각각의 감정은 다음과 같이 정의된다:"
      ],
      "id": "8387524a-8ab6-43f8-afe9-a754f1dedf63"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion['train'].features['label'].names"
      ],
      "id": "e39e7b5d-8bde-4bc3-b536-cfd606cb278e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "  0: 'sadness',\n",
        "  1: 'joy',\n",
        "  2: 'love',\n",
        "  3: 'anger',\n",
        "  4: 'fear',\n",
        "  5: 'surprise'\n",
        "}"
      ],
      "id": "ee94057f-7696-4525-8933-9dde24abea19"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "따라서, 문장 “i feel like this was such a rude comment and im glad that\n",
        "t” 의 감정은 `label`이 3이므로, “anger”에 해당한다.\n",
        "\n",
        "`(1)` `emotion` 데이터셋의 각 분할(train, validation, test)에서 감정별로\n",
        "몇 개의 데이터가 있는지를 조사하라. 즉 아래의 표에서 빈칸에 해당하는\n",
        "숫자를 계산할 수 있는 코드를 제시하라. – 5점\n",
        "\n",
        "| Dataset    | 0:Sadness | 1:Joy | 2:Love | 3:Anger | 4:Fear | 5:Surprise | Total |\n",
        "|------------|-----------|-------|--------|---------|--------|------------|-------|\n",
        "| Train      | ??        | ??    | ??     | ??      | ??     | ??         | 16000 |\n",
        "| Validation | ??        | ??    | ??     | ??      | ??     | ??         | 2000  |\n",
        "| Test       | ??        | ??    | ??     | ??      | ??     | ??         | 2000  |\n",
        "\n",
        "**note:** 정답예시: 아래와 같은 형식으로 출력하는 코드를 작성하면\n",
        "정답으로 인정\n",
        "\n",
        "    train\n",
        "    {0: 4666, 1: 5362, 2: 1304, 3: 2159, 4: 1937, 5: 572}\n",
        "    --\n",
        "    validation\n",
        "    {0: 550, 1: 704, 2: 178, 3: 275, 4: 212, 5: 81}\n",
        "    --\n",
        "    test\n",
        "    {0: 581, 1: 695, 2: 159, 3: 275, 4: 224, 5: 66}\n",
        "    --\n",
        "\n",
        "**hint**: 아래중 원하는 형태를 이용하여 풀이하면 편리하다.\n",
        "\n",
        "-   `emotion['train']['label']`\n",
        "-   `emotion['train'].to_dict()`\n",
        "-   `emotion['train'].to_pandas()`\n",
        "\n",
        "(풀이)"
      ],
      "id": "03857df9-f29d-4a2b-beff-71c6e38676b8"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "{key: {i:emotion[key]['label'].count(i) for i in set(emotion[key]['label'])} for key in emotion}"
      ],
      "id": "45a0dd75-1741-43ea-9766-6e0884cb048f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2)` `emotion` 데이터셋의 `test`셋에서 각 감정(label)별로 가장 짧은\n",
        "길이를 가진 텍스트를 출력하는 코드를 작성하라. – 5점\n",
        "\n",
        "**note**: 정답예시는 아래와 같다.\n",
        "\n",
        "    ['i feels so lame',\n",
        "     'i feel any better',\n",
        "     'i just feel tender',\n",
        "     'i feel so damn agitated',\n",
        "     'i feel alarmed',\n",
        "     'i feel all funny sometimes']\n",
        "\n",
        "(풀이1)"
      ],
      "id": "f26ec030-409e-4810-8f00-07e744d263c0"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "_라벨0만 = [dct['text'] for dct in emotion['test'] if dct['label']==0]\n",
        "min(map(len,_라벨0만))\n",
        "[txt for txt in _라벨0만 if len(txt)==min(map(len,_라벨0만))]"
      ],
      "id": "8f511432-af55-4afe-8443-5c7406389321"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def func(_라벨0만):\n",
        "    min(map(len,_라벨0만))\n",
        "    return [txt for txt in _라벨0만 if len(txt)==min(map(len,_라벨0만))]"
      ],
      "id": "05aaea9b-0ec0-47fd-a5e6-4ffee4f65ce0"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(map(func,[[dct['text'] for dct in emotion['test'] if dct['label']==lbl] for lbl in range(6)]))"
      ],
      "id": "e267862f-78f8-4f0d-b320-244bf2e25ca3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(풀이2)"
      ],
      "id": "a27cb9e2-3c28-4ea7-8a88-6a00a18adcc9"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = emotion['test'].to_pandas()\n",
        "df['length'] = list(map(len,df['text']))\n",
        "df = df.sort_values('length')\n",
        "df "
      ],
      "id": "26450a52-9102-4811-be58-792dc1acf00a"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _,subdf in df.groupby('label'):\n",
        "    display(subdf.text.iloc[0])"
      ],
      "id": "4eaa6ae7-f345-406c-b472-daed49369756"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `2`. `emotion` 자료 감성분석 – 80점\n",
        "\n",
        "> (1)은 부분점수 있음, (2)는 부분점수 없음.\n",
        "\n",
        "`(1)` 아래의 reference 를 참고하여 `emotion`에 대한 감성분석모델을\n",
        "학습하는 코드를 작성하라. – 60점\n",
        "\n",
        "ref:\n",
        "\n",
        "-   <https://guebin.github.io/MP2024/posts/02wk-1.html>\n",
        "-   <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n",
        "\n",
        "**세부지침** – 세부지침을 따르지 않을시 감점이 있음 (지침1은 30점감점\n",
        "지침2는 5점감점)\n",
        "\n",
        "`지침1`. `Trainer`생성시 `eval_dataset`에는 `emotion['validation']`를\n",
        "전처리한 데이터를 이용하라. (`emotion['test']` 가 아니라)\n",
        "\n",
        "`지침2`. `TrainingArguments`에서 `num_train_epochs`은 1로 설정하라.\n",
        "\n",
        "**hint**: `imdb` 자료의 경우 `num_labels = 2` 이지만, `emotion` 자료의\n",
        "경우 그렇지 않음을 유의하라.\n",
        "\n",
        "(풀이)"
      ],
      "id": "4ff73cc4-f718-4d7d-9b02-30d5c65b3732"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import evaluate\n",
        "import numpy as np"
      ],
      "id": "0ea09636-0329-4af1-befb-5c8d4dc5de38"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn("
          ]
        }
      ],
      "source": [
        "## Step1 \n",
        "데이터불러오기 = datasets.load_dataset\n",
        "데이터전처리하기1 = 토크나이저 = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \n",
        "def 데이터전처리하기2(examples):\n",
        "    return 데이터전처리하기1(examples[\"text\"], truncation=True)\n",
        "## Step2 \n",
        "인공지능생성하기 = transformers.AutoModelForSequenceClassification.from_pretrained\n",
        "## Step3 \n",
        "데이터콜렉터 = transformers.DataCollatorWithPadding(tokenizer=토크나이저)\n",
        "def 평가하기(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy = evaluate.load(\"accuracy\")\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "트레이너세부지침생성기 = transformers.TrainingArguments\n",
        "트레이너생성기 = transformers.Trainer\n",
        "## Step4 \n",
        "강인공지능생성하기 = transformers.pipeline"
      ],
      "id": "fec9754d-0cd1-4a71-9925-f63179725bd8"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
          ]
        }
      ],
      "source": [
        "## Step1 \n",
        "데이터 = 데이터불러오기('emotion')\n",
        "전처리된데이터 = 데이터.map(데이터전처리하기2,batched=True)\n",
        "전처리된훈련자료, 전처리된검증자료 = 전처리된데이터['train'], 전처리된데이터['validation']\n",
        "## Step2 \n",
        "인공지능 = 인공지능생성하기(\"distilbert/distilbert-base-uncased\", num_labels=6)\n",
        "## Step3 \n",
        "트레이너세부지침 = 트레이너세부지침생성기(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1, # 전체문제세트를 2번 공부하라..\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "트레이너 = 트레이너생성기(\n",
        "    model=인공지능,\n",
        "    args=트레이너세부지침,\n",
        "    train_dataset=전처리된훈련자료,\n",
        "    eval_dataset=전처리된검증자료,\n",
        "    tokenizer=토크나이저,\n",
        "    data_collator=데이터콜렉터,\n",
        "    compute_metrics=평가하기,\n",
        ")\n",
        "트레이너.train()"
      ],
      "id": "ba58f54c-8117-421a-bef0-a37b1bcafd63"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2)` `1-(2)`에서 구해진 text에 대하여 감성분석을 수행하라. – 20점\n",
        "\n",
        "**힌트** `1-(2)`를 풀지못하였다면 아래의 코드를 이용하여 강제설정할 것\n",
        "\n",
        "``` python\n",
        "['i feels so lame',\n",
        " 'i feel any better',\n",
        " 'i just feel tender',\n",
        " 'i feel so damn agitated',\n",
        " 'i feel alarmed',\n",
        " 'i feel all funny sometimes']\n",
        "```"
      ],
      "id": "981dc614-3078-4d00-9f16-08bff4e69dff"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU."
          ]
        }
      ],
      "source": [
        "## Step4 \n",
        "강인공지능 = 강인공지능생성하기(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1000\")\n",
        "강인공지능([\n",
        "    'i feels so lame',\n",
        "    'i feel any better',\n",
        "    'i just feel tender',\n",
        "    'i feel so damn agitated',\n",
        "    'i feel alarmed',\n",
        "    'i feel all funny sometimes'\n",
        "])"
      ],
      "id": "986e9146-0dcf-4bf7-972f-23929eb6fb1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `3`. O/X. – 10점\n",
        "\n",
        "> 모두 맞출경우만 정답으로 인정\n",
        "\n",
        "아래의 제시문을 읽고 올바르게 해석한 사람을 모두 고르라.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> 나는 50,000개의 “텍스트-라벨” 데이터를 인공지능에게 학습시켰다. 학습이\n",
        "> 끝난 후, 50,000개의 데이터 중 20개의 샘플을 무작위로 뽑아 테스트한\n",
        "> 결과, 인공지능은 20개의 텍스트에 대한 라벨을 모두 정확히 맞췄다. 이\n",
        "> 결과만으로 인공지능이 영화 리뷰에 대한 감성 분석(긍정/부정)을\n",
        "> 성공적으로 학습했다고 결론을 내려도 될까?\n",
        "\n",
        "`민지`: 제시문에 따르면 50,000개의 훈련 데이터를 사용하여 인공지능을\n",
        "학습시켰으니, `train_data`의 크기는 50,000이라고 볼 수 있어.\n",
        "\n",
        "`하니`: 50,000개의 데이터 중 일부를 무작위로 샘플링하여 평가하는 것은\n",
        "올바른 방법이 아니야. 학습에 사용되지 않은 별도의 테스트 데이터를 사용해\n",
        "성능을 평가해야 인공지능이 제대로 학습했는지 알 수 있어.\n",
        "\n",
        "`다니엘`: 하니의 말이 맞아. 50,000개의 데이터 중 20개를 샘플링한 게\n",
        "아니라, 50,000개의 데이터를 모두 올바르게 맞췄다고 하더라도, 새로운\n",
        "데이터에 대해 성능이 좋다고 단정할 수는 없어. 중요한 건 새로운 데이터에\n",
        "대한 예측 성능이지.\n",
        "\n",
        "`해린`: 맞아, 훈련 데이터 (=학습 데이터) 를 너무 반복해서 학습하다 보면,\n",
        "인공지능이 그 데이터에만 지나치게 맞춰져서 새로운 데이터를 잘 처리하지\n",
        "못할 수 있어. 결국 모델이 학습 데이터에서는 좋은 성능을 내지만, 학습하지\n",
        "않은 데이터나 실제 환경에서는 성능이 떨어질 위험이 생기는 거야.”\n",
        "\n",
        "`혜인`: 그렇구나! 그래서 50,000개의 데이터가 있더라도, 그 중 일부만\n",
        "학습에 사용하고, 나머지는 평가용으로 따로 남겨두기도 하는 거네. 이렇게\n",
        "하면 인공지능이 새로운 데이터에서도 잘 작동하는지, 성능을 확인할 수 있는\n",
        "거잖아?\n",
        "\n",
        "> 모두 정답"
      ],
      "id": "45b2558c-6765-45f7-a029-4fbb3c5e7c1a"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  }
}