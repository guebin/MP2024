<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.533">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="ìµœê·œë¹ˆ">
<meta name="dcterms.date" content="2024-11-09">

<title>MP2024 - 09wk-2: modelì˜ ì…ë ¥íŒŒì•…, modelì˜ ì‚¬ìš©ì—°ìŠµ</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">MP2024</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../quiz.html"> 
<span class="menu-text"><strong>Quiz</strong></span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/guebin/MP2024"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/channel/UCQk9RyBNgXc7ORIsYlOfQrg/playlists?view=50&amp;sort=dd&amp;shelf_id=2"> <i class="bi bi-youtube" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ê°•ì˜ì˜ìƒ" id="toc-ê°•ì˜ì˜ìƒ" class="nav-link active" data-scroll-target="#ê°•ì˜ì˜ìƒ">1. ê°•ì˜ì˜ìƒ</a></li>
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports">2. Imports</a></li>
  <li><a href="#model-ì…ë ¥íŒŒì•…" id="toc-model-ì…ë ¥íŒŒì•…" class="nav-link" data-scroll-target="#model-ì…ë ¥íŒŒì•…">3. Model ì…ë ¥íŒŒì•…</a></li>
  <li><a href="#model-ì‚¬ìš©-ì—°ìŠµ" id="toc-model-ì‚¬ìš©-ì—°ìŠµ" class="nav-link" data-scroll-target="#model-ì‚¬ìš©-ì—°ìŠµ">4. Model ì‚¬ìš© ì—°ìŠµ</a>
  <ul class="collapse">
  <li><a href="#a.-í…ìŠ¤íŠ¸" id="toc-a.-í…ìŠ¤íŠ¸" class="nav-link" data-scroll-target="#a.-í…ìŠ¤íŠ¸">A. í…ìŠ¤íŠ¸</a></li>
  <li><a href="#b.-ì´ë¯¸ì§€" id="toc-b.-ì´ë¯¸ì§€" class="nav-link" data-scroll-target="#b.-ì´ë¯¸ì§€">B. ì´ë¯¸ì§€</a></li>
  <li><a href="#c.-ë™ì˜ìƒ" id="toc-c.-ë™ì˜ìƒ" class="nav-link" data-scroll-target="#c.-ë™ì˜ìƒ">C. ë™ì˜ìƒ</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="09wk-2.out.ipynb" download="09wk-2.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">09wk-2: <code>model</code>ì˜ ì…ë ¥íŒŒì•…, <code>model</code>ì˜ ì‚¬ìš©ì—°ìŠµ</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>ìµœê·œë¹ˆ </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 9, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><a href="https://colab.research.google.com/github/guebin/MP2024/blob/main/posts/09wk-2.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" style="text-align: left"></a></p>
<section id="ê°•ì˜ì˜ìƒ" class="level1">
<h1>1. ê°•ì˜ì˜ìƒ</h1>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/playlist?list=PLQqh36zP38-xsRgsXpLEUNWClxLi0N9Mk&amp;si=Lssxzw70RRT1adiJ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="imports" class="level1">
<h1>2. Imports</h1>
<div id="cell-5" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> huggingface_hub</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytorchvideo.data</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tarfile</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mp2024pkg <span class="im">as</span> mp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
</div>
</section>
<section id="model-ì…ë ¥íŒŒì•…" class="level1">
<h1>3. Model ì…ë ¥íŒŒì•…</h1>
<p><code>-</code> ì•„ë˜ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìˆœìœ¼ë¡œ..</p>
<ul>
<li>ë°©ë²•1: <code>model.forward?</code> ì—ì„œ ì‹œê·¸ë‹ˆì²˜ë¥¼ í™•ì¸</li>
<li>ë°©ë²•2: <code>model.forward?</code> ì—ì„œ ì‚¬ìš©ì˜ˆì œë¥¼ í™•ì¸</li>
<li>ë°©ë²•3: ì¸í„°ë„·ì„ í™œìš©í•œ ì™¸ë¶€ ìë£Œ í™•ì¸ (ê³µì‹ë¬¸ì„œ, ê³µì‹íŠœí† ë¦¬ì–¼, ì‹ ë¢°í• ë§Œí•œ ë¸”ë¡œê·¸, ChatGPTë“±)</li>
<li>ë°©ë²•4: <code>model.forward??</code> ë¥¼ ë³´ê³  ëª¨ë“  ì½”ë“œë¥¼ ëœ¯ì–´ë´„ &lt;â€” í•˜ì§€ë§ˆì„¸ìš”</li>
</ul>
<p><code>-</code> ëª¨ë¸ì˜ ì…ë ¥ì´ ì–´ë–¤í˜•íƒœë¡œ ì •ë¦¬ë˜ì–´ì•¼ í•˜ëŠ”ì§€ ì•Œì•„ë‚´ëŠ” í™•ì‹¤í•œ ë°©ë²•ì€ ì—†ìŒ</p>
<ul>
<li>ë°©ë²•1,2,3 ì€ ë‹¤ë¥¸ì‚¬ëŒì˜ í˜¸ì˜ì— ê¸°ëŒ€í•´ì•¼í•¨.</li>
<li>ë°©ë²•4ëŠ” ì‚¬ì‹¤ìƒ ë¶ˆê°€ëŠ¥</li>
</ul>
<p><code># ì˜ˆì œ1</code> â€“ í…ìŠ¤íŠ¸ë¶„ë¥˜</p>
<div id="cell-10" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> transformers.AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distilbert/distilbert-base-uncased"</span>, num_labels<span class="op">=</span><span class="dv">2</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p><em>ëª¨ë¸ì˜ ê¸°ë³¸ì •ë³´(config)</em></p>
<div id="cell-12" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model1.config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>DistilBertConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "distilbert/distilbert-base-uncased",
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "transformers_version": "4.46.2",
  "vocab_size": 30522
}</code></pre>
</div>
</div>
<ul>
<li>max_position_embeddings: 512</li>
</ul>
<p><em>ëª¨ë¸ì˜ ì…ë ¥íŒŒì•…</em></p>
<div id="cell-15" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>model1.forward? </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature:
model1.forward(
    input_ids: Optional[torch.Tensor] = None,
    attention_mask: Optional[torch.Tensor] = None,
    head_mask: Optional[torch.Tensor] = None,
    inputs_embeds: Optional[torch.Tensor] = None,
    labels: Optional[torch.LongTensor] = None,
    output_attentions: Optional[bool] = None,
    output_hidden_states: Optional[bool] = None,
    return_dict: Optional[bool] = None,
) -&gt; Union[transformers.modeling_outputs.SequenceClassifierOutput, Tuple[torch.Tensor, ...]]
Docstring:
The [`DistilBertForSequenceClassification`] forward method, overrides the `__call__` special method.

&lt;Tip&gt;

Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.

&lt;/Tip&gt;

Args:
    input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):
        Indices of input sequence tokens in the vocabulary.

        Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
        [`PreTrainedTokenizer.__call__`] for details.

        [What are input IDs?](../glossary#input-ids)
    attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):
        Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:

        - 1 for tokens that are **not masked**,
        - 0 for tokens that are **masked**.

        [What are attention masks?](../glossary#attention-mask)
    head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):
        Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:

        - 1 indicates the head is **not masked**,
        - 0 indicates the head is **masked**.

    inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):
        Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
        is useful if you want more control over how to convert `input_ids` indices into associated vectors than the
        model's internal embedding lookup matrix.
    output_attentions (`bool`, *optional*):
        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
        tensors for more detail.
    output_hidden_states (`bool`, *optional*):
        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
        more detail.
    return_dict (`bool`, *optional*):
        Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.

    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,
        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
        `config.num_labels &gt; 1` a classification loss is computed (Cross-Entropy).
    
Returns:
    [`transformers.modeling_outputs.SequenceClassifierOutput`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.SequenceClassifierOutput`] or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various
    elements depending on the configuration ([`DistilBertConfig`]) and inputs.

    - **loss** (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) -- Classification (or regression if config.num_labels==1) loss.
    - **logits** (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) -- Classification (or regression if config.num_labels==1) scores (before SoftMax).
    - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +
      one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.

      Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.
    - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
      sequence_length)`.

      Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
      heads.

Example of single-label classification:

```python
&gt;&gt;&gt; import torch
&gt;&gt;&gt; from transformers import AutoTokenizer, DistilBertForSequenceClassification

&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
&gt;&gt;&gt; model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")

&gt;&gt;&gt; inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")

&gt;&gt;&gt; with torch.no_grad():
...     logits = model(**inputs).logits

&gt;&gt;&gt; predicted_class_id = logits.argmax().item()

&gt;&gt;&gt; # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
&gt;&gt;&gt; num_labels = len(model.config.id2label)
&gt;&gt;&gt; model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=num_labels)

&gt;&gt;&gt; labels = torch.tensor([1])
&gt;&gt;&gt; loss = model(**inputs, labels=labels).loss
```

Example of multi-label classification:

```python
&gt;&gt;&gt; import torch
&gt;&gt;&gt; from transformers import AutoTokenizer, DistilBertForSequenceClassification

&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
&gt;&gt;&gt; model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", problem_type="multi_label_classification")

&gt;&gt;&gt; inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")

&gt;&gt;&gt; with torch.no_grad():
...     logits = model(**inputs).logits

&gt;&gt;&gt; predicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) &gt; 0.5]

&gt;&gt;&gt; # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
&gt;&gt;&gt; num_labels = len(model.config.id2label)
&gt;&gt;&gt; model = DistilBertForSequenceClassification.from_pretrained(
...     "distilbert-base-uncased", num_labels=num_labels, problem_type="multi_label_classification"
... )

&gt;&gt;&gt; labels = torch.sum(
...     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1
... ).to(torch.float)
&gt;&gt;&gt; loss = model(**inputs, labels=labels).loss
```
File:      ~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py
Type:      method</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ1 â€“ ì…ë ¥ë‚˜ì—´, loss O</em></p>
<div id="cell-17" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model1(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]]),</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>SequenceClassifierOutput(loss=tensor(0.6543, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0386, -0.1142],
        [-0.0372, -0.1201]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ2 â€“ <code>**ë”•ì…”ë„ˆë¦¬</code>, loss O</em></p>
<div id="cell-19" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model1_input <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]]),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model1(<span class="op">**</span>model1_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>SequenceClassifierOutput(loss=tensor(0.6543, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0386, -0.1142],
        [-0.0372, -0.1201]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ3 â€“ ì…ë ¥ë‚˜ì—´, loss X</em></p>
<div id="cell-21" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model1(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[-0.0386, -0.1142],
        [-0.0372, -0.1201]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ4 â€“ <code>**ë”•ì…”ë„ˆë¦¬</code>, loss X</em></p>
<div id="cell-23" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model1_input <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]])</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>model1(<span class="op">**</span>model1_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[-0.0386, -0.1142],
        [-0.0372, -0.1201]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ5 â€“ ì´ˆê°„ë‹¨, loss X</em></p>
<div id="cell-25" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model1(torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[-0.0386, -0.1142],
        [-0.0372, -0.1201]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>ì‚¬ìš©ì˜ˆì‹œ1~5ì—ì„œ <code>model1()</code> ëŒ€ì‹ ì— <code>model1.forward()</code>ë¥¼ ì‚¬ìš©í•´ë„ ëœë‹¤.</p>
</blockquote>
<p><code>#</code></p>
<p><code># ì˜ˆì œ2</code> â€“ ì´ë¯¸ì§€ë¶„ë¥˜</p>
<div id="cell-29" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> transformers.AutoModelForImageClassification.from_pretrained(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"google/vit-base-patch16-224-in21k"</span>,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">3</span> <span class="co"># ê·¸ëƒ¥ ëŒ€ì¶© 3ì´ë¼ê³  í–ˆìŒ.. ë³„ ì´ìœ ëŠ” ì—†ìŒ</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p><em>ëª¨ë¸ì˜ ê¸°ë³¸ì •ë³´(config)</em></p>
<div id="cell-31" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>model2.config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>ViTConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "google/vit-base-patch16-224-in21k",
  "architectures": [
    "ViTModel"
  ],
  "attention_probs_dropout_prob": 0.0,
  "encoder_stride": 16,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "image_size": 224,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "model_type": "vit",
  "num_attention_heads": 12,
  "num_channels": 3,
  "num_hidden_layers": 12,
  "patch_size": 16,
  "qkv_bias": true,
  "transformers_version": "4.46.2"
}</code></pre>
</div>
</div>
<ul>
<li>image_size: 224</li>
</ul>
<div id="cell-33" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>mp.tab(model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Type</th>
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Linear</td>
<td data-quarto-table-cell-role="th">classifier</td>
<td>Applies an affine linear transformation to the...</td>
</tr>
<tr class="even">
<td rowspan="2" data-quarto-table-cell-role="th" data-valign="top">NoneType</td>
<td data-quarto-table-cell-role="th">generation_config</td>
<td>None</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">model_tags</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TypeVar</td>
<td data-quarto-table-cell-role="th">T_destination</td>
<td>Type variable.\n\nThe preferred way to constru...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ViTConfig</td>
<td data-quarto-table-cell-role="th">config</td>
<td>This is the configuration class to store the c...</td>
</tr>
<tr class="even">
<td rowspan="2" data-quarto-table-cell-role="th" data-valign="top">ViTModel</td>
<td data-quarto-table-cell-role="th">base_model</td>
<td>The bare ViT Model transformer outputting raw ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">vit</td>
<td>The bare ViT Model transformer outputting raw ...</td>
</tr>
<tr class="even">
<td rowspan="6" data-quarto-table-cell-role="th" data-valign="top">bool</td>
<td data-quarto-table-cell-role="th">call_super_init</td>
<td>bool(x) -&gt; bool\n\nReturns True when the argum...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">dump_patches</td>
<td>bool(x) -&gt; bool\n\nReturns True when the argum...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">is_gradient_checkpointing</td>
<td>bool(x) -&gt; bool\n\nReturns True when the argum...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">is_parallelizable</td>
<td>bool(x) -&gt; bool\n\nReturns True when the argum...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">supports_gradient_checkpointing</td>
<td>bool(x) -&gt; bool\n\nReturns True when the argum...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">training</td>
<td>bool(x) -&gt; bool\n\nReturns True when the argum...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">device</td>
<td data-quarto-table-cell-role="th">device</td>
<td>None</td>
</tr>
<tr class="odd">
<td rowspan="2" data-quarto-table-cell-role="th" data-valign="top">dict</td>
<td data-quarto-table-cell-role="th">dummy_inputs</td>
<td>dict() -&gt; new empty dictionary\ndict(mapping) ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">warnings_issued</td>
<td>dict() -&gt; new empty dictionary\ndict(mapping) ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">dtype</td>
<td data-quarto-table-cell-role="th">dtype</td>
<td>None</td>
</tr>
<tr class="even">
<td rowspan="2" data-quarto-table-cell-role="th" data-valign="top">function</td>
<td data-quarto-table-cell-role="th">create_extended_attention_mask_for_decoder</td>
<td>None</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">loss_function</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">int</td>
<td data-quarto-table-cell-role="th">num_labels</td>
<td>int([x]) -&gt; integer\nint(x, base=10) -&gt; intege...</td>
</tr>
<tr class="odd">
<td rowspan="92" data-quarto-table-cell-role="th" data-valign="top">method</td>
<td data-quarto-table-cell-role="th">active_adapters</td>
<td>If you are not familiar with adapters and PEFT...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">add_adapter</td>
<td>If you are not familiar with adapters and PEFT...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">add_memory_hooks</td>
<td>Add a memory hook before and after each sub-mo...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">add_model_tags</td>
<td>Add custom tags into the model that gets pushe...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">add_module</td>
<td>Add a child module to the current module.\n\nT...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">apply</td>
<td>Apply ``fn`` recursively to every submodule (a...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">bfloat16</td>
<td>Casts all floating point parameters and buffer...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">buffers</td>
<td>Return an iterator over module buffers.\n\nArg...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">can_generate</td>
<td>Returns whether this model can generate sequen...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">children</td>
<td>Return an iterator over immediate children mod...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">compile</td>
<td>Compile this Module's forward using :func:`tor...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">compute_transition_scores</td>
<td>Computes the transition scores of sequences gi...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">cpu</td>
<td>Move all model parameters and buffers to the C...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">cuda</td>
<td>Move all model parameters and buffers to the G...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">dequantize</td>
<td>Potentially dequantize the model in case it ha...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">disable_adapters</td>
<td>If you are not familiar with adapters and PEFT...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">disable_input_require_grads</td>
<td>Removes the `_require_grads_hook`.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">double</td>
<td>Casts all floating point parameters and buffer...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">enable_adapters</td>
<td>If you are not familiar with adapters and PEFT...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">enable_input_require_grads</td>
<td>Enables the gradients for the input embeddings...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">estimate_tokens</td>
<td>Helper function to estimate the total number o...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">eval</td>
<td>Set the module in evaluation mode.\n\nThis has...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">extra_repr</td>
<td>Set the extra representation of the module.\n\...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">float</td>
<td>Casts all floating point parameters and buffer...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">floating_point_ops</td>
<td>Get number of (optionally, non-embeddings) flo...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">forward</td>
<td>The [`ViTForImageClassification`] forward meth...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">from_pretrained</td>
<td>Instantiate a pretrained pytorch model from a ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">generate</td>
<td>Generates sequences of token ids for models wi...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">get_adapter_state_dict</td>
<td>If you are not familiar with adapters and PEFT...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">get_buffer</td>
<td>Return the buffer given by ``target`` if it ex...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">get_extended_attention_mask</td>
<td>Makes broadcastable attention and causal masks...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">get_extra_state</td>
<td>Return any extra state to include in the modul...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">get_head_mask</td>
<td>Prepare the head mask if needed.\n\nArgs:\n ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">get_input_embeddings</td>
<td>Returns the model's input embeddings.\n\nRetur...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">get_memory_footprint</td>
<td>Get the memory footprint of a model. This will...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">get_output_embeddings</td>
<td>Returns the model's output embeddings.\n\nRetu...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">get_parameter</td>
<td>Return the parameter given by ``target`` if it...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">get_submodule</td>
<td>Return the submodule given by ``target`` if it...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">gradient_checkpointing_disable</td>
<td>Deactivates gradient checkpointing for the cur...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">gradient_checkpointing_enable</td>
<td>Activates gradient checkpointing for the curre...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">half</td>
<td>Casts all floating point parameters and buffer...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">heal_tokens</td>
<td>Generates sequences of token ids for models wi...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">init_weights</td>
<td>If needed prunes and maybe initializes weights...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">invert_attention_mask</td>
<td>Invert an attention mask (e.g., switches 0. an...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ipu</td>
<td>Move all model parameters and buffers to the I...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">load_adapter</td>
<td>Load adapter weights from file or remote Hub f...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">load_state_dict</td>
<td>Copy parameters and buffers from :attr:`state_...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">modules</td>
<td>Return an iterator over all modules in the net...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">named_buffers</td>
<td>Return an iterator over module buffers, yieldi...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">named_children</td>
<td>Return an iterator over immediate children mod...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">named_modules</td>
<td>Return an iterator over all modules in the net...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">named_parameters</td>
<td>Return an iterator over module parameters, yie...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">num_parameters</td>
<td>Get number of (optionally, trainable or non-em...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">parameters</td>
<td>Return an iterator over module parameters.\n\n...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">post_init</td>
<td>A method executed at the end of each Transform...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">prepare_inputs_for_generation</td>
<td>Prepare the model inputs for generation. In in...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">prune_heads</td>
<td>Prunes heads of the base model.\n\nArguments:\...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">push_to_hub</td>
<td>Upload the model file to the ğŸ¤— Model Hub.\n\nP...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">register_backward_hook</td>
<td>Register a backward hook on the module.\n\nThi...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">register_buffer</td>
<td>Add a buffer to the module.\n\nThis is typical...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">register_for_auto_class</td>
<td>Register this class with a given auto class. T...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">register_forward_hook</td>
<td>Register a forward hook on the module.\n\nThe ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">register_forward_pre_hook</td>
<td>Register a forward pre-hook on the module.\n\n...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">register_full_backward_hook</td>
<td>Register a backward hook on the module.\n\nThe...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">register_full_backward_pre_hook</td>
<td>Register a backward pre-hook on the module.\n\...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">register_load_state_dict_post_hook</td>
<td>Register a post hook to be run after module's ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">register_module</td>
<td>Alias for :func:`add_module`.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">register_parameter</td>
<td>Add a parameter to the module.\n\nThe paramete...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">register_state_dict_pre_hook</td>
<td>Register a pre-hook for the :meth:`~torch.nn.M...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">requires_grad_</td>
<td>Change if autograd should record operations on...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">reset_memory_hooks_state</td>
<td>Reset the `mem_rss_diff` attribute of each mod...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">resize_token_embeddings</td>
<td>Resizes input token embeddings matrix of the m...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">reverse_bettertransformer</td>
<td>Reverts the transformation from [`~PreTrainedM...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">save_pretrained</td>
<td>Save a model and its configuration file to a d...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">set_adapter</td>
<td>If you are not familiar with adapters and PEFT...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">set_extra_state</td>
<td>Set extra state contained in the loaded `state...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">set_input_embeddings</td>
<td>Set model's input embeddings.\n\nArgs:\n va...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">share_memory</td>
<td>See :meth:`torch.Tensor.share_memory_`.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">state_dict</td>
<td>Return a dictionary containing references to t...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">tie_weights</td>
<td>Tie the weights between the input embeddings a...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">to</td>
<td>Move and/or cast the parameters and buffers.\n...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">to_bettertransformer</td>
<td>Converts the model to use [PyTorch's native at...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">to_empty</td>
<td>Move the parameters and buffers to the specifi...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">train</td>
<td>Set the module in training mode.\n\nThis has a...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">type</td>
<td>Casts all parameters and buffers to :attr:`dst...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">warn_if_padding_and_no_attention_mask</td>
<td>Shows a one-time warning if the input_ids appe...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">xpu</td>
<td>Move all model parameters and buffers to the X...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">zero_grad</td>
<td>Reset gradients of all model parameters.\n\nSe...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">active_adapter</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">get_position_embeddings</td>
<td>None</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">resize_position_embeddings</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">retrieve_modules_from_names</td>
<td>None</td>
</tr>
<tr class="odd">
<td rowspan="4" data-quarto-table-cell-role="th" data-valign="top">str</td>
<td data-quarto-table-cell-role="th">base_model_prefix</td>
<td>str(object='') -&gt; str\nstr(bytes_or_buffer[, e...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">framework</td>
<td>str(object='') -&gt; str\nstr(bytes_or_buffer[, e...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">main_input_name</td>
<td>str(object='') -&gt; str\nstr(bytes_or_buffer[, e...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">name_or_path</td>
<td>str(object='') -&gt; str\nstr(bytes_or_buffer[, e...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">type</td>
<td data-quarto-table-cell-role="th">config_class</td>
<td>This is the configuration class to store the c...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-34" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model2.config.num_channels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>3</code></pre>
</div>
</div>
<p><em>ëª¨ë¸ì˜ ì…ë ¥íŒŒì•…</em></p>
<div id="cell-36" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>torch.randn(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">64</span>,<span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>tensor([[[[ 1.5745e+00, -6.5144e-01,  1.3978e+00,  ...,  4.6716e-01,
            1.0718e+00,  1.5891e+00],
          [ 7.2066e-01, -1.2123e-01, -7.4478e-01,  ...,  2.1659e-01,
           -1.5586e+00,  6.1032e-01],
          [ 5.7600e-01,  1.2782e+00, -1.6226e+00,  ...,  5.7004e-01,
           -9.3501e-01, -1.4276e+00],
          ...,
          [-6.1726e-01, -2.3000e+00,  1.0953e+00,  ...,  2.8432e-01,
            1.4926e+00,  1.9293e-01],
          [ 3.1345e-01, -1.6033e+00, -5.3968e-01,  ...,  3.2452e-01,
            2.0841e-02, -5.9209e-01],
          [ 1.5393e+00,  1.9803e+00,  3.8718e-01,  ..., -4.9967e-01,
            3.2762e-01, -9.5884e-02]],

         [[ 1.5481e-01, -2.1678e+00, -9.8535e-02,  ..., -8.5066e-01,
           -1.6522e+00, -1.1021e+00],
          [-6.1898e-02, -1.5264e+00, -4.2154e-01,  ..., -1.2401e+00,
           -8.2305e-01, -9.2082e-01],
          [-1.2751e+00, -6.3566e-01,  1.5400e+00,  ...,  9.1556e-01,
            3.8755e-01,  1.2098e+00],
          ...,
          [ 3.1346e-01,  4.4149e-01, -2.5716e-01,  ..., -2.2885e-01,
            3.9848e-01, -5.4158e-04],
          [-1.2899e+00,  9.7720e-02, -9.6740e-01,  ..., -8.0419e-01,
           -1.2512e-01, -8.4751e-01],
          [ 2.2317e-01,  1.1580e+00, -1.7458e+00,  ..., -1.2634e+00,
            1.0704e-01,  1.1791e+00]],

         [[ 5.3254e-01,  6.3082e-01, -9.9093e-01,  ...,  6.4301e-01,
           -7.2970e-01,  8.1526e-01],
          [ 4.3581e-01,  1.6700e+00, -1.5576e+00,  ..., -6.1614e-01,
            1.6733e-01, -6.0567e-01],
          [ 3.6077e-02,  1.0616e+00, -1.2944e-01,  ..., -1.2316e+00,
           -1.2281e+00, -5.6705e-01],
          ...,
          [-2.0337e+00, -1.2634e-01,  4.4070e-02,  ..., -5.7722e-02,
            4.1883e-01, -9.8459e-01],
          [ 2.1882e+00, -2.4888e-02,  5.3597e-02,  ..., -2.3750e+00,
           -1.8387e-01, -1.6128e-01],
          [-4.0576e-01, -1.8897e+00,  1.1782e+00,  ...,  5.1731e-01,
            4.5297e-01, -5.3125e-01]]],


        [[[-9.2747e-01, -7.5570e-01, -1.4661e+00,  ...,  1.1517e+00,
           -2.2112e+00,  1.4106e+00],
          [ 9.5970e-01,  6.6660e-01,  9.3574e-01,  ...,  1.5504e+00,
           -1.1212e+00,  1.0728e+00],
          [ 1.0182e+00, -1.3789e+00, -7.2933e-01,  ...,  5.9614e-01,
           -1.2301e-01,  4.0164e-01],
          ...,
          [-1.0014e+00, -7.1850e-01, -7.8420e-01,  ..., -3.3162e-01,
            4.8575e-01,  3.1998e-01],
          [-1.7896e+00, -2.3898e+00, -8.0165e-01,  ..., -1.6916e+00,
           -4.1522e-01,  1.4758e+00],
          [ 5.5693e-01,  8.0012e-01,  9.9807e-01,  ...,  1.3519e+00,
           -1.3475e+00,  2.3388e-01]],

         [[-7.4014e-01,  3.4345e-01, -1.5668e+00,  ..., -3.0768e-02,
           -1.7804e+00, -4.9629e-01],
          [ 1.4107e+00,  8.5074e-01, -7.8545e-01,  ...,  7.8777e-02,
            1.3570e+00,  1.1842e+00],
          [ 5.8394e-01, -6.8746e-01,  5.0234e-01,  ..., -2.5901e-01,
           -8.3004e-01, -6.7281e-01],
          ...,
          [-3.8982e-01, -2.0339e-01, -1.4185e+00,  ...,  7.1824e-01,
            1.1272e-01, -5.5666e-01],
          [-1.2153e+00,  1.1162e-01, -2.0197e+00,  ..., -4.1950e-01,
           -7.8650e-01,  3.4739e-01],
          [ 9.8186e-01, -2.8893e-01,  1.4978e+00,  ..., -7.9580e-01,
            2.2957e-01, -1.0904e-01]],

         [[ 1.9655e+00,  2.2175e-01, -1.1318e+00,  ..., -6.2302e-01,
           -3.6953e-03,  7.1338e-01],
          [-8.4720e-01, -6.9941e-01, -9.5270e-03,  ...,  2.9664e-01,
            1.2582e+00,  3.9544e-01],
          [-1.9157e-01,  1.9280e-01,  7.6348e-01,  ...,  2.1723e-01,
           -1.3277e-01, -4.8275e-01],
          ...,
          [-2.0642e+00, -5.2406e-01, -1.1908e+00,  ...,  1.7075e+00,
           -9.8756e-01,  5.1894e-02],
          [-1.4027e+00, -1.7799e-01, -3.1410e-01,  ...,  2.6471e-01,
            2.2696e-01,  1.2731e+00],
          [ 4.0601e-01, -7.4519e-02, -6.2866e-02,  ..., -3.4719e-01,
            1.6628e+00, -5.0701e-01]]]])</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ1 â€“ ì…ë ¥ë‚˜ì—´, loss O</em></p>
<div id="cell-38" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>model2(</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>),</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>ImageClassifierOutput(loss=tensor(1.0646, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.0740, -0.0991, -0.0717],
        [ 0.0718, -0.0768, -0.1305]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ2 â€“ <code>**ë”•ì…”ë„ˆë¦¬</code>, loss O</em></p>
<div id="cell-40" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model2_input <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>model2(<span class="op">**</span>model2_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>ImageClassifierOutput(loss=tensor(1.0646, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.0740, -0.0991, -0.0717],
        [ 0.0718, -0.0768, -0.1305]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ3 â€“ ì…ë ¥ë‚˜ì—´, loss X</em></p>
<div id="cell-42" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>model2(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[ 0.0740, -0.0991, -0.0717],
        [ 0.0718, -0.0768, -0.1305]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ4 â€“ <code>**ë”•ì…”ë„ˆë¦¬</code>, loss X</em></p>
<div id="cell-44" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>model2_input <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>),</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>model2(<span class="op">**</span>model2_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[ 0.0740, -0.0991, -0.0717],
        [ 0.0718, -0.0768, -0.1305]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ5 â€“ ì´ˆê°„ë‹¨, loss X</em></p>
<div id="cell-46" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>model2(torch.randn(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[ 0.0740, -0.0991, -0.0717],
        [ 0.0718, -0.0768, -0.1305]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
<p><code># ì˜ˆì œ3</code> â€“ ë™ì˜ìƒë¶„ë¥˜</p>
<div id="cell-49" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> transformers.VideoMAEForVideoClassification.from_pretrained(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MCG-NJU/videomae-base"</span>,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p><em>ëª¨ë¸ì˜ ê¸°ë³¸ì •ë³´(config)</em></p>
<div id="cell-51" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>model3.config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>VideoMAEConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "MCG-NJU/videomae-base",
  "architectures": [
    "VideoMAEForPreTraining"
  ],
  "attention_probs_dropout_prob": 0.0,
  "decoder_hidden_size": 384,
  "decoder_intermediate_size": 1536,
  "decoder_num_attention_heads": 6,
  "decoder_num_hidden_layers": 4,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "image_size": 224,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "model_type": "videomae",
  "norm_pix_loss": true,
  "num_attention_heads": 12,
  "num_channels": 3,
  "num_frames": 16,
  "num_hidden_layers": 12,
  "patch_size": 16,
  "qkv_bias": true,
  "torch_dtype": "float32",
  "transformers_version": "4.46.2",
  "tubelet_size": 2,
  "use_mean_pooling": false
}</code></pre>
</div>
</div>
<ul>
<li>image_size: 224</li>
<li>num_frames: 16</li>
</ul>
<p><em>ëª¨ë¸ì˜ ì…ë ¥íŒŒì•…</em></p>
<div id="cell-54" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>model3.forward?</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature:
model3.forward(
    pixel_values: Optional[torch.Tensor] = None,
    head_mask: Optional[torch.Tensor] = None,
    labels: Optional[torch.Tensor] = None,
    output_attentions: Optional[bool] = None,
    output_hidden_states: Optional[bool] = None,
    return_dict: Optional[bool] = None,
) -&gt; Union[Tuple, transformers.modeling_outputs.ImageClassifierOutput]
Docstring:
The [`VideoMAEForVideoClassification`] forward method, overrides the `__call__` special method.

&lt;Tip&gt;

Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.

&lt;/Tip&gt;

Args:
    pixel_values (`torch.FloatTensor` of shape `(batch_size, num_frames, num_channels, height, width)`):
        Pixel values. Pixel values can be obtained using [`AutoImageProcessor`]. See
        [`VideoMAEImageProcessor.__call__`] for details.

    head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):
        Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:

        - 1 indicates the head is **not masked**,
        - 0 indicates the head is **masked**.

    output_attentions (`bool`, *optional*):
        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
        tensors for more detail.
    output_hidden_states (`bool`, *optional*):
        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
        more detail.
    return_dict (`bool`, *optional*):
        Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.

    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
        Labels for computing the image classification/regression loss. Indices should be in `[0, ...,
        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If
        `config.num_labels &gt; 1` a classification loss is computed (Cross-Entropy).


    Returns:
        [`transformers.modeling_outputs.ImageClassifierOutput`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.ImageClassifierOutput`] or a tuple of
        `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various
        elements depending on the configuration ([`VideoMAEConfig`]) and inputs.

        - **loss** (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) -- Classification (or regression if config.num_labels==1) loss.
        - **logits** (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) -- Classification (or regression if config.num_labels==1) scores (before SoftMax).
        - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +
          one for the output of each stage) of shape `(batch_size, sequence_length, hidden_size)`. Hidden-states
          (also called feature maps) of the model at the output of each stage.
        - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, patch_size,
          sequence_length)`.

          Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
          heads.
  

    Examples:

    ```python
    &gt;&gt;&gt; import av
    &gt;&gt;&gt; import torch
    &gt;&gt;&gt; import numpy as np

    &gt;&gt;&gt; from transformers import AutoImageProcessor, VideoMAEForVideoClassification
    &gt;&gt;&gt; from huggingface_hub import hf_hub_download

    &gt;&gt;&gt; np.random.seed(0)


    &gt;&gt;&gt; def read_video_pyav(container, indices):
    ...     '''
    ...     Decode the video with PyAV decoder.
    ...     Args:
    ...         container (`av.container.input.InputContainer`): PyAV container.
    ...         indices (`List[int]`): List of frame indices to decode.
    ...     Returns:
    ...         result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).
    ...     '''
    ...     frames = []
    ...     container.seek(0)
    ...     start_index = indices[0]
    ...     end_index = indices[-1]
    ...     for i, frame in enumerate(container.decode(video=0)):
    ...         if i &gt; end_index:
    ...             break
    ...         if i &gt;= start_index and i in indices:
    ...             frames.append(frame)
    ...     return np.stack([x.to_ndarray(format="rgb24") for x in frames])


    &gt;&gt;&gt; def sample_frame_indices(clip_len, frame_sample_rate, seg_len):
    ...     '''
    ...     Sample a given number of frame indices from the video.
    ...     Args:
    ...         clip_len (`int`): Total number of frames to sample.
    ...         frame_sample_rate (`int`): Sample every n-th frame.
    ...         seg_len (`int`): Maximum allowed index of sample's last frame.
    ...     Returns:
    ...         indices (`List[int]`): List of sampled frame indices
    ...     '''
    ...     converted_len = int(clip_len * frame_sample_rate)
    ...     end_idx = np.random.randint(converted_len, seg_len)
    ...     start_idx = end_idx - converted_len
    ...     indices = np.linspace(start_idx, end_idx, num=clip_len)
    ...     indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)
    ...     return indices


    &gt;&gt;&gt; # video clip consists of 300 frames (10 seconds at 30 FPS)
    &gt;&gt;&gt; file_path = hf_hub_download(
    ...     repo_id="nielsr/video-demo", filename="eating_spaghetti.mp4", repo_type="dataset"
    ... )
    &gt;&gt;&gt; container = av.open(file_path)

    &gt;&gt;&gt; # sample 16 frames
    &gt;&gt;&gt; indices = sample_frame_indices(clip_len=16, frame_sample_rate=1, seg_len=container.streams.video[0].frames)
    &gt;&gt;&gt; video = read_video_pyav(container, indices)

    &gt;&gt;&gt; image_processor = AutoImageProcessor.from_pretrained("MCG-NJU/videomae-base-finetuned-kinetics")
    &gt;&gt;&gt; model = VideoMAEForVideoClassification.from_pretrained("MCG-NJU/videomae-base-finetuned-kinetics")

    &gt;&gt;&gt; inputs = image_processor(list(video), return_tensors="pt")

    &gt;&gt;&gt; with torch.no_grad():
    ...     outputs = model(**inputs)
    ...     logits = outputs.logits

    &gt;&gt;&gt; # model predicts one of the 400 Kinetics-400 classes
    &gt;&gt;&gt; predicted_label = logits.argmax(-1).item()
    &gt;&gt;&gt; print(model.config.id2label[predicted_label])
    eating spaghetti
    ```
File:      ~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py
Type:      method</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ1 â€“ ì…ë ¥ë‚˜ì—´, loss O</em></p>
<div id="cell-56" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>model3(</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">4</span>,<span class="dv">16</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>),</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>ImageClassifierOutput(loss=tensor(0.7254, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.7084, -0.2919],
        [-0.5846, -0.1854],
        [-0.6635, -0.2402],
        [-0.7193, -0.3811]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ2 â€“ <code>**ë”•ì…”ë„ˆë¦¬</code>, loss O</em></p>
<div id="cell-58" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>model3_input <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">4</span>,<span class="dv">16</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>),</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>model3(<span class="op">**</span>model3_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>ImageClassifierOutput(loss=tensor(0.7254, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.7084, -0.2919],
        [-0.5846, -0.1854],
        [-0.6635, -0.2402],
        [-0.7193, -0.3811]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ3 â€“ ì…ë ¥ë‚˜ì—´, loss X</em></p>
<div id="cell-60" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model3(</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">4</span>,<span class="dv">16</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[-0.7084, -0.2919],
        [-0.5846, -0.1854],
        [-0.6635, -0.2402],
        [-0.7193, -0.3811]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ4 â€“ <code>**ë”•ì…”ë„ˆë¦¬</code>, loss X</em></p>
<div id="cell-62" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>model3_input <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    pixel_values <span class="op">=</span> torch.randn(<span class="dv">4</span>,<span class="dv">16</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>),</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>model3(<span class="op">**</span>model3_input)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[-0.7084, -0.2919],
        [-0.5846, -0.1854],
        [-0.6635, -0.2402],
        [-0.7193, -0.3811]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><em>ì‚¬ìš©ì˜ˆì‹œ5 â€“ ì´ˆê°„ë‹¨, loss X</em></p>
<div id="cell-64" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>model3(torch.randn(<span class="dv">4</span>,<span class="dv">16</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[-0.7084, -0.2919],
        [-0.5846, -0.1854],
        [-0.6635, -0.2402],
        [-0.7193, -0.3811]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
</section>
<section id="model-ì‚¬ìš©-ì—°ìŠµ" class="level1">
<h1>4. Model ì‚¬ìš© ì—°ìŠµ</h1>
<section id="a.-í…ìŠ¤íŠ¸" class="level2">
<h2 class="anchored" data-anchor-id="a.-í…ìŠ¤íŠ¸">A. í…ìŠ¤íŠ¸</h2>
<div id="cell-68" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> transformers.AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distilbert/distilbert-base-uncased"</span>, num_labels<span class="op">=</span><span class="dv">2</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> transformers.AutoTokenizer.from_pretrained(<span class="st">"distilbert/distilbert-base-uncased"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p><code># ì˜ˆì œ1</code> â€“ imdb</p>
<div id="cell-70" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>imdb <span class="op">=</span> datasets.load_dataset(<span class="st">'imdb'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-71" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> imdb[<span class="st">'train'</span>].select(<span class="bu">range</span>(<span class="dv">3</span>))</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Dataset({
    features: ['text', 'label'],
    num_rows: 3
})</code></pre>
</div>
</div>
<p><code>(í’€ì´1)</code></p>
<p><em>ì‹¤íŒ¨</em></p>
<div id="cell-74" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>model1.forward(torch.tensor(tokenizer(d[<span class="st">'text'</span>])[<span class="st">'input_ids'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: expected sequence of length 363 at dim 1 (got 304)</code></pre>
</div>
</div>
<p><em>ì›ì¸ë¶„ì„</em></p>
<div id="cell-76" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>mp.show_list(</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>    tokenizer(d[<span class="st">'text'</span>])[<span class="st">'input_ids'</span>]</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Level 1 - Type: list, Length: 3, Content: [[101, 1045, 12524, 1045, ... // ... , 7987, 1013, 1028, 102]]
     Level 2 - Type: list, Length: 363, Content: [101, 1045, 12524, 1045,  ... // ... 7, 1037, 5436, 1012, 102]
     Level 2 - Type: list, Length: 304, Content: [101, 1000, 1045, 2572, 8 ... // ... 5, 1055, 4230, 1012, 102]
     Level 2 - Type: list, Length: 133, Content: [101, 2065, 2069, 2000, 4 ... // ... 6, 7987, 1013, 1028, 102]</code></pre>
</div>
</div>
<div id="cell-77" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>mp.show_list(</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    tokenizer(d[<span class="st">'text'</span>], padding<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Level 1 - Type: list, Length: 3, Content: [[101, 1045, 12524, 1045, ... // ...  0, 0, 0, 0, 0, 0, 0, 0]]
     Level 2 - Type: list, Length: 363, Content: [101, 1045, 12524, 1045,  ... // ... 7, 1037, 5436, 1012, 102]
     Level 2 - Type: list, Length: 363, Content: [101, 1000, 1045, 2572, 8 ... // ... , 0, 0, 0, 0, 0, 0, 0, 0]
     Level 2 - Type: list, Length: 363, Content: [101, 2065, 2069, 2000, 4 ... // ... , 0, 0, 0, 0, 0, 0, 0, 0]</code></pre>
</div>
</div>
<p><em>ì„±ê³µ</em></p>
<div id="cell-79" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>model1(torch.tensor(tokenizer(d[<span class="st">'text'</span>], padding<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0165, -0.0270],
        [ 0.0295, -0.0017],
        [-0.0267, -0.0590]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>(í’€ì´2)</code></p>
<div id="cell-81" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>model1(tokenizer(d[<span class="st">'text'</span>], padding<span class="op">=</span><span class="va">True</span>, return_tensors<span class="op">=</span><span class="st">"pt"</span>)[<span class="st">'input_ids'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0165, -0.0270],
        [ 0.0295, -0.0017],
        [-0.0267, -0.0590]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
<p><code># ì˜ˆì œ2</code> â€“ emotion</p>
<div id="cell-84" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>emotion <span class="op">=</span> datasets.load_dataset(<span class="st">'emotion'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-85" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> emotion[<span class="st">'train'</span>].select(<span class="bu">range</span>(<span class="dv">3</span>))</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>Dataset({
    features: ['text', 'label'],
    num_rows: 3
})</code></pre>
</div>
</div>
<p><code>(í’€ì´)</code></p>
<div id="cell-87" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>model1(torch.tensor(tokenizer(d[<span class="st">'text'</span>],padding<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[-0.0104, -0.0463],
        [-0.0066,  0.0257],
        [-0.0160, -0.0326]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
<p><code># ì˜ˆì œ3</code> â€“ MBTI</p>
<div id="cell-90" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># mbti1.csv íŒŒì¼ ë‹¤ìš´ë¡œë“œ </span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>raw.githubusercontent.com<span class="op">/</span>guebin<span class="op">/</span>MP2024<span class="op">/</span>refs<span class="op">/</span>heads<span class="op">/</span>main<span class="op">/</span>posts<span class="op">/</span>mbti_1.csv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>--2024-11-10 01:07:26--  https://raw.githubusercontent.com/guebin/MP2024/refs/heads/main/posts/mbti_1.csv
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 62856486 (60M) [text/plain]
Saving to: â€˜mbti_1.csvâ€™

mbti_1.csv          100%[===================&gt;]  59.94M   108MB/s    in 0.6s    

2024-11-10 01:07:31 (108 MB/s) - â€˜mbti_1.csvâ€™ saved [62856486/62856486]
</code></pre>
</div>
</div>
<div id="cell-91" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> datasets.Dataset.from_csv(<span class="st">"mbti_1.csv"</span>).select(<span class="bu">range</span>(<span class="dv">3</span>))</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>Dataset({
    features: ['type', 'posts'],
    num_rows: 3
})</code></pre>
</div>
</div>
<p><code>(í’€ì´1)</code></p>
<p><em>ì‹¤íŒ¨</em></p>
<div id="cell-94" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>model1(torch.tensor(tokenizer(d[<span class="st">'posts'</span>],padding<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: The size of tensor a (2102) must match the size of tensor b (512) at non-singleton dimension 1</code></pre>
</div>
</div>
<p><em>ì›ì¸ë¶„ì„</em></p>
<div id="cell-96" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>mp.show_list(</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>    tokenizer(d[<span class="st">'posts'</span>],padding<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Level 1 - Type: list, Length: 3, Content: [[101, 1005, 8299, 1024,  ... // ...  0, 0, 0, 0, 0, 0, 0, 0]]
     Level 2 - Type: list, Length: 2102, Content: [101, 1005, 8299, 1024, 1 ... // ... , 0, 0, 0, 0, 0, 0, 0, 0]
     Level 2 - Type: list, Length: 2102, Content: [101, 1005, 1045, 1005, 1 ... // ... 2, 1012, 1012, 1005, 102]
     Level 2 - Type: list, Length: 2102, Content: [101, 1005, 2204, 2028, 1 ... // ... , 0, 0, 0, 0, 0, 0, 0, 0]</code></pre>
</div>
</div>
<div id="cell-97" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>mp.show_list(</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    tokenizer(d[<span class="st">'posts'</span>],truncation<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Level 1 - Type: list, Length: 3, Content: [[101, 1005, 8299, 1024,  ... // ... , 7834, 1012, 2077, 102]]
     Level 2 - Type: list, Length: 512, Content: [101, 1005, 8299, 1024, 1 ... // ... 1, 4127, 2017, 2215, 102]
     Level 2 - Type: list, Length: 512, Content: [101, 1005, 1045, 1005, 1 ... // ... 6, 2600, 3259, 2028, 102]
     Level 2 - Type: list, Length: 512, Content: [101, 1005, 2204, 2028, 1 ... // ... 0, 7834, 1012, 2077, 102]</code></pre>
</div>
</div>
<p><em>ì„±ê³µ</em></p>
<div id="cell-99" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>model1(torch.tensor(tokenizer(d[<span class="st">'posts'</span>],truncation<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]))</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co">#model1(tokenizer(d['posts'],truncation=True,return_tensors="pt")['input_ids'])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3229, -0.0525],
        [ 0.3190, -0.1215],
        [ 0.3195, -0.0921]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>(í’€ì´2)</code> <em>â€“ëª¨ë¸ì„¤ì •ë³€ê²½ (í€´ì¦ˆ5, ëª¨ë¸ì˜ í”„ë ˆì„ìˆ˜ë¥¼ 4ë¡œ ë°”ê¾¸ëŠ” ì˜ˆì œì—ì„œ ì‚¬ìš©í•œ í…Œí¬ë‹‰)</em></p>
<p><em>distilbert/distilbert-base-uncased ì„¤ì •ê°’ ë¶€ë¥´ê¸°</em></p>
<div id="cell-102" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> transformers.AutoConfig.from_pretrained(</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distilbert/distilbert-base-uncased"</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>DistilBertConfig {
  "_name_or_path": "distilbert/distilbert-base-uncased",
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "transformers_version": "4.46.2",
  "vocab_size": 30522
}</code></pre>
</div>
</div>
<p><em>ì„¤ì •ê°’ë³€ê²½</em></p>
<div id="cell-104" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>config.max_position_embeddings <span class="op">=</span> <span class="dv">2200</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>ì„¤ì •ê°’ìœ¼ë¡œ ëª¨ë¸ë¶ˆëŸ¬ì˜¤ê¸°</em></p>
<div id="cell-106" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>model1_large <span class="op">=</span> transformers.AutoModelForSequenceClassification.from_config(</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    config<span class="op">=</span>config</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>ëª¨ë¸ì‚¬ìš©</em></p>
<div id="cell-108" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>model1_large(torch.tensor(tokenizer(d[<span class="st">'posts'</span>],padding<span class="op">=</span><span class="va">True</span>)[<span class="st">'input_ids'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[0.1088, 0.3406],
        [0.0145, 0.2405],
        [0.2319, 0.4239]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<div id="cell-109" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>model1_large(<span class="op">**</span>tokenizer(d[<span class="st">'posts'</span>],padding<span class="op">=</span><span class="va">True</span>,return_tensors<span class="op">=</span><span class="st">"pt"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0095,  0.4671],
        [ 0.0105,  0.3673],
        [-0.0640,  0.4079]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
<p><code># ì˜ˆì œ4</code> â€“ sms_spam</p>
<div id="cell-112" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>sms_spam <span class="op">=</span> datasets.load_dataset(<span class="st">'sms_spam'</span>)[<span class="st">'train'</span>].train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>sms_spam</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['sms', 'label'],
        num_rows: 4459
    })
    test: Dataset({
        features: ['sms', 'label'],
        num_rows: 1115
    })
})</code></pre>
</div>
</div>
<div id="cell-113" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> sms_spam[<span class="st">'train'</span>].select(<span class="bu">range</span>(<span class="dv">3</span>))</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>Dataset({
    features: ['sms', 'label'],
    num_rows: 3
})</code></pre>
</div>
</div>
<p><code>(í’€ì´)</code></p>
<div id="cell-115" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>model1(<span class="op">**</span>tokenizer(d[<span class="st">'sms'</span>],padding<span class="op">=</span><span class="va">True</span>,return_tensors<span class="op">=</span><span class="st">"pt"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2472, -0.0833],
        [ 0.2985, -0.1250],
        [ 0.2760, -0.1416]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
</section>
<section id="b.-ì´ë¯¸ì§€" class="level2">
<h2 class="anchored" data-anchor-id="b.-ì´ë¯¸ì§€">B. ì´ë¯¸ì§€</h2>
<div id="cell-118" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> transformers.AutoModelForImageClassification.from_pretrained(</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"google/vit-base-patch16-224-in21k"</span>,</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">3</span> <span class="co"># ê·¸ëƒ¥ ëŒ€ì¶© 3ì´ë¼ê³  í–ˆìŒ.. ë³„ ì´ìœ ëŠ” ì—†ìŒ</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p><code># ì˜ˆì œ1</code> â€“ food101</p>
<div id="cell-120" class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> datasets.load_dataset(<span class="st">"food101"</span>, split<span class="op">=</span><span class="st">"train[:4]"</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="173">
<pre><code>Dataset({
    features: ['image', 'label'],
    num_rows: 4
})</code></pre>
</div>
</div>
<p><code>(ì˜ˆë¹„í•™ìŠµ)</code> â€“ <code>torchvision.transforms</code> ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ë“¤ì€ ë°°ì¹˜ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œê°€?</p>
<div id="cell-122" class="cell" data-execution_count="174">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>to_tensor <span class="op">=</span> torchvision.transforms.ToTensor()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-123" class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>to_tensor(d[<span class="st">'image'</span>][<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="175">
<pre><code>tensor([[[0.1216, 0.1137, 0.1098,  ..., 0.0039, 0.0039, 0.0000],
         [0.1255, 0.1216, 0.1176,  ..., 0.0039, 0.0039, 0.0000],
         [0.1294, 0.1255, 0.1255,  ..., 0.0039, 0.0000, 0.0000],
         ...,
         [0.2588, 0.2745, 0.2863,  ..., 0.3765, 0.3882, 0.3922],
         [0.2353, 0.2471, 0.2667,  ..., 0.3373, 0.3373, 0.3373],
         [0.2235, 0.2275, 0.2471,  ..., 0.3333, 0.3176, 0.3059]],

        [[0.1373, 0.1294, 0.1255,  ..., 0.1020, 0.1020, 0.0980],
         [0.1412, 0.1373, 0.1333,  ..., 0.1020, 0.1020, 0.0980],
         [0.1451, 0.1412, 0.1412,  ..., 0.1020, 0.0980, 0.0980],
         ...,
         [0.2471, 0.2627, 0.2745,  ..., 0.3647, 0.3765, 0.3882],
         [0.2235, 0.2353, 0.2549,  ..., 0.3255, 0.3333, 0.3333],
         [0.2118, 0.2157, 0.2353,  ..., 0.3216, 0.3137, 0.3020]],

        [[0.1412, 0.1333, 0.1294,  ..., 0.0902, 0.0902, 0.0863],
         [0.1451, 0.1412, 0.1451,  ..., 0.0902, 0.0902, 0.0863],
         [0.1490, 0.1451, 0.1529,  ..., 0.0902, 0.0863, 0.0863],
         ...,
         [0.1725, 0.1882, 0.2000,  ..., 0.2431, 0.2549, 0.2667],
         [0.1490, 0.1608, 0.1804,  ..., 0.2039, 0.2118, 0.2118],
         [0.1373, 0.1412, 0.1608,  ..., 0.2000, 0.1922, 0.1804]]])</code></pre>
</div>
</div>
<div id="cell-124" class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>to_tensor(d[<span class="st">'image'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>TypeError: pic should be PIL Image or ndarray. Got &lt;class 'list'&gt;</code></pre>
</div>
</div>
<p><code>(í’€ì´)</code></p>
<div id="cell-126" class="cell" data-execution_count="177">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>compose <span class="op">=</span> torchvision.transforms.Compose([</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>    torchvision.transforms.ToTensor(),</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>    torchvision.transforms.Resize((<span class="dv">224</span>,<span class="dv">224</span>))</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-127" class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>torch.stack(<span class="bu">list</span>(<span class="bu">map</span>(compose,d[<span class="st">'image'</span>])),axis<span class="op">=</span><span class="dv">0</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="178">
<pre><code>torch.Size([4, 3, 224, 224])</code></pre>
</div>
</div>
<div id="cell-128" class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>model2.forward(</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>    torch.stack(<span class="bu">list</span>(<span class="bu">map</span>(compose,d[<span class="st">'image'</span>])),axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="181">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[ 0.0918, -0.0196,  0.1804],
        [ 0.1143, -0.1224, -0.0767],
        [ 0.0384, -0.0947,  0.1103],
        [ 0.1829, -0.1174, -0.0410]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
<p><code># ì˜ˆì œ2</code></p>
<div id="cell-131" class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>beans <span class="op">=</span> datasets.load_dataset(<span class="st">'beans'</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> beans[<span class="st">'train'</span>].select(<span class="bu">range</span>(<span class="dv">4</span>))</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">
<pre><code>Dataset({
    features: ['image_file_path', 'image', 'labels'],
    num_rows: 4
})</code></pre>
</div>
</div>
<p><code>(í’€ì´)</code></p>
<div id="cell-133" class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>model2(torch.stack(<span class="bu">list</span>(<span class="bu">map</span>(compose,d[<span class="st">'image'</span>])),axis<span class="op">=</span><span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="187">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[ 0.0715,  0.1286, -0.0608],
        [-0.1150, -0.0106,  0.0222],
        [-0.0856,  0.0813,  0.0233],
        [ 0.0065,  0.1047,  0.0695]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p><code>#</code></p>
</section>
<section id="c.-ë™ì˜ìƒ" class="level2">
<h2 class="anchored" data-anchor-id="c.-ë™ì˜ìƒ">C. ë™ì˜ìƒ</h2>
<div id="cell-136" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> transformers.VideoMAEForVideoClassification.from_pretrained(</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MCG-NJU/videomae-base"</span>,</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p><code># ì˜ˆì œ1</code> â€“ UCF101_subset</p>
<div id="cell-138" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> huggingface_hub.hf_hub_download(</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span><span class="st">"sayakpaul/ucf101-subset"</span>,</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>    filename<span class="op">=</span><span class="st">"UCF101_subset.tar.gz"</span>,</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span><span class="st">"dataset"</span></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a><span class="co"># file_pathëŠ” ë‹¤ìš´ë¡œë“œí•œ ì••ì¶•íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ë¡œì™€ íŒŒì¼ëª…ì´ stringìœ¼ë¡œ ì €ì¥ë˜ì–´ìˆìŒ.</span></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tarfile.<span class="bu">open</span>(file_path) <span class="im">as</span> t:</span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a>     t.extractall(<span class="st">"./data"</span>) <span class="co"># ì—¬ê¸°ì—ì„œ "."ì€ í˜„ì¬í´ë”ë¼ëŠ” ì˜ë¯¸</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-139" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>mp.tree(<span class="st">"./data"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>â””â”€â”€ UCF101_subset
    â”œâ”€â”€ test
    â”‚   â”œâ”€â”€ ApplyEyeMakeup
    â”‚   â”‚   â”œâ”€â”€ UCF101
    â”‚   â”‚   â”œâ”€â”€ v_ApplyEyeMakeup_g03_c01.avi
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚   â””â”€â”€ v_ApplyEyeMakeup_g23_c06.avi
    â”‚   â”œâ”€â”€ ApplyLipstick
    â”‚   â”‚   â”œâ”€â”€ UCF101
    â”‚   â”‚   â”œâ”€â”€ v_ApplyLipstick_g14_c01.avi
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚   â””â”€â”€ v_ApplyLipstick_g16_c04.avi
    â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ BenchPress
    â”‚       â”œâ”€â”€ UCF101
    â”‚       â”œâ”€â”€ v_BenchPress_g05_c02.avi
    â”‚       â””â”€â”€ ...
    â”‚       â””â”€â”€ v_BenchPress_g25_c06.avi
    â”œâ”€â”€ train
    â”‚   â”œâ”€â”€ ApplyEyeMakeup
    â”‚   â”‚   â”œâ”€â”€ UCF101
    â”‚   â”‚   â”œâ”€â”€ v_ApplyEyeMakeup_g02_c03.avi
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚   â””â”€â”€ v_ApplyEyeMakeup_g25_c07.avi
    â”‚   â”œâ”€â”€ ApplyLipstick
    â”‚   â”‚   â”œâ”€â”€ UCF101
    â”‚   â”‚   â”œâ”€â”€ v_ApplyLipstick_g01_c02.avi
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚   â””â”€â”€ v_ApplyLipstick_g24_c05.avi
    â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ BenchPress
    â”‚       â”œâ”€â”€ UCF101
    â”‚       â”œâ”€â”€ v_BenchPress_g01_c05.avi
    â”‚       â””â”€â”€ ...
    â”‚       â””â”€â”€ v_BenchPress_g24_c05.avi
    â””â”€â”€ val
        â”œâ”€â”€ ApplyEyeMakeup
        â”‚   â”œâ”€â”€ UCF101
        â”‚   â”œâ”€â”€ v_ApplyEyeMakeup_g01_c01.avi
        â”‚   â”œâ”€â”€ v_ApplyEyeMakeup_g14_c05.avi
        â”‚   â””â”€â”€ v_ApplyEyeMakeup_g20_c04.avi
        â”œâ”€â”€ ApplyLipstick
        â”‚   â”œâ”€â”€ UCF101
        â”‚   â”œâ”€â”€ v_ApplyLipstick_g10_c04.avi
        â”‚   â”œâ”€â”€ v_ApplyLipstick_g20_c04.avi
        â”‚   â””â”€â”€ v_ApplyLipstick_g25_c02.avi
        â””â”€â”€ ...
        â””â”€â”€ BenchPress
            â”œâ”€â”€ UCF101
            â”œâ”€â”€ v_BenchPress_g11_c05.avi
            â”œâ”€â”€ v_BenchPress_g17_c02.avi
            â””â”€â”€ v_BenchPress_g17_c06.avi</code></pre>
</div>
</div>
<div id="cell-140" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>video_path <span class="op">=</span> <span class="st">"./data/UCF101_subset/test/BenchPress/v_BenchPress_g05_c02.avi"</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>video <span class="op">=</span> pytorchvideo.data.encoded_video.EncodedVideo.from_path(video_path).get_clip(<span class="dv">0</span>, <span class="bu">float</span>(<span class="st">'inf'</span>))[<span class="st">'video'</span>]</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>video.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>torch.Size([3, 67, 240, 320])</code></pre>
</div>
</div>
<p><code>(í’€ì´)</code></p>
<div id="cell-142" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>model3(</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">#video.permute(1,0,2,3)[:16,:,:224,:224].unsqueeze(0)</span></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#video.permute(1,0,2,3)[:16,:,:224,:224].reshape(1,16,3,224,224)</span></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>    torch.stack([video.permute(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>)[:<span class="dv">16</span>,:,:<span class="dv">224</span>,:<span class="dv">224</span>]])</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>ImageClassifierOutput(loss=None, logits=tensor([[ 0.2642, -0.1763]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="guebin/MP2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>